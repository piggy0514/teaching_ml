{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"source/index.md","hash":"9160d54d61816806c995dba5fb4e48cab5704998","modified":1480564743618},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1473389848811},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1473389848811},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1473389848811},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1473389848811},{"_id":"themes/landscape/_config.yml","hash":"fb8c98a0f6ff9f962637f329c22699721854cd73","modified":1473389848811},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1473389848811},{"_id":"source/_posts/FactorAnalysis.md","hash":"842bfcf0e6b25d208763a9990195d5c24e1bb317","modified":1480499667147},{"_id":"source/_posts/TF-1-style.md","hash":"927e590f2f4094d4dc9281a845f81359faaf7391","modified":1480593705819},{"_id":"source/_posts/TF-2-basics.md","hash":"f0d9b9d975325a4075daf6b5fc2f3de3ea49bf08","modified":1480591236939},{"_id":"source/_posts/TF-3-graph.md","hash":"c10455c9c08096c1d60d753169b8e6dfb5acf40c","modified":1480591284767},{"_id":"source/_posts/TF-4-summary.md","hash":"99121b66a8b295571bceeadc12e42b94a0da3ee3","modified":1480592260455},{"_id":"source/_posts/TF-5-ann.md","hash":"e4997afdc415e167117b439148008790b4437bd4","modified":1480593739891},{"_id":"source/_posts/TF-6-autoencoder.md","hash":"8787bcb5525c6889fc652e325547c3ae87782f81","modified":1480592807443},{"_id":"source/_posts/TF-7-cnn.md","hash":"d9bd02bbf8e0b9470a36d905563d4c2e0baca64d","modified":1480592857127},{"_id":"source/_posts/TF-8-rnn.md","hash":"b278c2b7c242ff2fd80945fee9dfdae6b08d0f1e","modified":1480592887431},{"_id":"source/_posts/TF-9-distributed.md","hash":"cdaad1aedfc069cd7e163dc28790e59cbe06913a","modified":1480593762115},{"_id":"source/_posts/TF-Introduction.md","hash":"e136ac3e8e84a1e5ca3234c4694955f39b049667","modified":1480593691463},{"_id":"source/_posts/howto.md","hash":"4dd5f5279c08e509beb300e077b7d872081a2949","modified":1480575479094},{"_id":"source/_posts/mxnet.org","hash":"21c58fe00230d6ec1e431f7b2632cc044755050f","modified":1480499667155},{"_id":"source/_posts/svm.org","hash":"fa9b182a397409ce3fe02e44df185d44f41a5a26","modified":1480499667155},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1473389848811},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1473389848811},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1473389848811},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1473389848811},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1473389848811},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1473389848811},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1473389848811},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1473389848811},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1473389848811},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1473389848811},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1473389848811},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1473389848811},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1473389848811},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1473389848811},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1473389848811},{"_id":"source/_posts/associations/关联规则挖掘基础篇.md","hash":"29dfcb7505ea8eb7b64d07253dd14ce6c7cbe05f","modified":1480499667155},{"_id":"source/_posts/hexo-org-cache/0adaf7637c5ac6f4435c887c7b3bc5ee","hash":"31d4d5324e107e8dad3620b19949c6ffe498aa03","modified":1480593771891},{"_id":"source/_posts/hexo-org-cache/9701883c08c18cfb2bb4119a650c23c0","hash":"cae59f77d7de3d3f2f1d58f34632988b83c8ca4e","modified":1480593771971},{"_id":"source/_posts/mxnet/arch.png","hash":"1da84384896a43ea2146d3f59de682e50f619732","modified":1480499667155},{"_id":"source/_posts/mxnet/back_graph.png","hash":"4e0dae494db4cbd340b061e980563e40fa014df2","modified":1480499667155},{"_id":"source/_posts/mxnet/perf.png","hash":"7dfa95726f6604d74830cd564028582120d02538","modified":1480499667155},{"_id":"source/_posts/svm/code.png","hash":"605cb8052da83d6c222fea3ae7e6d33eca4f4586","modified":1473389848803},{"_id":"source/_posts/svm/codeblack.png","hash":"7a3cad9f76506ae2033c3525dea10f1f663f5ce5","modified":1473389848803},{"_id":"source/_posts/svm/codewhite.png","hash":"7e9d2b266f2051be4c06d2ceb180ea7c8ae91d62","modified":1473389848803},{"_id":"source/_posts/svm/perf.eps","hash":"79e5d8d742ea3ebd0d6b96181a6711fa9e7bcc2e","modified":1473389848803},{"_id":"source/_posts/svm/rdd.png","hash":"8de3a0ab6f7acb89f3b60021f58d6f73be3a7dc2","modified":1473389848803},{"_id":"source/_posts/svm/spark.png","hash":"d2fa24f9b373717ec6e34253d414ae202aaeeacc","modified":1473389848807},{"_id":"source/_posts/svm/ste1.eps","hash":"c484b2bbfd705fa624a4dae670403c5a6d047197","modified":1473389848807},{"_id":"source/_posts/svm/step.eps","hash":"714e5b804d0b9d87b368f8ba3ed101734e3f00fb","modified":1473389848807},{"_id":"source/_posts/svm/step1.eps","hash":"efb962773f19dba7ca9ad2d800772b4e824a3906","modified":1473389848807},{"_id":"source/_posts/svm/step2.eps","hash":"fabf228bdc128f4c18fdb5766a5b4c44812a4330","modified":1473389848807},{"_id":"source/_posts/svm/step2.png","hash":"fe7f973d76d5de960861e178b04a3f79c7c8b42e","modified":1473389848807},{"_id":"source/_posts/svm/tree.png","hash":"08b6148887a218155219736ef8d7c70d40d54a8a","modified":1473389848807},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"052cba143e3c79bbd709f1fb3c8e458dbcef3032","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"c21ca56f419d01a9f49c27b6be9f4a98402b2aa3","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1473389848811},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1473389848811},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1473389848811},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1473389848811},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1473389848811},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1473389848811},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1473389848811},{"_id":"themes/landscape/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1473389848811},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1473389848815},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1473389848815},{"_id":"source/_posts/svm/2d_circle.png","hash":"0eb7886e5bb750d70aad3f258e4cb64d47a9dac6","modified":1473389848795},{"_id":"source/_posts/svm/2d_linear.png","hash":"e09c10d5893bf37df0c13d03fbe6a2325742f361","modified":1473389848795},{"_id":"source/_posts/svm/2dcircle_2.png","hash":"cf6fcf6d353fdb43b045b26f6f59062bbbb0cb55","modified":1473389848795},{"_id":"source/_posts/svm/perf.png","hash":"571a3d198b480bcc0d8bcf99e07143d4ee28e069","modified":1473389848803},{"_id":"source/_posts/svm/step.png","hash":"af4a80c46bf2bec9bff5bfb1f7a4fcb29f066fce","modified":1473389848807},{"_id":"source/_posts/svm/step1.png","hash":"7c74f6fb0164054508eb6e7b0a4f0504886842b2","modified":1473389848807},{"_id":"source/_posts/svm/svm.png","hash":"084cb10c2bad504d958e601558a5a2121f8e1776","modified":1473389848807},{"_id":"source/_posts/associations/关联规则挖掘基础篇/Hash Tree.png","hash":"e0b28773967ba76cea9acde6f3a461eb13839c44","modified":1473389848783},{"_id":"source/_posts/associations/关联规则挖掘基础篇/db.jpg","hash":"cfcfabb111b21460fd67a837bbe784da10cb3a1d","modified":1473389848783},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fparray.png","hash":"753dcacac3cdb8c316c1f1c43cd17f2e97ba38af","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/headertable.jpg","hash":"7442280d1311b405c6f51c09a8b9e9df58f9a1a8","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/pfp.png","hash":"7e5ebe5b12963c905102cb8d4ecc028cdb2b9aec","modified":1473389848791},{"_id":"source/_posts/associations/关联规则挖掘基础篇/self_join.png","hash":"cd08b9c7e54f1519cabbf9d2b8f66a418595cdc1","modified":1473389848791},{"_id":"source/_posts/associations/关联规则挖掘基础篇/yafim.png","hash":"1a2d587976ad4b316ae605a2f4893e1bb6a83763","modified":1473389848791},{"_id":"source/_posts/associations/关联规则挖掘基础篇/subset_hash_tree.png","hash":"7afc1db1eca6f8987320e471d96b777f2335bcf6","modified":1473389848791},{"_id":"source/_posts/associations/关联规则挖掘基础篇/yafim_1.png","hash":"5a72ada606b469dee1c634feebfeb41a35e50b23","modified":1473389848791},{"_id":"source/_posts/svm/3d_ball_2.png","hash":"e688e2bd152a29c38240fa9913f508aa59f123e4","modified":1473389848799},{"_id":"source/_posts/svm/3d_linear_2.png","hash":"e10712796b9ac2f8282830c53e1112e3e6a43569","modified":1473389848803},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1473389848811},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1473389848811},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1473389848811},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1473389848811},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1473389848811},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1473389848811},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1473389848811},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1473389848811},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1473389848815},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1473389848815},{"_id":"source/_posts/associations/关联规则挖掘基础篇/apriori.jpg","hash":"24aa1a13444173eabadc216e1a04fe83017b2141","modified":1473389848783},{"_id":"source/_posts/associations/关联规则挖掘基础篇/apriori_prune.png","hash":"ba6d2dac768f52e05b9394b3a40685aefaf37728","modified":1473389848783},{"_id":"source/_posts/associations/关联规则挖掘基础篇/brute_force.png","hash":"66283cc537b0f47a622fe7a5c21fa4d08e0a4bb5","modified":1473389848783},{"_id":"source/_posts/associations/关联规则挖掘基础篇/dhp_example.png","hash":"a0ac1707afe1601e3c3429ac44e66ad87afe56de","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fpgrowthmine.jpg","hash":"0b6ab22df7128da1efe2c66d719d5b82eb18f045","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fptree.png","hash":"dbc6588b50e8dd28eff79e2509a58de62fa9bdbf","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/lattice.png","hash":"9f994c939122427066d2ef5130aea06e00be8765","modified":1473389848791},{"_id":"source/_posts/associations/关联规则挖掘基础篇/pfp1.png","hash":"f085188624ee2e16b8fc97ef62054b5417673234","modified":1473389848791},{"_id":"source/_posts/svm/3d_ball.png","hash":"ea862ca45e7008136d188a2467e65d1f19160f9c","modified":1473389848795},{"_id":"source/_posts/svm/3d_ball_2.eps","hash":"ff49c0a81594750c53b25350d7157a097e367088","modified":1473389848799},{"_id":"source/_posts/svm/3d_linear.png","hash":"674243695cca3a86b5a182dd23fee0ea5c6bd3f8","modified":1473389848803},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1473389848811},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fparray1.png","hash":"cfb65c98cbb324a7ad30d38ba25b9003e41087af","modified":1473389848787},{"_id":"source/_posts/associations/关联规则挖掘基础篇/market.jpg","hash":"859ae04a885e11fb99134250b432bbf8f833940d","modified":1473389848791},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1473389848811},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1473389848815}],"Category":[{"name":"数据挖掘","_id":"ciw6beddu000ilf8hl3jcqpbu"}],"Data":[],"Page":[{"_content":"这个文档将作为我们已经做过分享，或者将要进行分享的主题的一个索引。主要分为三个大块：常见机器学习算法，深度学习以及高级机器学习算法。常见机器学习算法主要是介绍一些spark mllib中已经实现的算法，通常要求对数学原理、mllib中的代码实现，以及如何应用于实际问题的解决等方面都要比较熟练的掌握。深度学习主要是针对一些常见的概念、优化的trick等的介绍，以及在流行深度学习框架上解决实际问题。而高级机器学习算法，通常对数学原理以及如何使用等做介绍。\n\n以下将按照这个分类列出相应的topic。\n\n# 常见机器学习算法\n## 已分享\n1. [SVM](2016/08/30/svm/)\n2. [关联规则](2016/07/04/associations/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E7%AF%87/)\n3. [ALS](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E6%8E%A8%E8%8D%90/ALS.md)\n4. [LDA](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/LDA/lda.md)\n5. [Gaussian Mixture](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/gaussian-mixture/gaussian-mixture.md)\n6. [Bistecting KMeans](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/bis-k-means/bisecting-k-means.md)\n7. [KMeans](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/k-means/k-means.md)\n8. [PIC](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/PIC/pic.md)\n\n## 将分享\n5. Logistic Regression\n6. Decision Tree\n7. Random Forest\n8. Gradient-boosted tree\n9. One-vs-Rest classifier\n10. boosting and bagging\n11. Survival Regression\n12. Isotonic Regression\n13. SGD\n14. BFGS and L-BFGS\n15. 其它最优化算法\n16. 集成学习相关算法介绍\n\n# 深度学习\n## コースの周先生Tensorflow\n#### [Introduction](_posts/deeplearning/TFLearn.ipynb)\n1. [Style](_posts/deeplearning/chapters/1-style.ipynb)\n2. [Basics](_posts/deeplearning/chapters/2-basics.ipynb)\n3. [Graph](_posts/deeplearning/chapters/3-graph.ipynb)\n4. [Summary](_posts/deeplearning/chapters/4-summary.ipynb)\n5. [Artificial neural network](_posts/deeplearning/chapters/5-ann.ipynb)\n6. [Autoencoder](_posts/deeplearning/chapters/6-autoencoder.ipynb)\n7. [Convolution neural network](_posts/deeplearning/chapters/7-cnn.ipynb)\n8. [Recursive neural network](_posts/deeplearning/chapters/8-rnn.ipynb)\n9. [Distributed](_posts/deeplearning/chapters/9-distributed.ipynb)\n\n## 已分享\n1. [MXNet框架从原理到代码](2016/07/05/mxnet)\n2. [深度信念网络在蛋白质突变检测中的应用](https://github.com/xzry6/notes/blob/master/transwarp/dbn.md)\n\n## 将分享\n1. tensor,conv,pooling\n2. Word2Vec\n3. BP\n4. Auto Encoder\n5. RBM\n6. DBN\n7. CNN\n8. RNN\n9. LSTM\n10. LSTM改进\n11. DL在NLP中的应用\n\n# 高级机器学习算法\n## 已分享\n1. TODO\n\n## 将分享\n1. 概率图模型相关知识\n2. Max Entropy\n3. HMM\n4. CRF\n5. 分词，句法分析，语法分析，语义分析，命名实体识别等\n6. 强化学习相关算法介绍\n7. 迁移学习相关算法介绍\n\n# 源码解析\n\n## 将分享\n1.deeplearning4j中深度学习和NLP源码分享\n2.tensorflow源码分享\n","source":"index.md","raw":"这个文档将作为我们已经做过分享，或者将要进行分享的主题的一个索引。主要分为三个大块：常见机器学习算法，深度学习以及高级机器学习算法。常见机器学习算法主要是介绍一些spark mllib中已经实现的算法，通常要求对数学原理、mllib中的代码实现，以及如何应用于实际问题的解决等方面都要比较熟练的掌握。深度学习主要是针对一些常见的概念、优化的trick等的介绍，以及在流行深度学习框架上解决实际问题。而高级机器学习算法，通常对数学原理以及如何使用等做介绍。\n\n以下将按照这个分类列出相应的topic。\n\n# 常见机器学习算法\n## 已分享\n1. [SVM](2016/08/30/svm/)\n2. [关联规则](2016/07/04/associations/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E7%AF%87/)\n3. [ALS](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E6%8E%A8%E8%8D%90/ALS.md)\n4. [LDA](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/LDA/lda.md)\n5. [Gaussian Mixture](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/gaussian-mixture/gaussian-mixture.md)\n6. [Bistecting KMeans](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/bis-k-means/bisecting-k-means.md)\n7. [KMeans](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/k-means/k-means.md)\n8. [PIC](https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/PIC/pic.md)\n\n## 将分享\n5. Logistic Regression\n6. Decision Tree\n7. Random Forest\n8. Gradient-boosted tree\n9. One-vs-Rest classifier\n10. boosting and bagging\n11. Survival Regression\n12. Isotonic Regression\n13. SGD\n14. BFGS and L-BFGS\n15. 其它最优化算法\n16. 集成学习相关算法介绍\n\n# 深度学习\n## コースの周先生Tensorflow\n#### [Introduction](_posts/deeplearning/TFLearn.ipynb)\n1. [Style](_posts/deeplearning/chapters/1-style.ipynb)\n2. [Basics](_posts/deeplearning/chapters/2-basics.ipynb)\n3. [Graph](_posts/deeplearning/chapters/3-graph.ipynb)\n4. [Summary](_posts/deeplearning/chapters/4-summary.ipynb)\n5. [Artificial neural network](_posts/deeplearning/chapters/5-ann.ipynb)\n6. [Autoencoder](_posts/deeplearning/chapters/6-autoencoder.ipynb)\n7. [Convolution neural network](_posts/deeplearning/chapters/7-cnn.ipynb)\n8. [Recursive neural network](_posts/deeplearning/chapters/8-rnn.ipynb)\n9. [Distributed](_posts/deeplearning/chapters/9-distributed.ipynb)\n\n## 已分享\n1. [MXNet框架从原理到代码](2016/07/05/mxnet)\n2. [深度信念网络在蛋白质突变检测中的应用](https://github.com/xzry6/notes/blob/master/transwarp/dbn.md)\n\n## 将分享\n1. tensor,conv,pooling\n2. Word2Vec\n3. BP\n4. Auto Encoder\n5. RBM\n6. DBN\n7. CNN\n8. RNN\n9. LSTM\n10. LSTM改进\n11. DL在NLP中的应用\n\n# 高级机器学习算法\n## 已分享\n1. TODO\n\n## 将分享\n1. 概率图模型相关知识\n2. Max Entropy\n3. HMM\n4. CRF\n5. 分词，句法分析，语法分析，语义分析，命名实体识别等\n6. 强化学习相关算法介绍\n7. 迁移学习相关算法介绍\n\n# 源码解析\n\n## 将分享\n1.deeplearning4j中深度学习和NLP源码分享\n2.tensorflow源码分享\n","date":"2016-12-01T03:59:03.618Z","updated":"2016-12-01T03:59:03.618Z","path":"index.html","title":"","comments":1,"layout":"page","_id":"ciw6bed8c0000lf8hjm92ghrj","content":"<p>&#x8FD9;&#x4E2A;&#x6587;&#x6863;&#x5C06;&#x4F5C;&#x4E3A;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x505A;&#x8FC7;&#x5206;&#x4EAB;&#xFF0C;&#x6216;&#x8005;&#x5C06;&#x8981;&#x8FDB;&#x884C;&#x5206;&#x4EAB;&#x7684;&#x4E3B;&#x9898;&#x7684;&#x4E00;&#x4E2A;&#x7D22;&#x5F15;&#x3002;&#x4E3B;&#x8981;&#x5206;&#x4E3A;&#x4E09;&#x4E2A;&#x5927;&#x5757;&#xFF1A;&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#xFF0C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4EE5;&#x53CA;&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x3002;&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x4E3B;&#x8981;&#x662F;&#x4ECB;&#x7ECD;&#x4E00;&#x4E9B;spark mllib&#x4E2D;&#x5DF2;&#x7ECF;&#x5B9E;&#x73B0;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x901A;&#x5E38;&#x8981;&#x6C42;&#x5BF9;&#x6570;&#x5B66;&#x539F;&#x7406;&#x3001;mllib&#x4E2D;&#x7684;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#xFF0C;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x5E94;&#x7528;&#x4E8E;&#x5B9E;&#x9645;&#x95EE;&#x9898;&#x7684;&#x89E3;&#x51B3;&#x7B49;&#x65B9;&#x9762;&#x90FD;&#x8981;&#x6BD4;&#x8F83;&#x719F;&#x7EC3;&#x7684;&#x638C;&#x63E1;&#x3002;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E3B;&#x8981;&#x662F;&#x9488;&#x5BF9;&#x4E00;&#x4E9B;&#x5E38;&#x89C1;&#x7684;&#x6982;&#x5FF5;&#x3001;&#x4F18;&#x5316;&#x7684;trick&#x7B49;&#x7684;&#x4ECB;&#x7ECD;&#xFF0C;&#x4EE5;&#x53CA;&#x5728;&#x6D41;&#x884C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6846;&#x67B6;&#x4E0A;&#x89E3;&#x51B3;&#x5B9E;&#x9645;&#x95EE;&#x9898;&#x3002;&#x800C;&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#xFF0C;&#x901A;&#x5E38;&#x5BF9;&#x6570;&#x5B66;&#x539F;&#x7406;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x7B49;&#x505A;&#x4ECB;&#x7ECD;&#x3002;</p>\n<p>&#x4EE5;&#x4E0B;&#x5C06;&#x6309;&#x7167;&#x8FD9;&#x4E2A;&#x5206;&#x7C7B;&#x5217;&#x51FA;&#x76F8;&#x5E94;&#x7684;topic&#x3002;</p>\n<h1 id=\"&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"><a href=\"#&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\" class=\"headerlink\" title=\"&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"></a>&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;</h1><h2 id=\"&#x5DF2;&#x5206;&#x4EAB;\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li><a href=\"2016/08/30/svm/\">SVM</a></li>\n<li><a href=\"2016/07/04/associations/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E7%AF%87/\">&#x5173;&#x8054;&#x89C4;&#x5219;</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E6%8E%A8%E8%8D%90/ALS.md\" target=\"_blank\" rel=\"external\">ALS</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/LDA/lda.md\" target=\"_blank\" rel=\"external\">LDA</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/gaussian-mixture/gaussian-mixture.md\" target=\"_blank\" rel=\"external\">Gaussian Mixture</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/bis-k-means/bisecting-k-means.md\" target=\"_blank\" rel=\"external\">Bistecting KMeans</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/k-means/k-means.md\" target=\"_blank\" rel=\"external\">KMeans</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/PIC/pic.md\" target=\"_blank\" rel=\"external\">PIC</a></li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>Logistic Regression</li>\n<li>Decision Tree</li>\n<li>Random Forest</li>\n<li>Gradient-boosted tree</li>\n<li>One-vs-Rest classifier</li>\n<li>boosting and bagging</li>\n<li>Survival Regression</li>\n<li>Isotonic Regression</li>\n<li>SGD</li>\n<li>BFGS and L-BFGS</li>\n<li>&#x5176;&#x5B83;&#x6700;&#x4F18;&#x5316;&#x7B97;&#x6CD5;</li>\n<li>&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n</ol>\n<h1 id=\"&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\"><a href=\"#&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\" class=\"headerlink\" title=\"&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\"></a>&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;</h1><h2 id=\"&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\"><a href=\"#&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\" class=\"headerlink\" title=\"&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\"></a>&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow</h2><h4 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a><a href=\"_posts/deeplearning/TFLearn.ipynb\">Introduction</a></h4><ol>\n<li><a href=\"_posts/deeplearning/chapters/1-style.ipynb\">Style</a></li>\n<li><a href=\"_posts/deeplearning/chapters/2-basics.ipynb\">Basics</a></li>\n<li><a href=\"_posts/deeplearning/chapters/3-graph.ipynb\">Graph</a></li>\n<li><a href=\"_posts/deeplearning/chapters/4-summary.ipynb\">Summary</a></li>\n<li><a href=\"_posts/deeplearning/chapters/5-ann.ipynb\">Artificial neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/6-autoencoder.ipynb\">Autoencoder</a></li>\n<li><a href=\"_posts/deeplearning/chapters/7-cnn.ipynb\">Convolution neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/8-rnn.ipynb\">Recursive neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/9-distributed.ipynb\">Distributed</a></li>\n</ol>\n<h2 id=\"&#x5DF2;&#x5206;&#x4EAB;-1\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;-1\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li><a href=\"2016/07/05/mxnet\">MXNet&#x6846;&#x67B6;&#x4ECE;&#x539F;&#x7406;&#x5230;&#x4EE3;&#x7801;</a></li>\n<li><a href=\"https://github.com/xzry6/notes/blob/master/transwarp/dbn.md\" target=\"_blank\" rel=\"external\">&#x6DF1;&#x5EA6;&#x4FE1;&#x5FF5;&#x7F51;&#x7EDC;&#x5728;&#x86CB;&#x767D;&#x8D28;&#x7A81;&#x53D8;&#x68C0;&#x6D4B;&#x4E2D;&#x7684;&#x5E94;&#x7528;</a></li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;-1\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-1\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>tensor,conv,pooling</li>\n<li>Word2Vec</li>\n<li>BP</li>\n<li>Auto Encoder</li>\n<li>RBM</li>\n<li>DBN</li>\n<li>CNN</li>\n<li>RNN</li>\n<li>LSTM</li>\n<li>LSTM&#x6539;&#x8FDB;</li>\n<li>DL&#x5728;NLP&#x4E2D;&#x7684;&#x5E94;&#x7528;</li>\n</ol>\n<h1 id=\"&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"><a href=\"#&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\" class=\"headerlink\" title=\"&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"></a>&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;</h1><h2 id=\"&#x5DF2;&#x5206;&#x4EAB;-2\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;-2\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li>TODO</li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;-2\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-2\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>&#x6982;&#x7387;&#x56FE;&#x6A21;&#x578B;&#x76F8;&#x5173;&#x77E5;&#x8BC6;</li>\n<li>Max Entropy</li>\n<li>HMM</li>\n<li>CRF</li>\n<li>&#x5206;&#x8BCD;&#xFF0C;&#x53E5;&#x6CD5;&#x5206;&#x6790;&#xFF0C;&#x8BED;&#x6CD5;&#x5206;&#x6790;&#xFF0C;&#x8BED;&#x4E49;&#x5206;&#x6790;&#xFF0C;&#x547D;&#x540D;&#x5B9E;&#x4F53;&#x8BC6;&#x522B;&#x7B49;</li>\n<li>&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n<li>&#x8FC1;&#x79FB;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n</ol>\n<h1 id=\"&#x6E90;&#x7801;&#x89E3;&#x6790;\"><a href=\"#&#x6E90;&#x7801;&#x89E3;&#x6790;\" class=\"headerlink\" title=\"&#x6E90;&#x7801;&#x89E3;&#x6790;\"></a>&#x6E90;&#x7801;&#x89E3;&#x6790;</h1><h2 id=\"&#x5C06;&#x5206;&#x4EAB;-3\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-3\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><p>1.deeplearning4j&#x4E2D;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x548C;NLP&#x6E90;&#x7801;&#x5206;&#x4EAB;<br>2.tensorflow&#x6E90;&#x7801;&#x5206;&#x4EAB;</p>\n","excerpt":"","more":"<p>&#x8FD9;&#x4E2A;&#x6587;&#x6863;&#x5C06;&#x4F5C;&#x4E3A;&#x6211;&#x4EEC;&#x5DF2;&#x7ECF;&#x505A;&#x8FC7;&#x5206;&#x4EAB;&#xFF0C;&#x6216;&#x8005;&#x5C06;&#x8981;&#x8FDB;&#x884C;&#x5206;&#x4EAB;&#x7684;&#x4E3B;&#x9898;&#x7684;&#x4E00;&#x4E2A;&#x7D22;&#x5F15;&#x3002;&#x4E3B;&#x8981;&#x5206;&#x4E3A;&#x4E09;&#x4E2A;&#x5927;&#x5757;&#xFF1A;&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#xFF0C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4EE5;&#x53CA;&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x3002;&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x4E3B;&#x8981;&#x662F;&#x4ECB;&#x7ECD;&#x4E00;&#x4E9B;spark mllib&#x4E2D;&#x5DF2;&#x7ECF;&#x5B9E;&#x73B0;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x901A;&#x5E38;&#x8981;&#x6C42;&#x5BF9;&#x6570;&#x5B66;&#x539F;&#x7406;&#x3001;mllib&#x4E2D;&#x7684;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#xFF0C;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x5E94;&#x7528;&#x4E8E;&#x5B9E;&#x9645;&#x95EE;&#x9898;&#x7684;&#x89E3;&#x51B3;&#x7B49;&#x65B9;&#x9762;&#x90FD;&#x8981;&#x6BD4;&#x8F83;&#x719F;&#x7EC3;&#x7684;&#x638C;&#x63E1;&#x3002;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E3B;&#x8981;&#x662F;&#x9488;&#x5BF9;&#x4E00;&#x4E9B;&#x5E38;&#x89C1;&#x7684;&#x6982;&#x5FF5;&#x3001;&#x4F18;&#x5316;&#x7684;trick&#x7B49;&#x7684;&#x4ECB;&#x7ECD;&#xFF0C;&#x4EE5;&#x53CA;&#x5728;&#x6D41;&#x884C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6846;&#x67B6;&#x4E0A;&#x89E3;&#x51B3;&#x5B9E;&#x9645;&#x95EE;&#x9898;&#x3002;&#x800C;&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#xFF0C;&#x901A;&#x5E38;&#x5BF9;&#x6570;&#x5B66;&#x539F;&#x7406;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x7B49;&#x505A;&#x4ECB;&#x7ECD;&#x3002;</p>\n<p>&#x4EE5;&#x4E0B;&#x5C06;&#x6309;&#x7167;&#x8FD9;&#x4E2A;&#x5206;&#x7C7B;&#x5217;&#x51FA;&#x76F8;&#x5E94;&#x7684;topic&#x3002;</p>\n<h1 id=\"&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"><a href=\"#&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\" class=\"headerlink\" title=\"&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"></a>&#x5E38;&#x89C1;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;</h1><h2 id=\"&#x5DF2;&#x5206;&#x4EAB;\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li><a href=\"2016/08/30/svm/\">SVM</a></li>\n<li><a href=\"2016/07/04/associations/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E5%9F%BA%E7%A1%80%E7%AF%87/\">&#x5173;&#x8054;&#x89C4;&#x5219;</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E6%8E%A8%E8%8D%90/ALS.md\">ALS</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/LDA/lda.md\">LDA</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/gaussian-mixture/gaussian-mixture.md\">Gaussian Mixture</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/bis-k-means/bisecting-k-means.md\">Bistecting KMeans</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/k-means/k-means.md\">KMeans</a></li>\n<li><a href=\"https://github.com/endymecy/spark-ml-source-analysis/blob/master/%E8%81%9A%E7%B1%BB/PIC/pic.md\">PIC</a></li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>Logistic Regression</li>\n<li>Decision Tree</li>\n<li>Random Forest</li>\n<li>Gradient-boosted tree</li>\n<li>One-vs-Rest classifier</li>\n<li>boosting and bagging</li>\n<li>Survival Regression</li>\n<li>Isotonic Regression</li>\n<li>SGD</li>\n<li>BFGS and L-BFGS</li>\n<li>&#x5176;&#x5B83;&#x6700;&#x4F18;&#x5316;&#x7B97;&#x6CD5;</li>\n<li>&#x96C6;&#x6210;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n</ol>\n<h1 id=\"&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\"><a href=\"#&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\" class=\"headerlink\" title=\"&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;\"></a>&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;</h1><h2 id=\"&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\"><a href=\"#&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\" class=\"headerlink\" title=\"&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow\"></a>&#x30B3;&#x30FC;&#x30B9;&#x306E;&#x5468;&#x5148;&#x751F;Tensorflow</h2><h4 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a><a href=\"_posts/deeplearning/TFLearn.ipynb\">Introduction</a></h4><ol>\n<li><a href=\"_posts/deeplearning/chapters/1-style.ipynb\">Style</a></li>\n<li><a href=\"_posts/deeplearning/chapters/2-basics.ipynb\">Basics</a></li>\n<li><a href=\"_posts/deeplearning/chapters/3-graph.ipynb\">Graph</a></li>\n<li><a href=\"_posts/deeplearning/chapters/4-summary.ipynb\">Summary</a></li>\n<li><a href=\"_posts/deeplearning/chapters/5-ann.ipynb\">Artificial neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/6-autoencoder.ipynb\">Autoencoder</a></li>\n<li><a href=\"_posts/deeplearning/chapters/7-cnn.ipynb\">Convolution neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/8-rnn.ipynb\">Recursive neural network</a></li>\n<li><a href=\"_posts/deeplearning/chapters/9-distributed.ipynb\">Distributed</a></li>\n</ol>\n<h2 id=\"&#x5DF2;&#x5206;&#x4EAB;-1\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;-1\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li><a href=\"2016/07/05/mxnet\">MXNet&#x6846;&#x67B6;&#x4ECE;&#x539F;&#x7406;&#x5230;&#x4EE3;&#x7801;</a></li>\n<li><a href=\"https://github.com/xzry6/notes/blob/master/transwarp/dbn.md\">&#x6DF1;&#x5EA6;&#x4FE1;&#x5FF5;&#x7F51;&#x7EDC;&#x5728;&#x86CB;&#x767D;&#x8D28;&#x7A81;&#x53D8;&#x68C0;&#x6D4B;&#x4E2D;&#x7684;&#x5E94;&#x7528;</a></li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;-1\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-1\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>tensor,conv,pooling</li>\n<li>Word2Vec</li>\n<li>BP</li>\n<li>Auto Encoder</li>\n<li>RBM</li>\n<li>DBN</li>\n<li>CNN</li>\n<li>RNN</li>\n<li>LSTM</li>\n<li>LSTM&#x6539;&#x8FDB;</li>\n<li>DL&#x5728;NLP&#x4E2D;&#x7684;&#x5E94;&#x7528;</li>\n</ol>\n<h1 id=\"&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"><a href=\"#&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\" class=\"headerlink\" title=\"&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;\"></a>&#x9AD8;&#x7EA7;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;</h1><h2 id=\"&#x5DF2;&#x5206;&#x4EAB;-2\"><a href=\"#&#x5DF2;&#x5206;&#x4EAB;-2\" class=\"headerlink\" title=\"&#x5DF2;&#x5206;&#x4EAB;\"></a>&#x5DF2;&#x5206;&#x4EAB;</h2><ol>\n<li>TODO</li>\n</ol>\n<h2 id=\"&#x5C06;&#x5206;&#x4EAB;-2\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-2\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><ol>\n<li>&#x6982;&#x7387;&#x56FE;&#x6A21;&#x578B;&#x76F8;&#x5173;&#x77E5;&#x8BC6;</li>\n<li>Max Entropy</li>\n<li>HMM</li>\n<li>CRF</li>\n<li>&#x5206;&#x8BCD;&#xFF0C;&#x53E5;&#x6CD5;&#x5206;&#x6790;&#xFF0C;&#x8BED;&#x6CD5;&#x5206;&#x6790;&#xFF0C;&#x8BED;&#x4E49;&#x5206;&#x6790;&#xFF0C;&#x547D;&#x540D;&#x5B9E;&#x4F53;&#x8BC6;&#x522B;&#x7B49;</li>\n<li>&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n<li>&#x8FC1;&#x79FB;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</li>\n</ol>\n<h1 id=\"&#x6E90;&#x7801;&#x89E3;&#x6790;\"><a href=\"#&#x6E90;&#x7801;&#x89E3;&#x6790;\" class=\"headerlink\" title=\"&#x6E90;&#x7801;&#x89E3;&#x6790;\"></a>&#x6E90;&#x7801;&#x89E3;&#x6790;</h1><h2 id=\"&#x5C06;&#x5206;&#x4EAB;-3\"><a href=\"#&#x5C06;&#x5206;&#x4EAB;-3\" class=\"headerlink\" title=\"&#x5C06;&#x5206;&#x4EAB;\"></a>&#x5C06;&#x5206;&#x4EAB;</h2><p>1.deeplearning4j&#x4E2D;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x548C;NLP&#x6E90;&#x7801;&#x5206;&#x4EAB;<br>2.tensorflow&#x6E90;&#x7801;&#x5206;&#x4EAB;</p>\n"}],"Post":[{"title":"Factor Analysis","date":"2016-11-30T06:02:27.000Z","_content":"## 1. Introduction\n An extension of **principal component analysis(PCA)** in the sense of approximating covariance matrix.\n### Goal\n- To describe the covariance relationships among many variables in terms of a few underlying unobservable random variables, called factors.\n- To reduce dimensions and solve the problem with n<p.\n\n## 2. Orthogonal Factor Model（正交因子模型）\n### A Factor Analysis Example\nWe have a  training data $ X_{n \\times p} $. Here is its scatter plot. $ y = a $\n\n![plot](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557474219.png)\n\n1. Generate a k dimension variable $F \\sim N_k(0,I)$\n\n![Factor](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557493007.png)\n\n2. There exists a transformation matrix $L \\in R^{p \\times k}$ which maps F into n dimension space: $LF$\n\n![transform](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155750367.png)\n\n3. Add a mean $\\mu$ on $LF$\n\n![add_mu](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557566675.png)\n\n4. For real  instance has errors, add error $\\epsilon_{p \\times 1}$\n\n$$X = LF+\\mu + \\epsilon$$\n\n![error](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558042959.png)\n\n### Factor Analysis Model\n- Suppose $X \\sim \\Pi_p(\\mu, \\Sigma)$\n- The factor model postulates that $X$ is linearly related to a few unobservable random variables $F_1,F_2,...,F_m$, called **common factors**（共同因子）, through\n\n$$X- \\mu = L_{p \\times m}F_{m \\times 1} + \\epsilon_{p \\times 1}$$\n\nwhere $L = (l_{ij})_{p \\times m}$ is the matrix of **factor loading**（因子载荷）, $l_{ij}$ is the loading of variable $i$ on factor $j$, $\\epsilon = (\\epsilon_1, . . . , \\epsilon_p)′$, $\\epsilon_i$ are called errors or **specific factors**（特殊因子）.\n- **Assume**: \n\n$$E(F) = 0, cov(F) = I_m, $$\n\n$$E(\\epsilon) = 0, cov(\\epsilon) = \\psi_{p \\times p} = diag(\\varphi_1,.., \\varphi_p)$$\n\n$$cov(F, \\epsilon) = E(F \\epsilon ') = 0$$\n\nThen\n\n$$cov(X) = \\Sigma_{p \\times p} = LL' + \\psi$$\n\n$$cov(X, F)  = L_{p \\times m}$$\n\nIf $cov(F) \\ne I_m$, it becomes oblique factor model（斜交因子模型）\n\n- Define the $i_{th}$ **community**（变量共同度，或公因子方差）:\n\n$$ h_i^2 = \\sum_{j = 1}^m l_{ij}^2$$\n\n- Define the $i_{th}$ **specific variance**（特殊因子方差）:\n\n$$\\varphi_i = \\sigma_{ii} - h_i^2$$\n\n#### Ambiguity of L\n\n- Let T be any m × m orthogonal matrix. Then, we can express\n\n$$X- \\mu = L^*F^* + \\epsilon$$\n\nwhere $L^* = LT$, $F^* = T'F$\n\n- Since $E(F^*) = 0$, $cov(F^*) = I_{m}$, $F^*$ and $L^*$ form another pair of factor and factor loading matrix.\n\n$$ \\Sigma = LL' + \\psi = L^* L'^{*}  + \\psi$$\n\n$$h_i^2 = e_i'LL'e_i = e_i'L^*L'^*e_i$$\n\nAfter rotation, community $h_i^2$ doesn't change.\n\n## 3. Estimation\n### 3.1 Principal Component Method \n####1) Get correlation matrix\n$$\\hat{Cor}(X) = \\Sigma$$\n####2) Spectral Decompositions\n$$\\Sigma = \\lambda_1\\ e_1e_1'\\ +\\ ...\\ +\\ \\lambda_p\\ e_pe_p'$$\n####3) Determine $m$\nRule of thumb: choose $m =\\ \\# \\ of \\{\\lambda_j>1\\}$\n####4) Estimation\n$$\\hat L = (\\sqrt{\\lambda_1}\\ e_1,\\ ...\\ ,\\ \\sqrt{\\lambda_m}\\ e_m)$$\n\n$$\\hat \\psi = diag(\\Sigma - LL')$$\n\n$$\\hat h_i^2 = \\sum_{j = 1}^m \\hat l_{ij}^2$$\n\nThe contribution to the total sample variance tr(S) from the first common factor is then（公共因子的方差贡献）\n\n$$\\hat l^2_{11} + ...+ \\hat l^2_{p1} = (\\sqrt{\\hat \\lambda_1}\\hat e_1)'(\\sqrt{\\hat \\lambda_1}\\hat e_1) = \\hat \\lambda_1$$\n\nIn general, the proportion of total sample variance(after standardization) due to the $j_{th}$ factor = $\\frac{\\hat \\lambda_j}{p}$\n\n### 3.2 Maximum Likelihood Method\n\n**1) Joint distribution:**\n\n$$\n\\begin{bmatrix}\n f\\\\\n x\n \\end{bmatrix} \\sim N \\begin{pmatrix}\n \\begin{bmatrix} 0\\\\\n \\mu\n \\end{bmatrix}, \\begin{bmatrix}\n I & L'\\\\\n L & LL' + \\psi\n \\end{bmatrix}\n \\end{pmatrix}$$\n \n**2) Marginal distribution:**\n$$x \\sim N(\\mu, LL'+\\psi)$$\n**3) Conditional distribution:**\n$$\\mu_{f|x} = L'(LL'+\\psi)^{-1}(x-\\mu)$$\n\n$$\\Sigma_{f|x} = I - L'(LL'+\\psi)^{-1}L$$\n\n**4) Log likelihood:** \n\n$$l(\\mu, L, \\psi) = log \\prod_{i=1}^n \\frac{1}{(2 \\pi)^{p/2}|LL'+\\psi|} exp \\left(-\\frac{1}{2}(x^{(i)}-\\mu)'(LL'+\\psi)^{-1}(x^{(i)}-\\mu)  \\right)$$\n\n#### EM estimation\n\n- **E Step:**\n\n$$Q(f) = \\frac{1}{(2 \\pi)^{k/2}|\\Sigma_{f|x}|} exp \\left(-\\frac{1}{2}(f-\\mu_{f|x})'(\\Sigma_{f|x})^{-1}(x^{(i)}-\\mu_{f|x})  \\right)$$\n\n- **M Step:**\n\n$$max\\ \\ \\sum_{i=1}^n \\int_{f^{(i)}} Q(f^{(i)})log \\frac{p(x^{(i)}，f^{(i)};\\mu, L, \\psi)}{Q(f^{(i)})} $$\n\n- **Parameter Iteration:**\n\n![L_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558444306.png)\n\n![mu_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558474881.png)\n\n![psi_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558484749.jpg)\n\n$\\psi = diag(\\Phi)$\n\nGet more detail on [【机器学习-斯坦福】因子分析（Factor Analysis） ](http://blog.csdn.net/littleqqqqq/article/details/50899717)\n\n##4. Factor Rotation\n\nAn orthogonal matrix $T$, and let $L^* = LT$.\n\n- **Goal: **to rotate $L$ such that a ‘simple’ structure is achieved.\n\n- Kaiser (1958)’s **varimax** criterion（方差最大旋转） :\n - Define $\\widetilde l^*_ {ij} = \\hat l^*_{ij}/h_i^2$\n - Choose $T$ s.t.\n \n$$max\\ \\ V=\\frac{1}{p} \\sum_{j=1}^m \\left ({\\sum_{i=1}^p {\\widetilde l^*_ {ij}}^4 - \\frac{\\left(\\sum_{i = 1}^p {\\widetilde l^*_ {ij}}^2 \\right)^2}{p} }\\right )$$\n\n\n##5. Factor Scores\n\n### Weighted Least Squares Method\n\n- Suppose that $\\mu$, $L$, and $\\psi$ are known.\n- Then $X-\\mu = LF + \\epsilon \\sim \\Pi_p(0, \\psi)$\n\n$$\\hat F = (L' \\psi ^{-1}L)^{-1}L' \\psi^{-1} (X-\\mu)$$\n\n### Regression Method\n\nFrom the mean of the conditional distribution of $F|X$ is $\\mu_{f|x} = L'(LL'+\\psi)^{-1}(x-\\mu)$\n\n$$\\hat F = \\hat E(F|X) = L'\\Sigma^{-1}(X-\\overline X)$$\n\n\n\n\n","source":"_posts/FactorAnalysis.md","raw":"---\ntitle: Factor Analysis\ndate: 2016-11-30 14:02:27\ntags: Multivariate Statistics\n---\n## 1. Introduction\n An extension of **principal component analysis(PCA)** in the sense of approximating covariance matrix.\n### Goal\n- To describe the covariance relationships among many variables in terms of a few underlying unobservable random variables, called factors.\n- To reduce dimensions and solve the problem with n<p.\n\n## 2. Orthogonal Factor Model（正交因子模型）\n### A Factor Analysis Example\nWe have a  training data $ X_{n \\times p} $. Here is its scatter plot. $ y = a $\n\n![plot](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557474219.png)\n\n1. Generate a k dimension variable $F \\sim N_k(0,I)$\n\n![Factor](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557493007.png)\n\n2. There exists a transformation matrix $L \\in R^{p \\times k}$ which maps F into n dimension space: $LF$\n\n![transform](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155750367.png)\n\n3. Add a mean $\\mu$ on $LF$\n\n![add_mu](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557566675.png)\n\n4. For real  instance has errors, add error $\\epsilon_{p \\times 1}$\n\n$$X = LF+\\mu + \\epsilon$$\n\n![error](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558042959.png)\n\n### Factor Analysis Model\n- Suppose $X \\sim \\Pi_p(\\mu, \\Sigma)$\n- The factor model postulates that $X$ is linearly related to a few unobservable random variables $F_1,F_2,...,F_m$, called **common factors**（共同因子）, through\n\n$$X- \\mu = L_{p \\times m}F_{m \\times 1} + \\epsilon_{p \\times 1}$$\n\nwhere $L = (l_{ij})_{p \\times m}$ is the matrix of **factor loading**（因子载荷）, $l_{ij}$ is the loading of variable $i$ on factor $j$, $\\epsilon = (\\epsilon_1, . . . , \\epsilon_p)′$, $\\epsilon_i$ are called errors or **specific factors**（特殊因子）.\n- **Assume**: \n\n$$E(F) = 0, cov(F) = I_m, $$\n\n$$E(\\epsilon) = 0, cov(\\epsilon) = \\psi_{p \\times p} = diag(\\varphi_1,.., \\varphi_p)$$\n\n$$cov(F, \\epsilon) = E(F \\epsilon ') = 0$$\n\nThen\n\n$$cov(X) = \\Sigma_{p \\times p} = LL' + \\psi$$\n\n$$cov(X, F)  = L_{p \\times m}$$\n\nIf $cov(F) \\ne I_m$, it becomes oblique factor model（斜交因子模型）\n\n- Define the $i_{th}$ **community**（变量共同度，或公因子方差）:\n\n$$ h_i^2 = \\sum_{j = 1}^m l_{ij}^2$$\n\n- Define the $i_{th}$ **specific variance**（特殊因子方差）:\n\n$$\\varphi_i = \\sigma_{ii} - h_i^2$$\n\n#### Ambiguity of L\n\n- Let T be any m × m orthogonal matrix. Then, we can express\n\n$$X- \\mu = L^*F^* + \\epsilon$$\n\nwhere $L^* = LT$, $F^* = T'F$\n\n- Since $E(F^*) = 0$, $cov(F^*) = I_{m}$, $F^*$ and $L^*$ form another pair of factor and factor loading matrix.\n\n$$ \\Sigma = LL' + \\psi = L^* L'^{*}  + \\psi$$\n\n$$h_i^2 = e_i'LL'e_i = e_i'L^*L'^*e_i$$\n\nAfter rotation, community $h_i^2$ doesn't change.\n\n## 3. Estimation\n### 3.1 Principal Component Method \n####1) Get correlation matrix\n$$\\hat{Cor}(X) = \\Sigma$$\n####2) Spectral Decompositions\n$$\\Sigma = \\lambda_1\\ e_1e_1'\\ +\\ ...\\ +\\ \\lambda_p\\ e_pe_p'$$\n####3) Determine $m$\nRule of thumb: choose $m =\\ \\# \\ of \\{\\lambda_j>1\\}$\n####4) Estimation\n$$\\hat L = (\\sqrt{\\lambda_1}\\ e_1,\\ ...\\ ,\\ \\sqrt{\\lambda_m}\\ e_m)$$\n\n$$\\hat \\psi = diag(\\Sigma - LL')$$\n\n$$\\hat h_i^2 = \\sum_{j = 1}^m \\hat l_{ij}^2$$\n\nThe contribution to the total sample variance tr(S) from the first common factor is then（公共因子的方差贡献）\n\n$$\\hat l^2_{11} + ...+ \\hat l^2_{p1} = (\\sqrt{\\hat \\lambda_1}\\hat e_1)'(\\sqrt{\\hat \\lambda_1}\\hat e_1) = \\hat \\lambda_1$$\n\nIn general, the proportion of total sample variance(after standardization) due to the $j_{th}$ factor = $\\frac{\\hat \\lambda_j}{p}$\n\n### 3.2 Maximum Likelihood Method\n\n**1) Joint distribution:**\n\n$$\n\\begin{bmatrix}\n f\\\\\n x\n \\end{bmatrix} \\sim N \\begin{pmatrix}\n \\begin{bmatrix} 0\\\\\n \\mu\n \\end{bmatrix}, \\begin{bmatrix}\n I & L'\\\\\n L & LL' + \\psi\n \\end{bmatrix}\n \\end{pmatrix}$$\n \n**2) Marginal distribution:**\n$$x \\sim N(\\mu, LL'+\\psi)$$\n**3) Conditional distribution:**\n$$\\mu_{f|x} = L'(LL'+\\psi)^{-1}(x-\\mu)$$\n\n$$\\Sigma_{f|x} = I - L'(LL'+\\psi)^{-1}L$$\n\n**4) Log likelihood:** \n\n$$l(\\mu, L, \\psi) = log \\prod_{i=1}^n \\frac{1}{(2 \\pi)^{p/2}|LL'+\\psi|} exp \\left(-\\frac{1}{2}(x^{(i)}-\\mu)'(LL'+\\psi)^{-1}(x^{(i)}-\\mu)  \\right)$$\n\n#### EM estimation\n\n- **E Step:**\n\n$$Q(f) = \\frac{1}{(2 \\pi)^{k/2}|\\Sigma_{f|x}|} exp \\left(-\\frac{1}{2}(f-\\mu_{f|x})'(\\Sigma_{f|x})^{-1}(x^{(i)}-\\mu_{f|x})  \\right)$$\n\n- **M Step:**\n\n$$max\\ \\ \\sum_{i=1}^n \\int_{f^{(i)}} Q(f^{(i)})log \\frac{p(x^{(i)}，f^{(i)};\\mu, L, \\psi)}{Q(f^{(i)})} $$\n\n- **Parameter Iteration:**\n\n![L_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558444306.png)\n\n![mu_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558474881.png)\n\n![psi_est](http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558484749.jpg)\n\n$\\psi = diag(\\Phi)$\n\nGet more detail on [【机器学习-斯坦福】因子分析（Factor Analysis） ](http://blog.csdn.net/littleqqqqq/article/details/50899717)\n\n##4. Factor Rotation\n\nAn orthogonal matrix $T$, and let $L^* = LT$.\n\n- **Goal: **to rotate $L$ such that a ‘simple’ structure is achieved.\n\n- Kaiser (1958)’s **varimax** criterion（方差最大旋转） :\n - Define $\\widetilde l^*_ {ij} = \\hat l^*_{ij}/h_i^2$\n - Choose $T$ s.t.\n \n$$max\\ \\ V=\\frac{1}{p} \\sum_{j=1}^m \\left ({\\sum_{i=1}^p {\\widetilde l^*_ {ij}}^4 - \\frac{\\left(\\sum_{i = 1}^p {\\widetilde l^*_ {ij}}^2 \\right)^2}{p} }\\right )$$\n\n\n##5. Factor Scores\n\n### Weighted Least Squares Method\n\n- Suppose that $\\mu$, $L$, and $\\psi$ are known.\n- Then $X-\\mu = LF + \\epsilon \\sim \\Pi_p(0, \\psi)$\n\n$$\\hat F = (L' \\psi ^{-1}L)^{-1}L' \\psi^{-1} (X-\\mu)$$\n\n### Regression Method\n\nFrom the mean of the conditional distribution of $F|X$ is $\\mu_{f|x} = L'(LL'+\\psi)^{-1}(x-\\mu)$\n\n$$\\hat F = \\hat E(F|X) = L'\\Sigma^{-1}(X-\\overline X)$$\n\n\n\n\n","slug":"FactorAnalysis","published":1,"updated":"2016-11-30T09:54:27.147Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bed9l0001lf8hi8uu3pc8","content":"<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p> An extension of <strong>principal component analysis(PCA)</strong> in the sense of approximating covariance matrix.</p>\n<h3 id=\"Goal\"><a href=\"#Goal\" class=\"headerlink\" title=\"Goal\"></a>Goal</h3><ul>\n<li>To describe the covariance relationships among many variables in terms of a few underlying unobservable random variables, called factors.</li>\n<li>To reduce dimensions and solve the problem with n&lt;p.</li>\n</ul>\n<h2 id=\"2-Orthogonal-Factor-Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\"><a href=\"#2-Orthogonal-Factor-Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\" class=\"headerlink\" title=\"2. Orthogonal Factor Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\"></a>2. Orthogonal Factor Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;</h2><h3 id=\"A-Factor-Analysis-Example\"><a href=\"#A-Factor-Analysis-Example\" class=\"headerlink\" title=\"A Factor Analysis Example\"></a>A Factor Analysis Example</h3><p>We have a  training data $ X_{n \\times p} $. Here is its scatter plot. $ y = a $</p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557474219.png\" alt=\"plot\"></p>\n<ol>\n<li>Generate a k dimension variable $F \\sim N_k(0,I)$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557493007.png\" alt=\"Factor\"></p>\n<ol>\n<li>There exists a transformation matrix $L \\in R^{p \\times k}$ which maps F into n dimension space: $LF$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155750367.png\" alt=\"transform\"></p>\n<ol>\n<li>Add a mean $\\mu$ on $LF$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557566675.png\" alt=\"add_mu\"></p>\n<ol>\n<li>For real  instance has errors, add error $\\epsilon_{p \\times 1}$</li>\n</ol>\n<p>$$X = LF+\\mu + \\epsilon$$</p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558042959.png\" alt=\"error\"></p>\n<h3 id=\"Factor-Analysis-Model\"><a href=\"#Factor-Analysis-Model\" class=\"headerlink\" title=\"Factor Analysis Model\"></a>Factor Analysis Model</h3><ul>\n<li>Suppose $X \\sim \\Pi_p(\\mu, \\Sigma)$</li>\n<li>The factor model postulates that $X$ is linearly related to a few unobservable random variables $F_1,F_2,&#x2026;,F_m$, called <strong>common factors</strong>&#xFF08;&#x5171;&#x540C;&#x56E0;&#x5B50;&#xFF09;, through</li>\n</ul>\n<p>$$X- \\mu = L<em>{p \\times m}F</em>{m \\times 1} + \\epsilon_{p \\times 1}$$</p>\n<p>where $L = (l<em>{ij})</em>{p \\times m}$ is the matrix of <strong>factor loading</strong>&#xFF08;&#x56E0;&#x5B50;&#x8F7D;&#x8377;&#xFF09;, $l_{ij}$ is the loading of variable $i$ on factor $j$, $\\epsilon = (\\epsilon_1, . . . , \\epsilon_p)&#x2032;$, $\\epsilon_i$ are called errors or <strong>specific factors</strong>&#xFF08;&#x7279;&#x6B8A;&#x56E0;&#x5B50;&#xFF09;.</p>\n<ul>\n<li><strong>Assume</strong>: </li>\n</ul>\n<p>$$E(F) = 0, cov(F) = I_m, $$</p>\n<p>$$E(\\epsilon) = 0, cov(\\epsilon) = \\psi_{p \\times p} = diag(\\varphi_1,.., \\varphi_p)$$</p>\n<p>$$cov(F, \\epsilon) = E(F \\epsilon &#x2018;) = 0$$</p>\n<p>Then</p>\n<p>$$cov(X) = \\Sigma_{p \\times p} = LL&#x2019; + \\psi$$</p>\n<p>$$cov(X, F)  = L_{p \\times m}$$</p>\n<p>If $cov(F) \\ne I_m$, it becomes oblique factor model&#xFF08;&#x659C;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;</p>\n<ul>\n<li>Define the $i_{th}$ <strong>community</strong>&#xFF08;&#x53D8;&#x91CF;&#x5171;&#x540C;&#x5EA6;&#xFF0C;&#x6216;&#x516C;&#x56E0;&#x5B50;&#x65B9;&#x5DEE;&#xFF09;:</li>\n</ul>\n<p>$$ h<em>i^2 = \\sum</em>{j = 1}^m l_{ij}^2$$</p>\n<ul>\n<li>Define the $i_{th}$ <strong>specific variance</strong>&#xFF08;&#x7279;&#x6B8A;&#x56E0;&#x5B50;&#x65B9;&#x5DEE;&#xFF09;:</li>\n</ul>\n<p>$$\\varphi<em>i = \\sigma</em>{ii} - h_i^2$$</p>\n<h4 id=\"Ambiguity-of-L\"><a href=\"#Ambiguity-of-L\" class=\"headerlink\" title=\"Ambiguity of L\"></a>Ambiguity of L</h4><ul>\n<li>Let T be any m &#xD7; m orthogonal matrix. Then, we can express</li>\n</ul>\n<p>$$X- \\mu = L^<em>F^</em> + \\epsilon$$</p>\n<p>where $L^<em> = LT$, $F^</em> = T&#x2019;F$</p>\n<ul>\n<li>Since $E(F^<em>) = 0$, $cov(F^</em>) = I_{m}$, $F^<em>$ and $L^</em>$ form another pair of factor and factor loading matrix.</li>\n</ul>\n<p>$$ \\Sigma = LL&#x2019; + \\psi = L^<em> L&#x2019;^{</em>}  + \\psi$$</p>\n<p>$$h_i^2 = e_i&#x2019;LL&#x2019;e_i = e_i&#x2019;L^<em>L&#x2019;^</em>e_i$$</p>\n<p>After rotation, community $h_i^2$ doesn&#x2019;t change.</p>\n<h2 id=\"3-Estimation\"><a href=\"#3-Estimation\" class=\"headerlink\" title=\"3. Estimation\"></a>3. Estimation</h2><h3 id=\"3-1-Principal-Component-Method\"><a href=\"#3-1-Principal-Component-Method\" class=\"headerlink\" title=\"3.1 Principal Component Method\"></a>3.1 Principal Component Method</h3><p>####1) Get correlation matrix<br>$$\\hat{Cor}(X) = \\Sigma$$</p>\n<p>####2) Spectral Decompositions<br>$$\\Sigma = \\lambda_1\\ e_1e_1&#x2019;\\ +\\ &#x2026;\\ +\\ \\lambda_p\\ e_pe_p&#x2019;$$</p>\n<p>####3) Determine $m$<br>Rule of thumb: choose $m =\\ # \\ of {\\lambda_j&gt;1}$</p>\n<p>####4) Estimation<br>$$\\hat L = (\\sqrt{\\lambda_1}\\ e_1,\\ &#x2026;\\ ,\\ \\sqrt{\\lambda_m}\\ e_m)$$</p>\n<p>$$\\hat \\psi = diag(\\Sigma - LL&#x2019;)$$</p>\n<p>$$\\hat h<em>i^2 = \\sum</em>{j = 1}^m \\hat l_{ij}^2$$</p>\n<p>The contribution to the total sample variance tr(S) from the first common factor is then&#xFF08;&#x516C;&#x5171;&#x56E0;&#x5B50;&#x7684;&#x65B9;&#x5DEE;&#x8D21;&#x732E;&#xFF09;</p>\n<p>$$\\hat l^2<em>{11} + &#x2026;+ \\hat l^2</em>{p1} = (\\sqrt{\\hat \\lambda_1}\\hat e_1)&#x2019;(\\sqrt{\\hat \\lambda_1}\\hat e_1) = \\hat \\lambda_1$$</p>\n<p>In general, the proportion of total sample variance(after standardization) due to the $j_{th}$ factor = $\\frac{\\hat \\lambda_j}{p}$</p>\n<h3 id=\"3-2-Maximum-Likelihood-Method\"><a href=\"#3-2-Maximum-Likelihood-Method\" class=\"headerlink\" title=\"3.2 Maximum Likelihood Method\"></a>3.2 Maximum Likelihood Method</h3><p><strong>1) Joint distribution:</strong></p>\n<p>$$<br>\\begin{bmatrix}<br> f\\<br> x<br> \\end{bmatrix} \\sim N \\begin{pmatrix}<br> \\begin{bmatrix} 0\\<br> \\mu<br> \\end{bmatrix}, \\begin{bmatrix}<br> I &amp; L&#x2019;\\<br> L &amp; LL&#x2019; + \\psi<br> \\end{bmatrix}<br> \\end{pmatrix}$$</p>\n<p><strong>2) Marginal distribution:</strong><br>$$x \\sim N(\\mu, LL&#x2019;+\\psi)$$<br><strong>3) Conditional distribution:</strong><br>$$\\mu_{f|x} = L&#x2019;(LL&#x2019;+\\psi)^{-1}(x-\\mu)$$</p>\n<p>$$\\Sigma_{f|x} = I - L&#x2019;(LL&#x2019;+\\psi)^{-1}L$$</p>\n<p><strong>4) Log likelihood:</strong> </p>\n<p>$$l(\\mu, L, \\psi) = log \\prod_{i=1}^n \\frac{1}{(2 \\pi)^{p/2}|LL&#x2019;+\\psi|} exp \\left(-\\frac{1}{2}(x^{(i)}-\\mu)&#x2019;(LL&#x2019;+\\psi)^{-1}(x^{(i)}-\\mu)  \\right)$$</p>\n<h4 id=\"EM-estimation\"><a href=\"#EM-estimation\" class=\"headerlink\" title=\"EM estimation\"></a>EM estimation</h4><ul>\n<li><strong>E Step:</strong></li>\n</ul>\n<p>$$Q(f) = \\frac{1}{(2 \\pi)^{k/2}|\\Sigma<em>{f|x}|} exp \\left(-\\frac{1}{2}(f-\\mu</em>{f|x})&#x2019;(\\Sigma<em>{f|x})^{-1}(x^{(i)}-\\mu</em>{f|x})  \\right)$$</p>\n<ul>\n<li><strong>M Step:</strong></li>\n</ul>\n<p>$$max\\ \\ \\sum<em>{i=1}^n \\int</em>{f^{(i)}} Q(f^{(i)})log \\frac{p(x^{(i)}&#xFF0C;f^{(i)};\\mu, L, \\psi)}{Q(f^{(i)})} $$</p>\n<ul>\n<li><strong>Parameter Iteration:</strong></li>\n</ul>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558444306.png\" alt=\"L_est\"></p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558474881.png\" alt=\"mu_est\"></p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558484749.jpg\" alt=\"psi_est\"></p>\n<p>$\\psi = diag(\\Phi)$</p>\n<p>Get more detail on <a href=\"http://blog.csdn.net/littleqqqqq/article/details/50899717\" target=\"_blank\" rel=\"external\">&#x3010;&#x673A;&#x5668;&#x5B66;&#x4E60;-&#x65AF;&#x5766;&#x798F;&#x3011;&#x56E0;&#x5B50;&#x5206;&#x6790;&#xFF08;Factor Analysis&#xFF09; </a></p>\n<p>##4. Factor Rotation</p>\n<p>An orthogonal matrix $T$, and let $L^* = LT$.</p>\n<ul>\n<li><p><strong>Goal: </strong>to rotate $L$ such that a &#x2018;simple&#x2019; structure is achieved.</p>\n</li>\n<li><p>Kaiser (1958)&#x2019;s <strong>varimax</strong> criterion&#xFF08;&#x65B9;&#x5DEE;&#x6700;&#x5927;&#x65CB;&#x8F6C;&#xFF09; :</p>\n<ul>\n<li>Define $\\widetilde l^<em>_ {ij} = \\hat l^</em>_{ij}/h_i^2$</li>\n<li>Choose $T$ s.t.</li>\n</ul>\n</li>\n</ul>\n<p>$$max\\ \\ V=\\frac{1}{p} \\sum<em>{j=1}^m \\left ({\\sum</em>{i=1}^p {\\widetilde l^<em><em> {ij}}^4 - \\frac{\\left(\\sum</em>{i = 1}^p {\\widetilde l^</em>_ {ij}}^2 \\right)^2}{p} }\\right )$$</p>\n<p>##5. Factor Scores</p>\n<h3 id=\"Weighted-Least-Squares-Method\"><a href=\"#Weighted-Least-Squares-Method\" class=\"headerlink\" title=\"Weighted Least Squares Method\"></a>Weighted Least Squares Method</h3><ul>\n<li>Suppose that $\\mu$, $L$, and $\\psi$ are known.</li>\n<li>Then $X-\\mu = LF + \\epsilon \\sim \\Pi_p(0, \\psi)$</li>\n</ul>\n<p>$$\\hat F = (L&#x2019; \\psi ^{-1}L)^{-1}L&#x2019; \\psi^{-1} (X-\\mu)$$</p>\n<h3 id=\"Regression-Method\"><a href=\"#Regression-Method\" class=\"headerlink\" title=\"Regression Method\"></a>Regression Method</h3><p>From the mean of the conditional distribution of $F|X$ is $\\mu_{f|x} = L&#x2019;(LL&#x2019;+\\psi)^{-1}(x-\\mu)$</p>\n<p>$$\\hat F = \\hat E(F|X) = L&#x2019;\\Sigma^{-1}(X-\\overline X)$$</p>\n","excerpt":"","more":"<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p> An extension of <strong>principal component analysis(PCA)</strong> in the sense of approximating covariance matrix.</p>\n<h3 id=\"Goal\"><a href=\"#Goal\" class=\"headerlink\" title=\"Goal\"></a>Goal</h3><ul>\n<li>To describe the covariance relationships among many variables in terms of a few underlying unobservable random variables, called factors.</li>\n<li>To reduce dimensions and solve the problem with n&lt;p.</li>\n</ul>\n<h2 id=\"2-Orthogonal-Factor-Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\"><a href=\"#2-Orthogonal-Factor-Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\" class=\"headerlink\" title=\"2. Orthogonal Factor Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;\"></a>2. Orthogonal Factor Model&#xFF08;&#x6B63;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;</h2><h3 id=\"A-Factor-Analysis-Example\"><a href=\"#A-Factor-Analysis-Example\" class=\"headerlink\" title=\"A Factor Analysis Example\"></a>A Factor Analysis Example</h3><p>We have a  training data $ X_{n \\times p} $. Here is its scatter plot. $ y = a $</p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557474219.png\" alt=\"plot\"></p>\n<ol>\n<li>Generate a k dimension variable $F \\sim N_k(0,I)$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557493007.png\" alt=\"Factor\"></p>\n<ol>\n<li>There exists a transformation matrix $L \\in R^{p \\times k}$ which maps F into n dimension space: $LF$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/20110511155750367.png\" alt=\"transform\"></p>\n<ol>\n<li>Add a mean $\\mu$ on $LF$</li>\n</ol>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111557566675.png\" alt=\"add_mu\"></p>\n<ol>\n<li>For real  instance has errors, add error $\\epsilon_{p \\times 1}$</li>\n</ol>\n<p>$$X = LF+\\mu + \\epsilon$$</p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558042959.png\" alt=\"error\"></p>\n<h3 id=\"Factor-Analysis-Model\"><a href=\"#Factor-Analysis-Model\" class=\"headerlink\" title=\"Factor Analysis Model\"></a>Factor Analysis Model</h3><ul>\n<li>Suppose $X \\sim \\Pi_p(\\mu, \\Sigma)$</li>\n<li>The factor model postulates that $X$ is linearly related to a few unobservable random variables $F_1,F_2,&#x2026;,F_m$, called <strong>common factors</strong>&#xFF08;&#x5171;&#x540C;&#x56E0;&#x5B50;&#xFF09;, through</li>\n</ul>\n<p>$$X- \\mu = L<em>{p \\times m}F</em>{m \\times 1} + \\epsilon_{p \\times 1}$$</p>\n<p>where $L = (l<em>{ij})</em>{p \\times m}$ is the matrix of <strong>factor loading</strong>&#xFF08;&#x56E0;&#x5B50;&#x8F7D;&#x8377;&#xFF09;, $l_{ij}$ is the loading of variable $i$ on factor $j$, $\\epsilon = (\\epsilon_1, . . . , \\epsilon_p)&#x2032;$, $\\epsilon_i$ are called errors or <strong>specific factors</strong>&#xFF08;&#x7279;&#x6B8A;&#x56E0;&#x5B50;&#xFF09;.</p>\n<ul>\n<li><strong>Assume</strong>: </li>\n</ul>\n<p>$$E(F) = 0, cov(F) = I_m, $$</p>\n<p>$$E(\\epsilon) = 0, cov(\\epsilon) = \\psi_{p \\times p} = diag(\\varphi_1,.., \\varphi_p)$$</p>\n<p>$$cov(F, \\epsilon) = E(F \\epsilon &#x2018;) = 0$$</p>\n<p>Then</p>\n<p>$$cov(X) = \\Sigma_{p \\times p} = LL&#x2019; + \\psi$$</p>\n<p>$$cov(X, F)  = L_{p \\times m}$$</p>\n<p>If $cov(F) \\ne I_m$, it becomes oblique factor model&#xFF08;&#x659C;&#x4EA4;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#xFF09;</p>\n<ul>\n<li>Define the $i_{th}$ <strong>community</strong>&#xFF08;&#x53D8;&#x91CF;&#x5171;&#x540C;&#x5EA6;&#xFF0C;&#x6216;&#x516C;&#x56E0;&#x5B50;&#x65B9;&#x5DEE;&#xFF09;:</li>\n</ul>\n<p>$$ h<em>i^2 = \\sum</em>{j = 1}^m l_{ij}^2$$</p>\n<ul>\n<li>Define the $i_{th}$ <strong>specific variance</strong>&#xFF08;&#x7279;&#x6B8A;&#x56E0;&#x5B50;&#x65B9;&#x5DEE;&#xFF09;:</li>\n</ul>\n<p>$$\\varphi<em>i = \\sigma</em>{ii} - h_i^2$$</p>\n<h4 id=\"Ambiguity-of-L\"><a href=\"#Ambiguity-of-L\" class=\"headerlink\" title=\"Ambiguity of L\"></a>Ambiguity of L</h4><ul>\n<li>Let T be any m &#xD7; m orthogonal matrix. Then, we can express</li>\n</ul>\n<p>$$X- \\mu = L^<em>F^</em> + \\epsilon$$</p>\n<p>where $L^<em> = LT$, $F^</em> = T&#x2019;F$</p>\n<ul>\n<li>Since $E(F^<em>) = 0$, $cov(F^</em>) = I_{m}$, $F^<em>$ and $L^</em>$ form another pair of factor and factor loading matrix.</li>\n</ul>\n<p>$$ \\Sigma = LL&#x2019; + \\psi = L^<em> L&#x2019;^{</em>}  + \\psi$$</p>\n<p>$$h_i^2 = e_i&#x2019;LL&#x2019;e_i = e_i&#x2019;L^<em>L&#x2019;^</em>e_i$$</p>\n<p>After rotation, community $h_i^2$ doesn&#x2019;t change.</p>\n<h2 id=\"3-Estimation\"><a href=\"#3-Estimation\" class=\"headerlink\" title=\"3. Estimation\"></a>3. Estimation</h2><h3 id=\"3-1-Principal-Component-Method\"><a href=\"#3-1-Principal-Component-Method\" class=\"headerlink\" title=\"3.1 Principal Component Method\"></a>3.1 Principal Component Method</h3><p>####1) Get correlation matrix<br>$$\\hat{Cor}(X) = \\Sigma$$</p>\n<p>####2) Spectral Decompositions<br>$$\\Sigma = \\lambda_1\\ e_1e_1&#x2019;\\ +\\ &#x2026;\\ +\\ \\lambda_p\\ e_pe_p&#x2019;$$</p>\n<p>####3) Determine $m$<br>Rule of thumb: choose $m =\\ # \\ of {\\lambda_j&gt;1}$</p>\n<p>####4) Estimation<br>$$\\hat L = (\\sqrt{\\lambda_1}\\ e_1,\\ &#x2026;\\ ,\\ \\sqrt{\\lambda_m}\\ e_m)$$</p>\n<p>$$\\hat \\psi = diag(\\Sigma - LL&#x2019;)$$</p>\n<p>$$\\hat h<em>i^2 = \\sum</em>{j = 1}^m \\hat l_{ij}^2$$</p>\n<p>The contribution to the total sample variance tr(S) from the first common factor is then&#xFF08;&#x516C;&#x5171;&#x56E0;&#x5B50;&#x7684;&#x65B9;&#x5DEE;&#x8D21;&#x732E;&#xFF09;</p>\n<p>$$\\hat l^2<em>{11} + &#x2026;+ \\hat l^2</em>{p1} = (\\sqrt{\\hat \\lambda_1}\\hat e_1)&#x2019;(\\sqrt{\\hat \\lambda_1}\\hat e_1) = \\hat \\lambda_1$$</p>\n<p>In general, the proportion of total sample variance(after standardization) due to the $j_{th}$ factor = $\\frac{\\hat \\lambda_j}{p}$</p>\n<h3 id=\"3-2-Maximum-Likelihood-Method\"><a href=\"#3-2-Maximum-Likelihood-Method\" class=\"headerlink\" title=\"3.2 Maximum Likelihood Method\"></a>3.2 Maximum Likelihood Method</h3><p><strong>1) Joint distribution:</strong></p>\n<p>$$<br>\\begin{bmatrix}<br> f\\<br> x<br> \\end{bmatrix} \\sim N \\begin{pmatrix}<br> \\begin{bmatrix} 0\\<br> \\mu<br> \\end{bmatrix}, \\begin{bmatrix}<br> I &amp; L&#x2019;\\<br> L &amp; LL&#x2019; + \\psi<br> \\end{bmatrix}<br> \\end{pmatrix}$$</p>\n<p><strong>2) Marginal distribution:</strong><br>$$x \\sim N(\\mu, LL&#x2019;+\\psi)$$<br><strong>3) Conditional distribution:</strong><br>$$\\mu_{f|x} = L&#x2019;(LL&#x2019;+\\psi)^{-1}(x-\\mu)$$</p>\n<p>$$\\Sigma_{f|x} = I - L&#x2019;(LL&#x2019;+\\psi)^{-1}L$$</p>\n<p><strong>4) Log likelihood:</strong> </p>\n<p>$$l(\\mu, L, \\psi) = log \\prod_{i=1}^n \\frac{1}{(2 \\pi)^{p/2}|LL&#x2019;+\\psi|} exp \\left(-\\frac{1}{2}(x^{(i)}-\\mu)&#x2019;(LL&#x2019;+\\psi)^{-1}(x^{(i)}-\\mu)  \\right)$$</p>\n<h4 id=\"EM-estimation\"><a href=\"#EM-estimation\" class=\"headerlink\" title=\"EM estimation\"></a>EM estimation</h4><ul>\n<li><strong>E Step:</strong></li>\n</ul>\n<p>$$Q(f) = \\frac{1}{(2 \\pi)^{k/2}|\\Sigma<em>{f|x}|} exp \\left(-\\frac{1}{2}(f-\\mu</em>{f|x})&#x2019;(\\Sigma<em>{f|x})^{-1}(x^{(i)}-\\mu</em>{f|x})  \\right)$$</p>\n<ul>\n<li><strong>M Step:</strong></li>\n</ul>\n<p>$$max\\ \\ \\sum<em>{i=1}^n \\int</em>{f^{(i)}} Q(f^{(i)})log \\frac{p(x^{(i)}&#xFF0C;f^{(i)};\\mu, L, \\psi)}{Q(f^{(i)})} $$</p>\n<ul>\n<li><strong>Parameter Iteration:</strong></li>\n</ul>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558444306.png\" alt=\"L_est\"></p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558474881.png\" alt=\"mu_est\"></p>\n<p><img src=\"http://images.cnblogs.com/cnblogs_com/jerrylead/201105/201105111558484749.jpg\" alt=\"psi_est\"></p>\n<p>$\\psi = diag(\\Phi)$</p>\n<p>Get more detail on <a href=\"http://blog.csdn.net/littleqqqqq/article/details/50899717\">&#x3010;&#x673A;&#x5668;&#x5B66;&#x4E60;-&#x65AF;&#x5766;&#x798F;&#x3011;&#x56E0;&#x5B50;&#x5206;&#x6790;&#xFF08;Factor Analysis&#xFF09; </a></p>\n<p>##4. Factor Rotation</p>\n<p>An orthogonal matrix $T$, and let $L^* = LT$.</p>\n<ul>\n<li><p><strong>Goal: </strong>to rotate $L$ such that a &#x2018;simple&#x2019; structure is achieved.</p>\n</li>\n<li><p>Kaiser (1958)&#x2019;s <strong>varimax</strong> criterion&#xFF08;&#x65B9;&#x5DEE;&#x6700;&#x5927;&#x65CB;&#x8F6C;&#xFF09; :</p>\n<ul>\n<li>Define $\\widetilde l^<em>_ {ij} = \\hat l^</em>_{ij}/h_i^2$</li>\n<li>Choose $T$ s.t.</li>\n</ul>\n</li>\n</ul>\n<p>$$max\\ \\ V=\\frac{1}{p} \\sum<em>{j=1}^m \\left ({\\sum</em>{i=1}^p {\\widetilde l^<em><em> {ij}}^4 - \\frac{\\left(\\sum</em>{i = 1}^p {\\widetilde l^</em>_ {ij}}^2 \\right)^2}{p} }\\right )$$</p>\n<p>##5. Factor Scores</p>\n<h3 id=\"Weighted-Least-Squares-Method\"><a href=\"#Weighted-Least-Squares-Method\" class=\"headerlink\" title=\"Weighted Least Squares Method\"></a>Weighted Least Squares Method</h3><ul>\n<li>Suppose that $\\mu$, $L$, and $\\psi$ are known.</li>\n<li>Then $X-\\mu = LF + \\epsilon \\sim \\Pi_p(0, \\psi)$</li>\n</ul>\n<p>$$\\hat F = (L&#x2019; \\psi ^{-1}L)^{-1}L&#x2019; \\psi^{-1} (X-\\mu)$$</p>\n<h3 id=\"Regression-Method\"><a href=\"#Regression-Method\" class=\"headerlink\" title=\"Regression Method\"></a>Regression Method</h3><p>From the mean of the conditional distribution of $F|X$ is $\\mu_{f|x} = L&#x2019;(LL&#x2019;+\\psi)^{-1}(x-\\mu)$</p>\n<p>$$\\hat F = \\hat E(F|X) = L&#x2019;\\Sigma^{-1}(X-\\overline X)$$</p>\n"},{"title":"TF-1-style","date":"2016-12-01T11:17:49.000Z","_content":"\n[Previous Chapter: TF Playground](../TF-Learn.ipynb)\n<br>\n[Next Chapter: Tensorflow Basics](2-basics.ipynb)\n\n## Style Guide\n\nThis page contains style decisions that both developers and users of Tensorflow should follow to increase the readability of their code, reduce the number of errors, and promote consistency.\n\n### Python Style\n2 spaces are used in tensorflow. Other than that, [PEP8 Python style guide](https://www.python.org/dev/peps/pep-0008/) should be followed.\n\n### Python 2 and 3 compatible\nTo be compatible with both Python 2 and Python 3, following lines should be added to the top of all Python files.\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\n```\n\n### Python operations\n###### A Python operation is a function that, given input tensors and parameters, creates a part of the graph and returns output tensors.\n\n- The first arguments should be tensors, followed by basic python parameters. The last argument is name with a default value of None. If operation needs to save some Tensors to Graph collections, put the arguments with names of the collections right before name argument.\n- Tensor arguments should be either a single tensor or an iterable of tensors. E.g. a \"Tensor or list of Tensors\" is too broad. See assert_proper_iterable.\n- Operations that take tensors as arguments should call convert_to_tensor to convert non-tensor inputs into tensors if they are using C++ operations. Note that the arguments are still described as a Tensor object of a specific dtype in the documentation.\n- Each Python operation should have an op_scope like below. Pass list of input tensors, name and a default name of the op as arguments.\n- Operations should contain an extensive Python comment with Args and Returns declarations that explain both the type and meaning of each value. Possible shapes, dtypes, or ranks should be specified in the description. See documentation details\n\n#### Example:\n```python\ndef my_op(tensor_in, other_tensor_in, my_param, other_param=0.5,\n          output_collections=(), name=None):\n\"\"\"My operation that adds two tensors with given coefficients.\n\nArgs:\n  tensor_in: `Tensor`, input tensor.\n  other_tensor_in: `Tensor`, same shape as `tensor_in`, other input tensor.\n  my_param: `float`, coefficient for `tensor_in`.\n  other_param: `float`, coefficient for `other_tensor_in`.\n  output_collections: `tuple` of `string`s, name of the collection to\n                      collect result of this op.\n  name: `string`, name of the operation.\n\nReturns:\n  `Tensor` of same shape as `tensor_in`, sum of input values with coefficients.\n\nExample:\n  >>> my_op([1., 2.], [3., 4.], my_param=0.5, other_param=0.6,\n            output_collections=['MY_OPS'], name='add_t1t2')\n  [2.3, 3.4]\n\"\"\"\nwith tf.op_scope([tensor_in, other_tensor_in], name, \"my_op\"):\n  tensor_in = tf.convert_to_tensor(tensor_in)\n  other_tensor_in = tf.convert_to_tensor(other_tensor_in)\n  result = my_param * tensor_in + other_param * other_tensor_in\n  tf.add_to_collections(output_collections, result)\n  return result\n```\n#### Usage:\n```python\noutput = my_op(t1, t2, my_param=0.5, other_param=0.6,\n               output_collections=['MY_OPS'], name='add_t1t2')\n```\n\n### Layers\n\n###### A Layer is a Python operation that combines variable creation and/or one or many other graph operations. Follow the same requirements as for regular Python operation.\n\nIf a layer creates one or more variables, the layer function should take next arguments also following order:\n- initializers: Optionally allow to specify initializers for the variables.\n- regularizers: Optionally allow to specify regularizers for the variables.\n- trainable: which control if their variables are trainable or not.\n- scope: VariableScope object that variable will be put under.\n- reuse: bool indicator if the variable should be reused if it's present in the scope.\n\nLayers that behave differently during training should have:\n- is_training: bool to indicate if a training graph is been built.\n\n#### Example:\n```python\ndef conv2d(inputs,\n           num_filters_out,\n           kernel_size,\n           stride=1,\n           padding='SAME',\n           activation_fn=tf.nn.relu,\n           normalization_fn=add_bias,\n           normalization_params=None,\n           initializers=None,\n           regularizers=None,\n           trainable=True,\n           scope=None,\n           reuse=None):\n  ... see implementation at tensorflow/contrib/layers/python/layers/layers.py ...\n```\n\n\n[Previous Chapter: TF Playground](../TF-Learn.ipynb)\n<br>\n[Next Chapter: Tensorflow Basics](2-basics.ipynb)\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\n```\n","source":"_posts/TF-1-style.md","raw":"---\ntitle: TF-1-style\ndate: 2016-12-01 19:17:49\ntags:\n---\n\n[Previous Chapter: TF Playground](../TF-Learn.ipynb)\n<br>\n[Next Chapter: Tensorflow Basics](2-basics.ipynb)\n\n## Style Guide\n\nThis page contains style decisions that both developers and users of Tensorflow should follow to increase the readability of their code, reduce the number of errors, and promote consistency.\n\n### Python Style\n2 spaces are used in tensorflow. Other than that, [PEP8 Python style guide](https://www.python.org/dev/peps/pep-0008/) should be followed.\n\n### Python 2 and 3 compatible\nTo be compatible with both Python 2 and Python 3, following lines should be added to the top of all Python files.\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\n```\n\n### Python operations\n###### A Python operation is a function that, given input tensors and parameters, creates a part of the graph and returns output tensors.\n\n- The first arguments should be tensors, followed by basic python parameters. The last argument is name with a default value of None. If operation needs to save some Tensors to Graph collections, put the arguments with names of the collections right before name argument.\n- Tensor arguments should be either a single tensor or an iterable of tensors. E.g. a \"Tensor or list of Tensors\" is too broad. See assert_proper_iterable.\n- Operations that take tensors as arguments should call convert_to_tensor to convert non-tensor inputs into tensors if they are using C++ operations. Note that the arguments are still described as a Tensor object of a specific dtype in the documentation.\n- Each Python operation should have an op_scope like below. Pass list of input tensors, name and a default name of the op as arguments.\n- Operations should contain an extensive Python comment with Args and Returns declarations that explain both the type and meaning of each value. Possible shapes, dtypes, or ranks should be specified in the description. See documentation details\n\n#### Example:\n```python\ndef my_op(tensor_in, other_tensor_in, my_param, other_param=0.5,\n          output_collections=(), name=None):\n\"\"\"My operation that adds two tensors with given coefficients.\n\nArgs:\n  tensor_in: `Tensor`, input tensor.\n  other_tensor_in: `Tensor`, same shape as `tensor_in`, other input tensor.\n  my_param: `float`, coefficient for `tensor_in`.\n  other_param: `float`, coefficient for `other_tensor_in`.\n  output_collections: `tuple` of `string`s, name of the collection to\n                      collect result of this op.\n  name: `string`, name of the operation.\n\nReturns:\n  `Tensor` of same shape as `tensor_in`, sum of input values with coefficients.\n\nExample:\n  >>> my_op([1., 2.], [3., 4.], my_param=0.5, other_param=0.6,\n            output_collections=['MY_OPS'], name='add_t1t2')\n  [2.3, 3.4]\n\"\"\"\nwith tf.op_scope([tensor_in, other_tensor_in], name, \"my_op\"):\n  tensor_in = tf.convert_to_tensor(tensor_in)\n  other_tensor_in = tf.convert_to_tensor(other_tensor_in)\n  result = my_param * tensor_in + other_param * other_tensor_in\n  tf.add_to_collections(output_collections, result)\n  return result\n```\n#### Usage:\n```python\noutput = my_op(t1, t2, my_param=0.5, other_param=0.6,\n               output_collections=['MY_OPS'], name='add_t1t2')\n```\n\n### Layers\n\n###### A Layer is a Python operation that combines variable creation and/or one or many other graph operations. Follow the same requirements as for regular Python operation.\n\nIf a layer creates one or more variables, the layer function should take next arguments also following order:\n- initializers: Optionally allow to specify initializers for the variables.\n- regularizers: Optionally allow to specify regularizers for the variables.\n- trainable: which control if their variables are trainable or not.\n- scope: VariableScope object that variable will be put under.\n- reuse: bool indicator if the variable should be reused if it's present in the scope.\n\nLayers that behave differently during training should have:\n- is_training: bool to indicate if a training graph is been built.\n\n#### Example:\n```python\ndef conv2d(inputs,\n           num_filters_out,\n           kernel_size,\n           stride=1,\n           padding='SAME',\n           activation_fn=tf.nn.relu,\n           normalization_fn=add_bias,\n           normalization_params=None,\n           initializers=None,\n           regularizers=None,\n           trainable=True,\n           scope=None,\n           reuse=None):\n  ... see implementation at tensorflow/contrib/layers/python/layers/layers.py ...\n```\n\n\n[Previous Chapter: TF Playground](../TF-Learn.ipynb)\n<br>\n[Next Chapter: Tensorflow Basics](2-basics.ipynb)\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\n```\n","slug":"TF-1-style","published":1,"updated":"2016-12-01T12:01:45.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bed9q0002lf8hyysq9d0j"},{"title":"TF-2-basics","date":"2016-12-01T11:19:30.000Z","_content":"\n[Previous Chapter: Style Guide](1-style.ipynb)\n<br>\n[Next Chapter: Graph](3-graph.ipynb)\n\n## Basic Concpts\n\nFollowing part is quoted from [Tensorflow 2015 White Paper](http://download.tensorflow.org/paper/whitepaper2015.pdf).\n\n<span style=\"color: #F08080\">A **TensorFlow computation** is described by a **directed graph**, which is composed of a set of nodes</span>. The *graph* represents a dataflow computation, with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph. Clients typically construct a computational graph using one of the supported frontend languages (C++ or\nPython).\n\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/3.png\" width=\"200\" />\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/2.png\" width=\"800\" />\n\nIn a *TensorFlow graph*, <span style=\"color: #F08080\">each **node** represents the instantiation of an **operation**, and has zero or more inputs and zero or more outputs</span>. <span style=\"color: #F08080\">Values that flow along normal edges in the graph (from outputs to inputs) are **tensors**</span>, arbitrary dimensionality arrays where the underlying element type is specified or inferred at graph-construction time.\n\n### Tensors\n<span style=\"color: #F08080\">A tensor is a typed, multidimensional array</span>. Tensorflow support a variety of tensor element types, including signed and unsigned integers ranging in size from 8 bits to 64 bits, IEEE float and double types, a complex number type, and a string type (an arbitrary byte array). Backing store of the appropriate size is managed by an allocator that is specific to the device on which the tensor resides. Tensor backing store buffers are reference counted and are deallocated when no references remain.\n\n\n### Variables\nIn most computations a graph is executed multiple times. Most **tensors** do not survive past a single execution of the graph. However, <span style=\"color: #F08080\">a **Variable** is a special kind of operation that returns a handle to a persistent mutable tensor that survives across executions of a graph</span>. Handles to these persistent mutable tensors can be passed to a handful of special operations, such as Assign and AssignAdd (equivalent to +=) that mutate the referenced tensor.\n\n### Operations(Ops)\n<span style=\"color: #F08080\">An **operation** has a name and represents an abstract computation (see the following table)</span>. An operation can have attributes, and all attributes must be provided or inferred at graph-construction time in order to instantiate a node to perform the operation.\n<span style=\"color: #F08080\">A **kernel** is a particular implementation of an operation that can be run on a particular type of device (e.g., CPU or GPU)</span>.\n\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/1.png\" width=\"800\" />\n\n### Sessions\n\n<span style=\"color: #F08080\">Clients programs interact with the TensorFlow system by creating a **Session**</span>.\n\n**Session Run**, which takes a set of output names that need to be computed, as well as an optional set of tensors to be fed into the graph in place of certain outputs of nodes. Using the arguments to Run, the TensorFlow implementation can compute the transitive closure of all nodes that must be executed in order to compute the outputs that were requested, and can then arrange to execute the appropriate nodes in an order that respects their dependencies. <span style=\"color: #F08080\">Most of our uses of TensorFlow set up a Session with a graph once, and then execute the full graph or a few distinct subgraphs thousands or millions of times via **Run** calls.</span>\n\n### Single Device Execution\nLet’s first consider the simplest execution scenario: a single worker process with a single device. The nodes of the graph are executed in an order that respects the dependencies between nodes. In particular, <span style=\"color: #F08080\">Tensorflow keeps track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible for execution and is added to a ready queue</span>. The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented.\n\n\n### Exercise: Basic Concepts\n\nRead the below **Tensorflow API** carefully and finish the exerceses.\n\n##### tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None)\n```\nRuns operations and evaluates tensors in fetches.\n\nThe fetches argument can be one of the following types:\n- An Operation;\n- A Tensor;\n- A SparseTensor;\n- A get_tensor_handle op;\n- A string which is the name of a tensor or operation in graph;\n\nReturns\n- A single value if fetches is a single graph element;\n- A list of values if fetches is a list;\n- A dictionary with the same keys;\n```\n\n##### tf.constant(value, dtype=None, shape=None, name='Const')\n```\nCreates a constant tensor.\n\nThe argument value can be\n- A constant value;\n- A list of values of type dtype; \n\nThe resulting tensor is populated with values of type dtype.\n```\n\n##### tf.placeholder(dtype, shape=None, name=None)\n```\nInserts a placeholder for a tensor that will be always fed.\n\nImportant: This tensor will produce an error if evaluated.\nIts value must be fed using the feed_dict optional argument\nto Session.run(), Tensor.eval(), or Operation.run().\n```\n\n##### tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)\n```\nMultiplies matrix a by matrix b, producing a * b.\n\nThe inputs must be\n- Two-dimensional matching matrices;\n- Both matrices must be of the same type\n  (float32, float64, int32, complex64)\n\nEither matrix can be transposed on the fly by setting the\ncorresponding flag to True.\n\nIf one or both of the matrices contain a lot of zeros, please\nset the corresponding a_is_sparse or b_is_sparse flag to True.\n```\n\n\n#### Prepare for Coding\nAt first, let's follow the [style guide](1-style.ipynb) and put the necessary headers.\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n```\n\nGet a session to run the code.\n\n\n```python\nsess = tf.Session()\n```\n\n#### Constants\n\n\n```python\n## create two variables `a = 2` and `b = 3`\na = ... ###### write your code here ######\nb = ... ###### write your code here ######\n\nresultA = sess.run(a)\nresultB = sess.run(b)\n\n# see the result and its type\nprint(\"a = %i with tpye of %s\" % (resultA, type(resultA)))\nprint(\"b = %i with tpye of %s\" % (resultB, type(resultB)))\n```\n\n#### Arrays and Matrices\n\n\n```python\n## create two matrixes `c = {{1, 2}, {3, 4}}` and `d = {{1, 1}, {0, 1}}`\nc = ... ###### write your code here ######\nd = ... ###### write your code here ######\n\nresultC = sess.run(c)\nresultCD = sess.run([c, d])\n\n# see the result and its type\nprint(resultC)\nprint(type(resultC))\nprint(resultCD)\nprint(type(resultCD))\n```\n\n#### String\n\n\n```python\n## create a string `e = 'Hello, Tensorflow'`\ne = ... ###### write your code here ######\nprint(sess.run(e))\n```\n\n#### Matrice Multipulation\n\n\n```python\n## multply c and d using `tf.matmul()`\nmul = ... ###### write your code here ######\nprint(sess.run(mul))\n```\n\n#### Placeholders\n\n\n```python\n## create two placeholder `f` and `g` holds `tf.int16`\nf = ... ###### write your code here ######\ng = ... ###### write your code here ######\n\n## some operations\nadd = tf.add(f, g)\nmul = tf.mul(f, g)\n\n# get the result of add by feeding `{f: 2, g: 3}` to `sess.run()` using feed_dict\nresultAdd, resultMul = ... ###### write your code here ######\nprint(\"adding result is: %i\" % resultAdd)\nprint(\"multiplying result is: %i\" % resultMul)\n```\n\n[Previous Chapter: Style Guide](1-style.ipynb)\n<br>\n[Next Chapter: Graph](3-graph.ipynb)\n\n","source":"_posts/TF-2-basics.md","raw":"---\ntitle: TF-2-basics\ndate: 2016-12-01 19:19:30\ntags:\n---\n\n[Previous Chapter: Style Guide](1-style.ipynb)\n<br>\n[Next Chapter: Graph](3-graph.ipynb)\n\n## Basic Concpts\n\nFollowing part is quoted from [Tensorflow 2015 White Paper](http://download.tensorflow.org/paper/whitepaper2015.pdf).\n\n<span style=\"color: #F08080\">A **TensorFlow computation** is described by a **directed graph**, which is composed of a set of nodes</span>. The *graph* represents a dataflow computation, with extensions for allowing some kinds of nodes to maintain and update persistent state and for branching and looping control structures within the graph. Clients typically construct a computational graph using one of the supported frontend languages (C++ or\nPython).\n\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/3.png\" width=\"200\" />\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/2.png\" width=\"800\" />\n\nIn a *TensorFlow graph*, <span style=\"color: #F08080\">each **node** represents the instantiation of an **operation**, and has zero or more inputs and zero or more outputs</span>. <span style=\"color: #F08080\">Values that flow along normal edges in the graph (from outputs to inputs) are **tensors**</span>, arbitrary dimensionality arrays where the underlying element type is specified or inferred at graph-construction time.\n\n### Tensors\n<span style=\"color: #F08080\">A tensor is a typed, multidimensional array</span>. Tensorflow support a variety of tensor element types, including signed and unsigned integers ranging in size from 8 bits to 64 bits, IEEE float and double types, a complex number type, and a string type (an arbitrary byte array). Backing store of the appropriate size is managed by an allocator that is specific to the device on which the tensor resides. Tensor backing store buffers are reference counted and are deallocated when no references remain.\n\n\n### Variables\nIn most computations a graph is executed multiple times. Most **tensors** do not survive past a single execution of the graph. However, <span style=\"color: #F08080\">a **Variable** is a special kind of operation that returns a handle to a persistent mutable tensor that survives across executions of a graph</span>. Handles to these persistent mutable tensors can be passed to a handful of special operations, such as Assign and AssignAdd (equivalent to +=) that mutate the referenced tensor.\n\n### Operations(Ops)\n<span style=\"color: #F08080\">An **operation** has a name and represents an abstract computation (see the following table)</span>. An operation can have attributes, and all attributes must be provided or inferred at graph-construction time in order to instantiate a node to perform the operation.\n<span style=\"color: #F08080\">A **kernel** is a particular implementation of an operation that can be run on a particular type of device (e.g., CPU or GPU)</span>.\n\n<img src=\"https://raw.githubusercontent.com/stdcoutzyx/Blogs/master/blogs2016/imgs_tensorflow/1.png\" width=\"800\" />\n\n### Sessions\n\n<span style=\"color: #F08080\">Clients programs interact with the TensorFlow system by creating a **Session**</span>.\n\n**Session Run**, which takes a set of output names that need to be computed, as well as an optional set of tensors to be fed into the graph in place of certain outputs of nodes. Using the arguments to Run, the TensorFlow implementation can compute the transitive closure of all nodes that must be executed in order to compute the outputs that were requested, and can then arrange to execute the appropriate nodes in an order that respects their dependencies. <span style=\"color: #F08080\">Most of our uses of TensorFlow set up a Session with a graph once, and then execute the full graph or a few distinct subgraphs thousands or millions of times via **Run** calls.</span>\n\n### Single Device Execution\nLet’s first consider the simplest execution scenario: a single worker process with a single device. The nodes of the graph are executed in an order that respects the dependencies between nodes. In particular, <span style=\"color: #F08080\">Tensorflow keeps track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible for execution and is added to a ready queue</span>. The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented.\n\n\n### Exercise: Basic Concepts\n\nRead the below **Tensorflow API** carefully and finish the exerceses.\n\n##### tf.Session.run(fetches, feed_dict=None, options=None, run_metadata=None)\n```\nRuns operations and evaluates tensors in fetches.\n\nThe fetches argument can be one of the following types:\n- An Operation;\n- A Tensor;\n- A SparseTensor;\n- A get_tensor_handle op;\n- A string which is the name of a tensor or operation in graph;\n\nReturns\n- A single value if fetches is a single graph element;\n- A list of values if fetches is a list;\n- A dictionary with the same keys;\n```\n\n##### tf.constant(value, dtype=None, shape=None, name='Const')\n```\nCreates a constant tensor.\n\nThe argument value can be\n- A constant value;\n- A list of values of type dtype; \n\nThe resulting tensor is populated with values of type dtype.\n```\n\n##### tf.placeholder(dtype, shape=None, name=None)\n```\nInserts a placeholder for a tensor that will be always fed.\n\nImportant: This tensor will produce an error if evaluated.\nIts value must be fed using the feed_dict optional argument\nto Session.run(), Tensor.eval(), or Operation.run().\n```\n\n##### tf.matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)\n```\nMultiplies matrix a by matrix b, producing a * b.\n\nThe inputs must be\n- Two-dimensional matching matrices;\n- Both matrices must be of the same type\n  (float32, float64, int32, complex64)\n\nEither matrix can be transposed on the fly by setting the\ncorresponding flag to True.\n\nIf one or both of the matrices contain a lot of zeros, please\nset the corresponding a_is_sparse or b_is_sparse flag to True.\n```\n\n\n#### Prepare for Coding\nAt first, let's follow the [style guide](1-style.ipynb) and put the necessary headers.\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n```\n\nGet a session to run the code.\n\n\n```python\nsess = tf.Session()\n```\n\n#### Constants\n\n\n```python\n## create two variables `a = 2` and `b = 3`\na = ... ###### write your code here ######\nb = ... ###### write your code here ######\n\nresultA = sess.run(a)\nresultB = sess.run(b)\n\n# see the result and its type\nprint(\"a = %i with tpye of %s\" % (resultA, type(resultA)))\nprint(\"b = %i with tpye of %s\" % (resultB, type(resultB)))\n```\n\n#### Arrays and Matrices\n\n\n```python\n## create two matrixes `c = {{1, 2}, {3, 4}}` and `d = {{1, 1}, {0, 1}}`\nc = ... ###### write your code here ######\nd = ... ###### write your code here ######\n\nresultC = sess.run(c)\nresultCD = sess.run([c, d])\n\n# see the result and its type\nprint(resultC)\nprint(type(resultC))\nprint(resultCD)\nprint(type(resultCD))\n```\n\n#### String\n\n\n```python\n## create a string `e = 'Hello, Tensorflow'`\ne = ... ###### write your code here ######\nprint(sess.run(e))\n```\n\n#### Matrice Multipulation\n\n\n```python\n## multply c and d using `tf.matmul()`\nmul = ... ###### write your code here ######\nprint(sess.run(mul))\n```\n\n#### Placeholders\n\n\n```python\n## create two placeholder `f` and `g` holds `tf.int16`\nf = ... ###### write your code here ######\ng = ... ###### write your code here ######\n\n## some operations\nadd = tf.add(f, g)\nmul = tf.mul(f, g)\n\n# get the result of add by feeding `{f: 2, g: 3}` to `sess.run()` using feed_dict\nresultAdd, resultMul = ... ###### write your code here ######\nprint(\"adding result is: %i\" % resultAdd)\nprint(\"multiplying result is: %i\" % resultMul)\n```\n\n[Previous Chapter: Style Guide](1-style.ipynb)\n<br>\n[Next Chapter: Graph](3-graph.ipynb)\n\n","slug":"TF-2-basics","published":1,"updated":"2016-12-01T11:20:36.939Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bed9y0004lf8h5lmbv2d8"},{"title":"TF-3--graph","date":"2016-12-01T11:20:49.000Z","_content":"\n[Previous Chapter: Tensorflow Basics](2-basics.ipynb)\n<br>\n[Next Chapter: Summary and Tensorboard](4-summary.ipynb)\n\n## Graph\n\nA *Graph* in Tensorflow represents complicated computation dataflow consisting of *Tensors*.<br>\n\nA *Tensor* is a basic data structure in *Tensorflow*. There are several features of a *Tensor*.\n- Represents one of outputs of an *Operation*;\n- As a symbolic handle to one of the outputs of an *Operation*, *Tensor* provides a mean of computing the outputs in *Tensor*flow session instead of hold the real value;\n- A *Tensor* could also be fed as an input to another *Operation*, that enables Tensorflow to build a multi-step, complicated computation which is called a *Graph*;\n- After the *Graph* has been launched to a *Session*, the value of the *Tensor* can be computed by passing it to `Session.run()`;\n\n\n\n### Exercise: Build a Softmax Regression in Tensorflow\n\n#### Logistic Regression\n\n*Logistic Regression* applies a sigmoid function on linear combination to break the constant gradient.\nAs ranging between 0 and 1, sigmoid function is widely used in *Neural Network* for neural activation.\n\nA sigmoid function is defined as\n$\\large \\sigma(z) = {1 \\over 1 + e^{-z}}$,\nwhere\n$\\normalsize z = x^T * w + b$.\n\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/2000px-Logistic-curve.svg.png\" width=\"300\" align=\"left\"/>\n\n#### Softmax Regression\n\n*Logistic Regression* could properly deal with 2-class classification problem. While in machine-learned neural networks, *Softmax Regression* is more common used because of the capability of multiple-class classfiction. Generally, *Softmax Regression* is a special case of *Logistic Regression* and is designed for filling the vacancy on its disadvantages.\n\nA Softmax function is defined as:\n\n$\n\\sigma(z)_j = \\Large {{e^{z_j} \\over \\Sigma^k_{k=1} e^{z_k}}}\n$\n\nThe largest $\\sigma(z)_j$ is then chosen as the predicted class.\n\n#### Relationship between Logistic Regression and Softmax Regression\n\nLet's do some simple mathmatics.\n\nWhen k = 2,\n\n$\n\\begin{align*} \n\\sigma(z)\n&= \\normalsize{{1 \\over e^{z_1} + e^{z_2}} \\begin{bmatrix} e^{z_1} \\\\ e^{z_2} \\end{bmatrix}} \\\\\n&= \\large\\begin{bmatrix} {1 \\over 1 + e^{(z_2 - z_1)}} \\\\ {1 \\over 1 + e^{(z_1 - z_2)}}\\end{bmatrix} \\\\\n&= \\large\\begin{bmatrix} {1 \\over 1 + e^{(z_2 - z_1)}} \\\\ 1 - {1 \\over 1 + e^{(z_2 - z_1)}}\\end{bmatrix}\n\\end{align*}\n$\n\n\nAssume $Z = z_1 - z_2$, one of the $\\sigma(z_1) = \\large{1 \\over 1 + e^{-Z}}$ while the other one $\\sigma(z_1) = 1 - \\large{1 \\over 1 + e^{-Z}}$, which proves the function is consitent with *Logistic Regression*.\n\n##### Now try to build a Softmax Regression in Tensorflow yourself. See [*Linear Regression sample*](../TF-Learn.ipynb#samplecode) for reference.\n\n#### Necessary Headers\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n```\n\n#### MNIST data\n\n\n```python\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n```\n\n#### Training Parameters\n\n\n```python\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\n```\n\n#### Inputs\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, [None, 784]) # MNIST data image are of shape 28*28\ny = tf.placeholder(tf.float32, [None, 10]) # MNIST data has 10 classes\n```\n\n#### Variables\n\n\n```python\n## variables\n\n# initialize random uniform distributed weights with size of [784, 10] ranging from -1 to 1\nW = tf.Variables(tf.random_uniform([784,10], -1.0, 1.0)) ###### write your code here ######\n\n# initialize bias with size of [10] to zero\nb = tf.Variables(tf.zeros([10])) ###### write your code here ######\n```\n\n#### Graph\n\n\n```python\n## graph\n\n# comb = W * x + b (using a similar tensorflow function)\ncomb = ... ###### write your code here ######\n\n# predicted value\npred = tf.nn.softmax(comb)\n\n# entr equals to **negative** `tf.reduce_sum()` of y * log(pred), with reduction_indices = 1\nentr = ... ###### write your code here ######\n\n# cross entropy cost\ncost = tf.reduce_mean(entr)\n\n# optimizer\nopti = tf.train.GradientDescentOptimizer(learning_rate)\n\n# training_steps use optimizer to minimize the cost\ntraining_steps = ... ###### write your code here ######\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # training epochs\n    for epoch in range(training_epochs):\n\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        # split the data into different batches and run\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # run training steps and cost both in session, which should be fed `x = batch_xs` and `y = batch_ys`\n            _, cur_cost = ... ###### write your code here ######\n\n            avg_cost += cur_cost / total_batch\n\n        # show the average cost\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n\n    # accuracy\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n```\n\n[Previous Chapter: Tensorflow Basics](2-basics.ipynb)\n<br>\n[Next Chapter: Summary and Tensorboard](4-summary.ipynb)\n\n","source":"_posts/TF-3-graph.md","raw":"---\ntitle: TF-3--graph\ndate: 2016-12-01 19:20:49\ntags:\n---\n\n[Previous Chapter: Tensorflow Basics](2-basics.ipynb)\n<br>\n[Next Chapter: Summary and Tensorboard](4-summary.ipynb)\n\n## Graph\n\nA *Graph* in Tensorflow represents complicated computation dataflow consisting of *Tensors*.<br>\n\nA *Tensor* is a basic data structure in *Tensorflow*. There are several features of a *Tensor*.\n- Represents one of outputs of an *Operation*;\n- As a symbolic handle to one of the outputs of an *Operation*, *Tensor* provides a mean of computing the outputs in *Tensor*flow session instead of hold the real value;\n- A *Tensor* could also be fed as an input to another *Operation*, that enables Tensorflow to build a multi-step, complicated computation which is called a *Graph*;\n- After the *Graph* has been launched to a *Session*, the value of the *Tensor* can be computed by passing it to `Session.run()`;\n\n\n\n### Exercise: Build a Softmax Regression in Tensorflow\n\n#### Logistic Regression\n\n*Logistic Regression* applies a sigmoid function on linear combination to break the constant gradient.\nAs ranging between 0 and 1, sigmoid function is widely used in *Neural Network* for neural activation.\n\nA sigmoid function is defined as\n$\\large \\sigma(z) = {1 \\over 1 + e^{-z}}$,\nwhere\n$\\normalsize z = x^T * w + b$.\n\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/2000px-Logistic-curve.svg.png\" width=\"300\" align=\"left\"/>\n\n#### Softmax Regression\n\n*Logistic Regression* could properly deal with 2-class classification problem. While in machine-learned neural networks, *Softmax Regression* is more common used because of the capability of multiple-class classfiction. Generally, *Softmax Regression* is a special case of *Logistic Regression* and is designed for filling the vacancy on its disadvantages.\n\nA Softmax function is defined as:\n\n$\n\\sigma(z)_j = \\Large {{e^{z_j} \\over \\Sigma^k_{k=1} e^{z_k}}}\n$\n\nThe largest $\\sigma(z)_j$ is then chosen as the predicted class.\n\n#### Relationship between Logistic Regression and Softmax Regression\n\nLet's do some simple mathmatics.\n\nWhen k = 2,\n\n$\n\\begin{align*} \n\\sigma(z)\n&= \\normalsize{{1 \\over e^{z_1} + e^{z_2}} \\begin{bmatrix} e^{z_1} \\\\ e^{z_2} \\end{bmatrix}} \\\\\n&= \\large\\begin{bmatrix} {1 \\over 1 + e^{(z_2 - z_1)}} \\\\ {1 \\over 1 + e^{(z_1 - z_2)}}\\end{bmatrix} \\\\\n&= \\large\\begin{bmatrix} {1 \\over 1 + e^{(z_2 - z_1)}} \\\\ 1 - {1 \\over 1 + e^{(z_2 - z_1)}}\\end{bmatrix}\n\\end{align*}\n$\n\n\nAssume $Z = z_1 - z_2$, one of the $\\sigma(z_1) = \\large{1 \\over 1 + e^{-Z}}$ while the other one $\\sigma(z_1) = 1 - \\large{1 \\over 1 + e^{-Z}}$, which proves the function is consitent with *Logistic Regression*.\n\n##### Now try to build a Softmax Regression in Tensorflow yourself. See [*Linear Regression sample*](../TF-Learn.ipynb#samplecode) for reference.\n\n#### Necessary Headers\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n```\n\n#### MNIST data\n\n\n```python\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n```\n\n#### Training Parameters\n\n\n```python\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 1\n```\n\n#### Inputs\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, [None, 784]) # MNIST data image are of shape 28*28\ny = tf.placeholder(tf.float32, [None, 10]) # MNIST data has 10 classes\n```\n\n#### Variables\n\n\n```python\n## variables\n\n# initialize random uniform distributed weights with size of [784, 10] ranging from -1 to 1\nW = tf.Variables(tf.random_uniform([784,10], -1.0, 1.0)) ###### write your code here ######\n\n# initialize bias with size of [10] to zero\nb = tf.Variables(tf.zeros([10])) ###### write your code here ######\n```\n\n#### Graph\n\n\n```python\n## graph\n\n# comb = W * x + b (using a similar tensorflow function)\ncomb = ... ###### write your code here ######\n\n# predicted value\npred = tf.nn.softmax(comb)\n\n# entr equals to **negative** `tf.reduce_sum()` of y * log(pred), with reduction_indices = 1\nentr = ... ###### write your code here ######\n\n# cross entropy cost\ncost = tf.reduce_mean(entr)\n\n# optimizer\nopti = tf.train.GradientDescentOptimizer(learning_rate)\n\n# training_steps use optimizer to minimize the cost\ntraining_steps = ... ###### write your code here ######\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # training epochs\n    for epoch in range(training_epochs):\n\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        # split the data into different batches and run\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # run training steps and cost both in session, which should be fed `x = batch_xs` and `y = batch_ys`\n            _, cur_cost = ... ###### write your code here ######\n\n            avg_cost += cur_cost / total_batch\n\n        # show the average cost\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n\n    # accuracy\n    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n```\n\n[Previous Chapter: Tensorflow Basics](2-basics.ipynb)\n<br>\n[Next Chapter: Summary and Tensorboard](4-summary.ipynb)\n\n","slug":"TF-3-graph","published":1,"updated":"2016-12-01T11:21:24.767Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6beda40005lf8hoc6miwyi"},{"title":"TF-4-summary","date":"2016-12-01T11:37:00.000Z","_content":"\n[Previous Chapter: Graph](3-graph.ipynb)\n<br>\n[Next Chapter: Neural Network](5-ann.ipynb)\n\n## Summary\n\nTo visualize the result of a graph, *Tensorflow* introduces *summary*, which could be collected and viewed in *Tensorboard*.\n\n<img src=\"https://www.tensorflow.org/versions/r0.11/images/graph_vis_animation.gif\" width=\"800\" align=\"left\"/>\n\n\n#### Import the previous softmax model\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 5\n```\n\n#### Graph\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\ny = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n# reshaped input image\nx_reshaped = tf.reshape(x, [-1, 28, 28, 1])\n\n## variables\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n## graph\npred = tf.nn.softmax(tf.matmul(x,W) + b)\ncost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1]))\ntraining_steps = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n## accuracy\ntp = tf.equal(tf.argmax(y,1), tf.argmax(pred,1))\naccuracy = tf.reduce_mean(tf.cast(tp, tf.float32))\n```\n\n#### Summary Operations\n- tf.scalar_summary()\n- tf.histogram_summary()\n- tf.image_summary()\n- tf.audio_summary()\n\n### Exercise: Life Cycle of Summay\n- Create the TensorFlow graph that you'd like to collect summary data from, and decide which nodes you would like to annotate with summary operations;\n\n\n```python\n## summaries\n\n# image summary\ntf.image_summary('input', x_reshaped, 10)\n\n# histogram summary\n# create two histogram summaries here, summarizing `W` and `b`\ntf.histogram_summary('weight', W)\ntf.histogram_summary('bias', b)\n###### write your code here ######\n###### write your code here ######\n\n# scalar summary\n# create two scalar summaries here, summarizing `cost` and `accuracy`\ntf.scalar_summary('cost', cost)\ntf.scalar_summary('accuarcy', accuracy)\n###### write your code here ######\n###### write your code here ######\n```\n\n- Operations in TensorFlow don't do anything until you run them, neither do summaries. So use `tf.merge_summary` or `tf.merge_all_summaries` to combine them into a single op that generates all the summary data;\n\n\n```python\n# use `tf.merge_all_summaries()` to register the summaries\nmerged = tf.merge_all_summaries() ###### write your code here ######\n```\n\n- Create a `tf.train.SummaryWriter`;\n\n\n```python\n# summary writer\nwriter = tf.train.SummaryWriter('/root/tensorflow/summaries/softmax', graph = tf.get_default_graph())\n```\n\n- Run the merged summary op in your Session, then pass the summary protobuf to your `tf.train.SummaryWriter`;\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n\n    # training epochs\n    for epoch in range(training_epochs):\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            _, cur_cost, summary = sess.run([training_steps, cost, merged], feed_dict={x: batch_xs, y: batch_ys})\n            avg_cost += cur_cost / total_batch\n\n            # write your summaries\n            writer.add_summary(summary, epoch * total_batch + i)\n\n        # show the average cost and add summary\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n    print(\"Accuracy:\", sess.run(accuracy, {x: mnist.test.images, y: mnist.test.labels}))\n```\n\n- Close your writer;\n\n\n```python\nwriter.close()\n```\n\n#### Visualization\nNow head to http://172.16.3.227:6006 !\n\n#### Why my graph looks so messy?\nTry to use `tf.name_scope()` wrapping your graph and re-run the **Life Cycle**.\n\n\n```python\n## reset the graph\ntf.reset_default_graph()\n\n## inputs\nwith tf.name_scope('inputs'):\n    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n    x_reshaped = tf.reshape(x, [-1, 28, 28, 1])\n\n## weights\nwith tf.name_scope('weights'):\n    W = tf.Variable(tf.zeros([784, 10]))\n\n## biases\nwith tf.name_scope('biases'):\n    b = tf.Variable(tf.zeros([10]))\n\n## softmax\nwith tf.name_scope('softmax'):\n    pred = tf.nn.softmax(tf.matmul(x,W) + b)\n    ###### write your code here ######\n\n## graph\nwith tf.name_scope('cost'):\n    cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1]))\n    ###### write your code here ######\n\n# specify optimizer\nwith tf.name_scope('train'):\n    training_steps = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n    ###### write your code here ######\n\n## accuracy\nwith tf.name_scope('Accuracy'):\n\n    tp = tf.equal(tf.argmax(y,1), tf.argmax(pred,1))\n    accuracy = tf.reduce_mean(tf.cast(tp, tf.float32))\n\n    ###### write your code here ######\n    ###### write your code here ######\n```\n\n[Previous Chapter: Graph](3-graph.ipynb)\n<br>\n[Next Chapter: Neural Network](5-ann.ipynb)\n\n","source":"_posts/TF-4-summary.md","raw":"---\ntitle: TF-4-summary\ndate: 2016-12-01 19:37:00\ntags:\n---\n\n[Previous Chapter: Graph](3-graph.ipynb)\n<br>\n[Next Chapter: Neural Network](5-ann.ipynb)\n\n## Summary\n\nTo visualize the result of a graph, *Tensorflow* introduces *summary*, which could be collected and viewed in *Tensorboard*.\n\n<img src=\"https://www.tensorflow.org/versions/r0.11/images/graph_vis_animation.gif\" width=\"800\" align=\"left\"/>\n\n\n#### Import the previous softmax model\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 25\nbatch_size = 100\ndisplay_step = 5\n```\n\n#### Graph\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\ny = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n# reshaped input image\nx_reshaped = tf.reshape(x, [-1, 28, 28, 1])\n\n## variables\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n## graph\npred = tf.nn.softmax(tf.matmul(x,W) + b)\ncost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1]))\ntraining_steps = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n\n## accuracy\ntp = tf.equal(tf.argmax(y,1), tf.argmax(pred,1))\naccuracy = tf.reduce_mean(tf.cast(tp, tf.float32))\n```\n\n#### Summary Operations\n- tf.scalar_summary()\n- tf.histogram_summary()\n- tf.image_summary()\n- tf.audio_summary()\n\n### Exercise: Life Cycle of Summay\n- Create the TensorFlow graph that you'd like to collect summary data from, and decide which nodes you would like to annotate with summary operations;\n\n\n```python\n## summaries\n\n# image summary\ntf.image_summary('input', x_reshaped, 10)\n\n# histogram summary\n# create two histogram summaries here, summarizing `W` and `b`\ntf.histogram_summary('weight', W)\ntf.histogram_summary('bias', b)\n###### write your code here ######\n###### write your code here ######\n\n# scalar summary\n# create two scalar summaries here, summarizing `cost` and `accuracy`\ntf.scalar_summary('cost', cost)\ntf.scalar_summary('accuarcy', accuracy)\n###### write your code here ######\n###### write your code here ######\n```\n\n- Operations in TensorFlow don't do anything until you run them, neither do summaries. So use `tf.merge_summary` or `tf.merge_all_summaries` to combine them into a single op that generates all the summary data;\n\n\n```python\n# use `tf.merge_all_summaries()` to register the summaries\nmerged = tf.merge_all_summaries() ###### write your code here ######\n```\n\n- Create a `tf.train.SummaryWriter`;\n\n\n```python\n# summary writer\nwriter = tf.train.SummaryWriter('/root/tensorflow/summaries/softmax', graph = tf.get_default_graph())\n```\n\n- Run the merged summary op in your Session, then pass the summary protobuf to your `tf.train.SummaryWriter`;\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n\n    # training epochs\n    for epoch in range(training_epochs):\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            _, cur_cost, summary = sess.run([training_steps, cost, merged], feed_dict={x: batch_xs, y: batch_ys})\n            avg_cost += cur_cost / total_batch\n\n            # write your summaries\n            writer.add_summary(summary, epoch * total_batch + i)\n\n        # show the average cost and add summary\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n    print(\"Accuracy:\", sess.run(accuracy, {x: mnist.test.images, y: mnist.test.labels}))\n```\n\n- Close your writer;\n\n\n```python\nwriter.close()\n```\n\n#### Visualization\nNow head to http://172.16.3.227:6006 !\n\n#### Why my graph looks so messy?\nTry to use `tf.name_scope()` wrapping your graph and re-run the **Life Cycle**.\n\n\n```python\n## reset the graph\ntf.reset_default_graph()\n\n## inputs\nwith tf.name_scope('inputs'):\n    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n    x_reshaped = tf.reshape(x, [-1, 28, 28, 1])\n\n## weights\nwith tf.name_scope('weights'):\n    W = tf.Variable(tf.zeros([784, 10]))\n\n## biases\nwith tf.name_scope('biases'):\n    b = tf.Variable(tf.zeros([10]))\n\n## softmax\nwith tf.name_scope('softmax'):\n    pred = tf.nn.softmax(tf.matmul(x,W) + b)\n    ###### write your code here ######\n\n## graph\nwith tf.name_scope('cost'):\n    cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1]))\n    ###### write your code here ######\n\n# specify optimizer\nwith tf.name_scope('train'):\n    training_steps = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n    ###### write your code here ######\n\n## accuracy\nwith tf.name_scope('Accuracy'):\n\n    tp = tf.equal(tf.argmax(y,1), tf.argmax(pred,1))\n    accuracy = tf.reduce_mean(tf.cast(tp, tf.float32))\n\n    ###### write your code here ######\n    ###### write your code here ######\n```\n\n[Previous Chapter: Graph](3-graph.ipynb)\n<br>\n[Next Chapter: Neural Network](5-ann.ipynb)\n\n","slug":"TF-4-summary","published":1,"updated":"2016-12-01T11:37:40.455Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6beda80006lf8hj1uafw1w"},{"title":"TF-5-ann","date":"2016-12-01T11:37:53.000Z","_content":"\n[Previous Chapter: Summary and Tensorboard](4-summary.ipynb)\n<br>\n[Next Chapter: AutoEncoder](6-autoencoder.ipynb)\n\n## Neural Network\n\nHere is an exercise of building a *Neural Network* using *Tensorflow*.\n\nFollowing note of *Neural Network* is quoted from [here](https://github.com/xzry6/notes/blob/master/transwarp/ann.md).\n\n### Note: 人工神经网络\n**人工神经网络**是受到了生物学上动物的中枢神经系统的启发而开发出来的一种计算模型。\n**人工神经网络**最早于20世纪40年代提出，但由于庞大的神经网络和当时计算能力的局限，神经网络的研究一直停滞不前。\n直到20世纪80年代**分散式并行处理**的流行和由*Paul Werbos*创造的反向传播算法，神经网络渐渐又开始流行起来。并于21世纪开始同**深度学习**一起成为机器学习领域的热点。\n\n#### 结构\n结构上，人工神经网络由一个*输入可见层*，多个*隐藏层*和一个*分类输出层*组成。每一层由不同数目的*神经单元*组成, 前后两层之间的*weight*和*bias*组成了整个模型。\n人工神经网络模拟了人脑神经元传递的过程，每一层的神经元都对应着通过观察而解析出的不同程度的特征。可以用一个简单的例子来理解人工神经网络的结构。\n当我们观察一辆车的时候，我们首先观察到的可能是“车高”，“车宽”，“四门”，“四驱”， “疝气大灯”等一系列可见特征，对应了神经网络的可见层。之后神经网络通过可见特征对隐藏特征进行解析，于是在第一个隐藏层中我们得到了我们未观察到的信息“奥迪”，“SUV”。之后逐层解析，通过第一个隐藏层特征，我们在第二个隐藏层可能会得到“Q7”这样的特征，神经网络在不同的隐藏层会解析出不同程度的隐藏特征。当得到了这些比可见特征更加具象并且有意义的特征后，位于神经网络顶层的分类器会更加容易判断出“开车人的职业”。\n\n<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" width=\"440\">\n\n在上图中，我们可以看到输入层有三个神经元，第一和第二隐藏层分别含有四个神经元，最后输出一个神经元。同一层的神经元相互之间没有连接，代表了同一层之间的特征相互独立。相邻两层的神经元相互连接，由直线表示，被成为*weights(权重)*。每一个神经元由**所有**上一层的*神经元*和*权重*计算得出，所以只有计算出同一层所有神经元的值后，才能继续向前传递。\n\n\n#### 人工神经网络的训练\n人工神经网络的训练可以分为两个部分，*前向传播*和*反向传播*。*前向传播*负责逐层传递并激活神经元，并于最后分类层预测结果。*反向传播*通过计算顶层预测结果和实际结果的误差，将误差逐层传递回模型，使用梯度下降或其它方式更新模型权重。<br><br>\n接下去我们会分开对*前向传播*和*反向传播*进行介绍。\n\n##### 前向传播\n对人工神经网络进行训练时，我们首先把输入放入输入可见层，*喂*进神经网络。上文已经说过，由于每一个神经元与上一层所有神经元有联系，所以人工神经网络的传递方式是**逐层**传递的。传递过程在生物意义上意味着**激活**，所以传递时用到的函数被称作激活函数。\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Network331.png\" width=\"440\">\n\n##### 组合函数\n在把参数传递进激活函数前，首先将上一层的神经元和相关权重进行组合，再加上偏置。这样的组合函数表示每一层的神经单元由上一层的单元和权重生成.\n\n传递函数: $p(x_j^n) = \\sigma(\\Sigma_i w_{ij}^{{n-1}n}x_i^{n-1})$\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/SingleNeuron.png\" width=\"240\">\n\n上述公式中，$p(x_j^n)$表示第n层第j个神经元被激活的概率，${x_i^{n-1}}$表示第(n-1)层第i个神经元的值，$w_{ij}^{{n-1}n}$表示第(n-1)层的第i个神经元与第n层第j个神经元之间的连线权重，(n-1)层最后一个神经元+1指的是n层第j个结点的权重。\n\n#### 激活函数\n当前一层神经元和对应权重进行组合后，我们可以直接把得到的值当作当前单元的激活函数，可是由于是简单的线性函数，所以容易造成值过大和过小的两极化分布。为此，研究者们引入了一些**激活函数**来改善分布，更好地*激活*神经元。\n\n- Sigmoid: $\\sigma(z) = \\large{1 \\over 1 + e^{-z}}$\n\n\n- Tanh: $\\sigma(z) = \\large{sinh(z) \\over cosh(z)} = {{e^z - e^{-z}} \\over {e^z + e^{-z}}}$\n\n\n- ReLU: $\\sigma(z) = max(0, z)$\n\nsigmoid和tanh由于有各自的区间（sigmoid: (0, 1)，tanh: (-1, 1)），能很好的把激活值限制在这些区间内，稳定的区间同时也说明神经元之间的权重会更加稳定。但是，这两个函数在极限值造成平滑的梯度，会丢失一部分的信息。relu函数可以保留着一部分梯度，同时$max(0, z)$也会稀疏出现的negative值。\n\n### 反向传播\n反向传播是神经网络更新权重的过程，因为多层的结构，当进行迭代更新的时候，输出层产生的error会反向传遍整个网络，每一层的权重会根据误差进行更新。和一般分类器一样，神经网络顶层的误差就是分类器的误差，即预测值和实际值的误差。之后，同前向传播一样，每前一层的神经元的误差由后一层的所有神经元和误差计算得出，反向逐层传递。当误差传到底层，即所有误差都被计算出后，我们再次*前向*传播更新权重。\n\n<img src=\"http://i.stack.imgur.com/H1KsG.png\" width=\"440\">\n\n- 输出层的error就是分类器的error: $\\delta_i^n = \\sigma_i^n - y_i$\n- 前一层的error由后一层的error产生: $\\delta_i^n = \\Sigma_j w_{ij}^{n+1} \\delta_j^{n+1}$\n- 更新权重使用梯度下降: $\\Delta w_{ij} = -\\gamma \\sigma_i^n \\delta_j^{n+1}$\n\n### Exercise: Neural Network\nIn this exercise, our neural network will have 2 hidden layer with user defined units and one linear regression output layer.\n\n#### Same as previous chapter\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\ndisplay_step = 1\n\n## inputs\nx = tf.placeholder(tf.float32, [None, 784])\ny = tf.placeholder(tf.float32, [None, 10])\n```\n\n#### Hidden Layers\n\n\n```python\n## hidden layer number of features\n# define any number of features to this two hidden layers\nn_hidden_1 = ... ###### write your code here ######\nn_hidden_2 = ... ###### write your code here ######\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {\n    'w1': tf.Variable(tf.random_normal([784, n_hidden_1])),\n    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'output': tf.Variable(tf.random_normal([n_hidden_2, 10]))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'output': tf.Variable(tf.random_normal([10]))\n}\n```\n\n#### Define a deep graph function\n\n\n```python\n## graph\ndef multilayer_perceptron(x, weights, biases):\n    # hidden layer 1\n    comb_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n    # layer_1 is activated using `tf.nn.relu()`\n    h_1 = ... ###### write your code here ######\n    \n    # hidden layer 2\n    comb_2 = tf.add(tf.matmul(h_1, weights['w2']), biases['b2'])\n    # layer_2 is activated using `tf.nn.relu()`\n    h_2 = ... ###### write your code here ######\n    \n    # output is just a linear combination function with `h_2 * w[output] + b[output]`\n    output = ... ###### write your code here ######\n\n    return output\n```\n\n#### Training Steps\n\n\n```python\n# predicted value\npred = multilayer_perceptron(x, weights, biases)\n\n# define your cost here, use `tf.nn.softmax_cross_entropy_with_logits(pred, y)` to calculate entropy here\ncost = ... ###### write your code here ######\n\n# define your optimizer here, we use a `tf.train.AdamOptimizer()` here\noptimizer = ... ###### write your code here ######\n\n# training steps\ntraining_steps = optimizer.minimize(cost)\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # training epochs\n    for epoch in range(training_epochs):\n\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        # split the data into different batches and run\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            _, cur_cost = sess.run([training_steps, cost],\n                            feed_dict={x: batch_xs, y: batch_ys})\n\n            avg_cost += cur_cost / total_batch\n\n        # show the average cost\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy\n    # use `tf.equal()` and `tf.argmax()` to get correction prediction\n    correct_prediction = ... ###### write your code here ######\n    # use `tf.reduce_mean` to get accuracy here\n    accuracy = ... ###### write your code here\n    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n```\n\n[Previous Chapter: Summary and Tensorboard](4-summary.ipynb)\n<br>\n[Next Chapter: AutoEncoder](6-autoencoder.ipynb)\n\n","source":"_posts/TF-5-ann.md","raw":"---\ntitle: TF-5-ann\ndate: 2016-12-01 19:37:53\ntags:\n---\n\n[Previous Chapter: Summary and Tensorboard](4-summary.ipynb)\n<br>\n[Next Chapter: AutoEncoder](6-autoencoder.ipynb)\n\n## Neural Network\n\nHere is an exercise of building a *Neural Network* using *Tensorflow*.\n\nFollowing note of *Neural Network* is quoted from [here](https://github.com/xzry6/notes/blob/master/transwarp/ann.md).\n\n### Note: 人工神经网络\n**人工神经网络**是受到了生物学上动物的中枢神经系统的启发而开发出来的一种计算模型。\n**人工神经网络**最早于20世纪40年代提出，但由于庞大的神经网络和当时计算能力的局限，神经网络的研究一直停滞不前。\n直到20世纪80年代**分散式并行处理**的流行和由*Paul Werbos*创造的反向传播算法，神经网络渐渐又开始流行起来。并于21世纪开始同**深度学习**一起成为机器学习领域的热点。\n\n#### 结构\n结构上，人工神经网络由一个*输入可见层*，多个*隐藏层*和一个*分类输出层*组成。每一层由不同数目的*神经单元*组成, 前后两层之间的*weight*和*bias*组成了整个模型。\n人工神经网络模拟了人脑神经元传递的过程，每一层的神经元都对应着通过观察而解析出的不同程度的特征。可以用一个简单的例子来理解人工神经网络的结构。\n当我们观察一辆车的时候，我们首先观察到的可能是“车高”，“车宽”，“四门”，“四驱”， “疝气大灯”等一系列可见特征，对应了神经网络的可见层。之后神经网络通过可见特征对隐藏特征进行解析，于是在第一个隐藏层中我们得到了我们未观察到的信息“奥迪”，“SUV”。之后逐层解析，通过第一个隐藏层特征，我们在第二个隐藏层可能会得到“Q7”这样的特征，神经网络在不同的隐藏层会解析出不同程度的隐藏特征。当得到了这些比可见特征更加具象并且有意义的特征后，位于神经网络顶层的分类器会更加容易判断出“开车人的职业”。\n\n<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" width=\"440\">\n\n在上图中，我们可以看到输入层有三个神经元，第一和第二隐藏层分别含有四个神经元，最后输出一个神经元。同一层的神经元相互之间没有连接，代表了同一层之间的特征相互独立。相邻两层的神经元相互连接，由直线表示，被成为*weights(权重)*。每一个神经元由**所有**上一层的*神经元*和*权重*计算得出，所以只有计算出同一层所有神经元的值后，才能继续向前传递。\n\n\n#### 人工神经网络的训练\n人工神经网络的训练可以分为两个部分，*前向传播*和*反向传播*。*前向传播*负责逐层传递并激活神经元，并于最后分类层预测结果。*反向传播*通过计算顶层预测结果和实际结果的误差，将误差逐层传递回模型，使用梯度下降或其它方式更新模型权重。<br><br>\n接下去我们会分开对*前向传播*和*反向传播*进行介绍。\n\n##### 前向传播\n对人工神经网络进行训练时，我们首先把输入放入输入可见层，*喂*进神经网络。上文已经说过，由于每一个神经元与上一层所有神经元有联系，所以人工神经网络的传递方式是**逐层**传递的。传递过程在生物意义上意味着**激活**，所以传递时用到的函数被称作激活函数。\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Network331.png\" width=\"440\">\n\n##### 组合函数\n在把参数传递进激活函数前，首先将上一层的神经元和相关权重进行组合，再加上偏置。这样的组合函数表示每一层的神经单元由上一层的单元和权重生成.\n\n传递函数: $p(x_j^n) = \\sigma(\\Sigma_i w_{ij}^{{n-1}n}x_i^{n-1})$\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/SingleNeuron.png\" width=\"240\">\n\n上述公式中，$p(x_j^n)$表示第n层第j个神经元被激活的概率，${x_i^{n-1}}$表示第(n-1)层第i个神经元的值，$w_{ij}^{{n-1}n}$表示第(n-1)层的第i个神经元与第n层第j个神经元之间的连线权重，(n-1)层最后一个神经元+1指的是n层第j个结点的权重。\n\n#### 激活函数\n当前一层神经元和对应权重进行组合后，我们可以直接把得到的值当作当前单元的激活函数，可是由于是简单的线性函数，所以容易造成值过大和过小的两极化分布。为此，研究者们引入了一些**激活函数**来改善分布，更好地*激活*神经元。\n\n- Sigmoid: $\\sigma(z) = \\large{1 \\over 1 + e^{-z}}$\n\n\n- Tanh: $\\sigma(z) = \\large{sinh(z) \\over cosh(z)} = {{e^z - e^{-z}} \\over {e^z + e^{-z}}}$\n\n\n- ReLU: $\\sigma(z) = max(0, z)$\n\nsigmoid和tanh由于有各自的区间（sigmoid: (0, 1)，tanh: (-1, 1)），能很好的把激活值限制在这些区间内，稳定的区间同时也说明神经元之间的权重会更加稳定。但是，这两个函数在极限值造成平滑的梯度，会丢失一部分的信息。relu函数可以保留着一部分梯度，同时$max(0, z)$也会稀疏出现的negative值。\n\n### 反向传播\n反向传播是神经网络更新权重的过程，因为多层的结构，当进行迭代更新的时候，输出层产生的error会反向传遍整个网络，每一层的权重会根据误差进行更新。和一般分类器一样，神经网络顶层的误差就是分类器的误差，即预测值和实际值的误差。之后，同前向传播一样，每前一层的神经元的误差由后一层的所有神经元和误差计算得出，反向逐层传递。当误差传到底层，即所有误差都被计算出后，我们再次*前向*传播更新权重。\n\n<img src=\"http://i.stack.imgur.com/H1KsG.png\" width=\"440\">\n\n- 输出层的error就是分类器的error: $\\delta_i^n = \\sigma_i^n - y_i$\n- 前一层的error由后一层的error产生: $\\delta_i^n = \\Sigma_j w_{ij}^{n+1} \\delta_j^{n+1}$\n- 更新权重使用梯度下降: $\\Delta w_{ij} = -\\gamma \\sigma_i^n \\delta_j^{n+1}$\n\n### Exercise: Neural Network\nIn this exercise, our neural network will have 2 hidden layer with user defined units and one linear regression output layer.\n\n#### Same as previous chapter\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100\ndisplay_step = 1\n\n## inputs\nx = tf.placeholder(tf.float32, [None, 784])\ny = tf.placeholder(tf.float32, [None, 10])\n```\n\n#### Hidden Layers\n\n\n```python\n## hidden layer number of features\n# define any number of features to this two hidden layers\nn_hidden_1 = ... ###### write your code here ######\nn_hidden_2 = ... ###### write your code here ######\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {\n    'w1': tf.Variable(tf.random_normal([784, n_hidden_1])),\n    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'output': tf.Variable(tf.random_normal([n_hidden_2, 10]))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'output': tf.Variable(tf.random_normal([10]))\n}\n```\n\n#### Define a deep graph function\n\n\n```python\n## graph\ndef multilayer_perceptron(x, weights, biases):\n    # hidden layer 1\n    comb_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n    # layer_1 is activated using `tf.nn.relu()`\n    h_1 = ... ###### write your code here ######\n    \n    # hidden layer 2\n    comb_2 = tf.add(tf.matmul(h_1, weights['w2']), biases['b2'])\n    # layer_2 is activated using `tf.nn.relu()`\n    h_2 = ... ###### write your code here ######\n    \n    # output is just a linear combination function with `h_2 * w[output] + b[output]`\n    output = ... ###### write your code here ######\n\n    return output\n```\n\n#### Training Steps\n\n\n```python\n# predicted value\npred = multilayer_perceptron(x, weights, biases)\n\n# define your cost here, use `tf.nn.softmax_cross_entropy_with_logits(pred, y)` to calculate entropy here\ncost = ... ###### write your code here ######\n\n# define your optimizer here, we use a `tf.train.AdamOptimizer()` here\noptimizer = ... ###### write your code here ######\n\n# training steps\ntraining_steps = optimizer.minimize(cost)\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # training epochs\n    for epoch in range(training_epochs):\n\n        avg_cost = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n\n        # split the data into different batches and run\n        for i in range(total_batch):\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            _, cur_cost = sess.run([training_steps, cost],\n                            feed_dict={x: batch_xs, y: batch_ys})\n\n            avg_cost += cur_cost / total_batch\n\n        # show the average cost\n        if (epoch+1) % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy\n    # use `tf.equal()` and `tf.argmax()` to get correction prediction\n    correct_prediction = ... ###### write your code here ######\n    # use `tf.reduce_mean` to get accuracy here\n    accuracy = ... ###### write your code here\n    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n```\n\n[Previous Chapter: Summary and Tensorboard](4-summary.ipynb)\n<br>\n[Next Chapter: AutoEncoder](6-autoencoder.ipynb)\n\n","slug":"TF-5-ann","published":1,"updated":"2016-12-01T12:02:19.891Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedaf0008lf8hgt0at4pk"},{"title":"TF-6-autoencoder","date":"2016-12-01T11:46:18.000Z","_content":"\n[Previous Chapter: Neural Network](5-ann.ipynb)\n<br>\n[Next Chapter: Convolutional Neural Network](7-cnn.ipynb)\n\n## AutoEncoder\n\nAn **Autoencoder** is a deep learning algorithm which has two parts, <span style=\"color: #F08080\">*encoder*</span> and <span style=\"color: #F08080\">*decoder*</span>. An *autoencoder* is very similar to an *artificial neural network* other than <span style=\"color: #F08080\">using inputs as output labels to optimize the parameters</span>, which makes it quite like an unsupervised model. Well, it is **NOT￼** though.\n\n![](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n\nThe following explanation of *Autoencoder* is quoted from [Keras](https://blog.keras.io/building-autoencoders-in-keras.html).\n\nThe **encoder** and **decoder** in Autoencoder are <span style=\"color: #F08080\">1) data-specific</span>, <span style=\"color: #F08080\">2) lossy</span>, and <span style=\"color: #F08080\">3) learned automatically from examples rather than engineered by a human</span>. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n\n1. Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. This is different from, say, the MPEG-2 Audio Layer III (MP3) compression algorithm, which only holds assumptions about \"sound\" in general, but not about specific types of sounds. An autoencoder trained on pictures of faces would do a rather poor job of compressing pictures of trees, because the features it would learn would be face-specific.\n\n2. Autoencoders are lossy, which means that the decompressed outputs will be degraded compared to the original inputs (similar to MP3 or JPEG compression). This differs from lossless arithmetic compression.\n\n3. Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn't require any new engineering, just appropriate training data.\n\nTo build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation (i.e. a \"loss\" function). The encoder and decoder will be chosen to be parametric functions (typically neural networks), and to be differentiable with respect to the distance function, so the parameters of the encoding/decoding functions can be optimize to minimize the reconstruction loss, using Stochastic Gradient Descent. It's simple! And you don't even need to understand any of these words to start using autoencoders in practice.\n\n\n#### Are they good at data compression?\n\n<span style=\"color: #F08080\">Usually, not really.</span> In picture compression for instance, it is pretty difficult to train an autoencoder that does a better job than a basic algorithm like JPEG, and typically the only way it can be achieved is by restricting yourself to a very specific type of picture (e.g. one for which JPEG does not do a good job). The fact that autoencoders are data-specific makes them generally impractical for real-world data compression problems: you can only use them on data that is similar to what they were trained on, and making them more general thus requires lots of training data. But future advances might change this, who knows.\n\n#### What are autoencoders good for?\n\nThey are rarely used in practical applications. In 2012 they briefly found an application in [greedy layer-wise pretraining for deep convolutional neural networks](http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf), but this quickly fell out of fashion as we started realizing that better random weight initialization schemes were sufficient for training deep networks from scratch. In 2014, [batch normalization](https://arxiv.org/abs/1502.03167) started allowing for even deeper networks, and from late 2015 we could train [arbitrarily deep networks from scratch using residual learning](https://arxiv.org/abs/1512.03385).\n\nToday two interesting practical applications of autoencoders are <span style=\"color: #F08080\">**data denoising**</span> (which we feature later in this post), and <span style=\"color: #F08080\">**dimensionality reduction for data visualization**</span>. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n\nFor 2D visualization specifically, t-SNE (pronounced \"tee-snee\") is probably the best algorithm around, but it typically requires relatively low-dimensional data. So a good strategy for visualizing similarity relationships in high-dimensional data is to start by using an autoencoder to compress your data into a low-dimensional space (e.g. 32 dimensional), then use t-SNE for mapping the compressed data to a 2D plane.\n\n#### So what's the big deal with autoencoders?\n\nTheir main claim to fame comes from being featured in many introductory machine learning classes available online. As a result, a lot of newcomers to the field absolutely love autoencoders and can't get enough of them. This is the reason why this tutorial exists!\n\nOtherwise, one reason why they have attracted so much research and attention is because they <span style=\"color: #F08080\">**have long been thought to be a potential avenue for solving the problem of unsupervised learning**</span>, i.e. the learning of useful representations without the need for labels. Then again, autoencoders are not a true unsupervised learning technique (which would imply a different learning process altogether), they are a <span style=\"color: #F08080\">**self-supervised technique**</span>, a specific instance of supervised learning where the targets are generated from the input data. In order to get self-supervised models to learn interesting features, you have to come up with an interesting synthetic target and loss function, and that's where problems arise: merely learning to reconstruct your input in minute detail might not be the right choice here. At this point there is significant evidence that focusing on the reconstruction of a picture at the pixel level, for instance, is not conductive to learning interesting, abstract features of the kind that label-supervized learning induces (where targets are fairly abstract concepts \"invented\" by humans such as \"dog\", \"car\"...). In fact, one may argue that the best features in this regard are those that are the worst at exact input reconstruction while achieving high performance on the main task that you are interested in (classification, localization, etc).\n\nIn self-supervized learning applied to vision, a potentially fruitful alternative to autoencoder-style input reconstruction is the use of toy tasks such as jigsaw puzzle solving, or detail-context matching (being able to match high-resolution but small patches of pictures with low-resolution versions of the pictures they are extracted from). The following paper investigates jigsaw puzzle solving and makes for a very interesting read: Noroozi and Favaro (2016) Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles. Such tasks are providing the model with built-in assumptions about the input data which are missing in traditional autoencoders, such as \"visual macro-structure matters more than pixel-level details\".\n\n![](https://blog.keras.io/img/ae/jigsaw-puzzle.png)\n\n### Let's begin with a common Autoencoder\n\n#### Prerequisite\nFirst we *import packages*, *read datasets* and *assign model parameters*.\n\n\n```python\n## matplotlib will be used to reconstruct the test \n%matplotlib notebook\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n## MNIST_data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('/root/tensorflow/MNIST_data', one_hot=True)\n\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 5\nbatch_size = 100\ndisplay_step = 1\ntesting_number = 5\n\n## number of hidden units\nh_0 = 784\nh_1 = 100\nh_2 = 10\n```\n\n#### Inputs and Variables\nMention that *labels* are not required here because an *autoencoder* uses inputs as output labels\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, [None, h_0])\n\n## variables\nw = {\n    'e_1': tf.Variable(tf.random_normal([h_0, h_1])),\n    'e_2': tf.Variable(tf.random_normal([h_1, h_2])),\n    'd_1': tf.Variable(tf.random_normal([h_2, h_1])),\n    'd_2': tf.Variable(tf.random_normal([h_1, h_0]))\n}\n\nb = {\n    'e_1': tf.Variable(tf.random_normal([h_1])),\n    'e_2': tf.Variable(tf.random_normal([h_2])),\n    'd_1': tf.Variable(tf.random_normal([h_1])),\n    'd_2': tf.Variable(tf.random_normal([h_0]))\n}\n```\n\n#### Graph\nDefine the graph and optimizer.\n\n\n```python\n## graph\ndef feed_forward(x, layer):\n    return tf.nn.sigmoid(tf.add(tf.matmul(x, w[layer]), b[layer]))\n\ne1 = feed_forward(x, 'e_1')\ne2 = feed_forward(e1, 'e_2')\nd1 = feed_forward(e2, 'd_1')\nd2 = feed_forward(d1, 'd_2')\n\nmean_err = tf.reduce_mean(tf.pow(d2 - x, 2))\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(mean_err)\n```\n\n#### Start a Session\nHere we use *[matplotlib](http://matplotlib.org/)* to reconstruct the image.\n\n\n```python\n## start a session\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    \n    # train\n    for epoch in range(training_epochs):\n        avg_err = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n        \n        for batch in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            _, err = sess.run([optimizer, mean_err], feed_dict={x: batch_x})\n            avg_err += err / total_batch\n\n        if (epoch + 1) % display_step == 0:\n            print('step: %d, average mean error is %f' % (epoch + 1, avg_err))\n    \n    print('optimization finished')\n\n    # test\n    encode_decode = sess.run(d2, feed_dict={x: mnist.test.images[:testing_number]})\n    \n    # visualize\n    f, a = plt.subplots(testing_number, 2, figsize=(5, 8))\n    for i in range(testing_number):\n        a[i][0].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n        a[i][1].imshow(np.reshape(encode_decode[i], (28, 28)))\n            \n```\n\n[Previous Chapter: Neural Network](5-ann.ipynb)\n<br>\n[Next Chapter: Convolutional Neural Network](7-cnn.ipynb)\n\n","source":"_posts/TF-6-autoencoder.md","raw":"---\ntitle: TF-6-autoencoder\ndate: 2016-12-01 19:46:18\ntags:\n---\n\n[Previous Chapter: Neural Network](5-ann.ipynb)\n<br>\n[Next Chapter: Convolutional Neural Network](7-cnn.ipynb)\n\n## AutoEncoder\n\nAn **Autoencoder** is a deep learning algorithm which has two parts, <span style=\"color: #F08080\">*encoder*</span> and <span style=\"color: #F08080\">*decoder*</span>. An *autoencoder* is very similar to an *artificial neural network* other than <span style=\"color: #F08080\">using inputs as output labels to optimize the parameters</span>, which makes it quite like an unsupervised model. Well, it is **NOT￼** though.\n\n![](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n\nThe following explanation of *Autoencoder* is quoted from [Keras](https://blog.keras.io/building-autoencoders-in-keras.html).\n\nThe **encoder** and **decoder** in Autoencoder are <span style=\"color: #F08080\">1) data-specific</span>, <span style=\"color: #F08080\">2) lossy</span>, and <span style=\"color: #F08080\">3) learned automatically from examples rather than engineered by a human</span>. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n\n1. Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. This is different from, say, the MPEG-2 Audio Layer III (MP3) compression algorithm, which only holds assumptions about \"sound\" in general, but not about specific types of sounds. An autoencoder trained on pictures of faces would do a rather poor job of compressing pictures of trees, because the features it would learn would be face-specific.\n\n2. Autoencoders are lossy, which means that the decompressed outputs will be degraded compared to the original inputs (similar to MP3 or JPEG compression). This differs from lossless arithmetic compression.\n\n3. Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn't require any new engineering, just appropriate training data.\n\nTo build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation (i.e. a \"loss\" function). The encoder and decoder will be chosen to be parametric functions (typically neural networks), and to be differentiable with respect to the distance function, so the parameters of the encoding/decoding functions can be optimize to minimize the reconstruction loss, using Stochastic Gradient Descent. It's simple! And you don't even need to understand any of these words to start using autoencoders in practice.\n\n\n#### Are they good at data compression?\n\n<span style=\"color: #F08080\">Usually, not really.</span> In picture compression for instance, it is pretty difficult to train an autoencoder that does a better job than a basic algorithm like JPEG, and typically the only way it can be achieved is by restricting yourself to a very specific type of picture (e.g. one for which JPEG does not do a good job). The fact that autoencoders are data-specific makes them generally impractical for real-world data compression problems: you can only use them on data that is similar to what they were trained on, and making them more general thus requires lots of training data. But future advances might change this, who knows.\n\n#### What are autoencoders good for?\n\nThey are rarely used in practical applications. In 2012 they briefly found an application in [greedy layer-wise pretraining for deep convolutional neural networks](http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf), but this quickly fell out of fashion as we started realizing that better random weight initialization schemes were sufficient for training deep networks from scratch. In 2014, [batch normalization](https://arxiv.org/abs/1502.03167) started allowing for even deeper networks, and from late 2015 we could train [arbitrarily deep networks from scratch using residual learning](https://arxiv.org/abs/1512.03385).\n\nToday two interesting practical applications of autoencoders are <span style=\"color: #F08080\">**data denoising**</span> (which we feature later in this post), and <span style=\"color: #F08080\">**dimensionality reduction for data visualization**</span>. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n\nFor 2D visualization specifically, t-SNE (pronounced \"tee-snee\") is probably the best algorithm around, but it typically requires relatively low-dimensional data. So a good strategy for visualizing similarity relationships in high-dimensional data is to start by using an autoencoder to compress your data into a low-dimensional space (e.g. 32 dimensional), then use t-SNE for mapping the compressed data to a 2D plane.\n\n#### So what's the big deal with autoencoders?\n\nTheir main claim to fame comes from being featured in many introductory machine learning classes available online. As a result, a lot of newcomers to the field absolutely love autoencoders and can't get enough of them. This is the reason why this tutorial exists!\n\nOtherwise, one reason why they have attracted so much research and attention is because they <span style=\"color: #F08080\">**have long been thought to be a potential avenue for solving the problem of unsupervised learning**</span>, i.e. the learning of useful representations without the need for labels. Then again, autoencoders are not a true unsupervised learning technique (which would imply a different learning process altogether), they are a <span style=\"color: #F08080\">**self-supervised technique**</span>, a specific instance of supervised learning where the targets are generated from the input data. In order to get self-supervised models to learn interesting features, you have to come up with an interesting synthetic target and loss function, and that's where problems arise: merely learning to reconstruct your input in minute detail might not be the right choice here. At this point there is significant evidence that focusing on the reconstruction of a picture at the pixel level, for instance, is not conductive to learning interesting, abstract features of the kind that label-supervized learning induces (where targets are fairly abstract concepts \"invented\" by humans such as \"dog\", \"car\"...). In fact, one may argue that the best features in this regard are those that are the worst at exact input reconstruction while achieving high performance on the main task that you are interested in (classification, localization, etc).\n\nIn self-supervized learning applied to vision, a potentially fruitful alternative to autoencoder-style input reconstruction is the use of toy tasks such as jigsaw puzzle solving, or detail-context matching (being able to match high-resolution but small patches of pictures with low-resolution versions of the pictures they are extracted from). The following paper investigates jigsaw puzzle solving and makes for a very interesting read: Noroozi and Favaro (2016) Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles. Such tasks are providing the model with built-in assumptions about the input data which are missing in traditional autoencoders, such as \"visual macro-structure matters more than pixel-level details\".\n\n![](https://blog.keras.io/img/ae/jigsaw-puzzle.png)\n\n### Let's begin with a common Autoencoder\n\n#### Prerequisite\nFirst we *import packages*, *read datasets* and *assign model parameters*.\n\n\n```python\n## matplotlib will be used to reconstruct the test \n%matplotlib notebook\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n## MNIST_data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('/root/tensorflow/MNIST_data', one_hot=True)\n\n## parameters\nlearning_rate = 0.01\ntraining_epochs = 5\nbatch_size = 100\ndisplay_step = 1\ntesting_number = 5\n\n## number of hidden units\nh_0 = 784\nh_1 = 100\nh_2 = 10\n```\n\n#### Inputs and Variables\nMention that *labels* are not required here because an *autoencoder* uses inputs as output labels\n\n\n```python\n## inputs\nx = tf.placeholder(tf.float32, [None, h_0])\n\n## variables\nw = {\n    'e_1': tf.Variable(tf.random_normal([h_0, h_1])),\n    'e_2': tf.Variable(tf.random_normal([h_1, h_2])),\n    'd_1': tf.Variable(tf.random_normal([h_2, h_1])),\n    'd_2': tf.Variable(tf.random_normal([h_1, h_0]))\n}\n\nb = {\n    'e_1': tf.Variable(tf.random_normal([h_1])),\n    'e_2': tf.Variable(tf.random_normal([h_2])),\n    'd_1': tf.Variable(tf.random_normal([h_1])),\n    'd_2': tf.Variable(tf.random_normal([h_0]))\n}\n```\n\n#### Graph\nDefine the graph and optimizer.\n\n\n```python\n## graph\ndef feed_forward(x, layer):\n    return tf.nn.sigmoid(tf.add(tf.matmul(x, w[layer]), b[layer]))\n\ne1 = feed_forward(x, 'e_1')\ne2 = feed_forward(e1, 'e_2')\nd1 = feed_forward(e2, 'd_1')\nd2 = feed_forward(d1, 'd_2')\n\nmean_err = tf.reduce_mean(tf.pow(d2 - x, 2))\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(mean_err)\n```\n\n#### Start a Session\nHere we use *[matplotlib](http://matplotlib.org/)* to reconstruct the image.\n\n\n```python\n## start a session\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    \n    # train\n    for epoch in range(training_epochs):\n        avg_err = 0\n        total_batch = int(mnist.train.num_examples / batch_size)\n        \n        for batch in range(total_batch):\n            batch_x, batch_y = mnist.train.next_batch(batch_size)\n            _, err = sess.run([optimizer, mean_err], feed_dict={x: batch_x})\n            avg_err += err / total_batch\n\n        if (epoch + 1) % display_step == 0:\n            print('step: %d, average mean error is %f' % (epoch + 1, avg_err))\n    \n    print('optimization finished')\n\n    # test\n    encode_decode = sess.run(d2, feed_dict={x: mnist.test.images[:testing_number]})\n    \n    # visualize\n    f, a = plt.subplots(testing_number, 2, figsize=(5, 8))\n    for i in range(testing_number):\n        a[i][0].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n        a[i][1].imshow(np.reshape(encode_decode[i], (28, 28)))\n            \n```\n\n[Previous Chapter: Neural Network](5-ann.ipynb)\n<br>\n[Next Chapter: Convolutional Neural Network](7-cnn.ipynb)\n\n","slug":"TF-6-autoencoder","published":1,"updated":"2016-12-01T11:46:47.443Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedaj0009lf8hsx0mvl11"},{"title":"TF-7-cnn","date":"2016-12-01T11:46:57.000Z","_content":"\n[Previous Chapter: AutoEncoder](6-autoencoder.ipynb)\n<br>\n[Next Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n## Convolutional Neural Network\n\nIn machine learning, a *Convolutional Neural Network* (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex. Individual neurons of the animal cortex are arranged in such a way that they respond to overlapping regions tiling the visual field, which can mathematically be described by a convolution operation. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in **image and video recognition**, **recommender systems** and **natural language processing**.\n\nFollowing note is partially quoted from [Standford Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/).\n\n### Note: Convolutional Neural Network(CNN)\n\n#### Structure\n![cnnStructure](http://parse.ele.tue.nl/cluster/2/CNNArchitecture.jpg)\n\n#### Convolution\nSince images have the 'stationary' property, which implies that features that are useful in one region are also likely to be useful for other regions. Thus, we use a rather small patch than the image size to convolve this image. For example, when having an image with m * m * r, we could use a n * n * q patch(where n < m && q <= r). The output will be produced in size m - n + 1.\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif\" width=\"440\"/>)\n\n#### Pooling\nTo further reduce computation, pooling is introduced in CNN. As mentioned previously, a mean pooling is applied into each region of the image because of the 'stationary' property. Pooling usually ranges from 2 to 5.\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Pooling_schematic.gif\" width=\"500\"/>)\n\n#### Others\n* Densely Connected Layers: after several convolutional layers, a few densely conncetedly layers are usually constructed before the output layer;\n* Top Layer Classifier: a top classifier is used to do supervised learning on CNN;\n* Back Propogation: unsample on pooling layer and use the flipped filter on convolution layer;\nHere is an exercise of building a *Convolutional Neural Network* using *Tensorflow*. \n\n### Exercise: Convolutional Neural Network\n\n#### Necessary Header\n\n\n```python\n## header\n###### write your code here ######\n```\n\n#### MNIST data\n\n\n```python\n## MNIST data\nmnist = ... ###### write your code here ######\n```\n\n#### Parameters\n\n\n```python\n## parameters\nlearning_rate = ... ###### write your code here ######\ntraining_iters = ... ###### write your code here ######\nbatch_size = ... ###### write your code here ######\ndisplay_step = ... ###### write your code here ######\n```\n\n#### Inputs\n\n\n```python\n## placeholder inputs\nx = ... ###### write your code here ######\ny = ... ###### write your code here ######\n# dropout is a probability for randomly dropping a unit away, it should be a float 32 value\ndropout = ... ###### write your code here ######\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    'wd': tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n    'output': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd': tf.Variable(tf.random_normal([1024])),\n    'output': tf.Variable(tf.random_normal([n_classes]))\n}\n```\n\n#### Graph\n\nIn a traditional *Convolutional Neural Network*, we have several *convolution layers* and *pool layers* following by a *fully-connected layer*.\n\n###### Covolutional Layer\n\n\n```python\n# convolutional layer\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n```\n\n###### Pool Layer\n\n\n```python\n# max pool layer\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1],\n                          strides=[1, k, k, 1],\n                          padding='SAME')\n```\n\n###### Model\n\n\n```python\n# graph\ndef conv_net(x, weights, biases, dropout):\n    # reshape\n    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n    # convolution layer 1\n    conv1 = ... ###### write your code here ######\n    # max pooling layer 1\n    conv1 = ... ###### write your code here ######\n\n    # convolution layer 2\n    conv2 = ... ###### write your code here ######\n    # max pooling layer 2\n    conv2 = ... ###### write your code here ######\n\n    # fully connected layer\n    # reshape conv2 output to fit fully connected layer input\n    fc = tf.reshape(conv2, [-1, weights['wd'].get_shape().as_list()[0]])\n    # apply `tf.nn.relu()` on linear combination of `fc * w[wd] + b[wd]`\n    fc = ... ###### write your code here ######\n    \n    # apply dropout on fully connected layer\n    fc = tf.nn.dropout(fc1, dropout)\n\n    # output is also a linear combination\n    output = ... ###### write your code here ######\n\n    return output\n```\n\n#### Training Steps\n\n\n```python\n# predicted value\npred = conv_net(x, weights, biases, dropout)\n\n# cost and optimizer\ncost = ... ###### write your code here ######\noptimizer = ... ###### write your code here ######\ntraining_steps = ... ###### write your code here ######\n\n# accuracy\ncorrect_prediction = ... ###### write your code here ######\naccuracy = ... ###### write your code here ######\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n\n    # keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # run training steps, use `x = batch_x`, `y = batch_y` and `dropout = 0.5` here\n        sess.run(... ###### write your code here ######)\n\n        if step % display_step == 0:\n            # run batch loss and accuracy, use `x = batch_x`, `y = batch_y` and `dropout = 1` here\n            loss, acc = ... ###### write your code here ######\n\n            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n        step += 1\n\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy for 256 mnist test images\n    print(\"Testing Accuracy:\", \\\n        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                      y: mnist.test.labels[:256],\n                                      dropout: 1.}))\n```\n\n[Previous Chapter: AutoEncoder](6-autoencoder.ipynb)\n<br>\n[Next Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n","source":"_posts/TF-7-cnn.md","raw":"---\ntitle: TF-7-cnn\ndate: 2016-12-01 19:46:57\ntags:\n---\n\n[Previous Chapter: AutoEncoder](6-autoencoder.ipynb)\n<br>\n[Next Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n## Convolutional Neural Network\n\nIn machine learning, a *Convolutional Neural Network* (CNN, or ConvNet) is a type of feed-forward artificial neural network in which the connectivity pattern between its neurons is inspired by the organization of the animal visual cortex. Individual neurons of the animal cortex are arranged in such a way that they respond to overlapping regions tiling the visual field, which can mathematically be described by a convolution operation. Convolutional networks were inspired by biological processes and are variations of multilayer perceptrons designed to use minimal amounts of preprocessing. They have wide applications in **image and video recognition**, **recommender systems** and **natural language processing**.\n\nFollowing note is partially quoted from [Standford Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/).\n\n### Note: Convolutional Neural Network(CNN)\n\n#### Structure\n![cnnStructure](http://parse.ele.tue.nl/cluster/2/CNNArchitecture.jpg)\n\n#### Convolution\nSince images have the 'stationary' property, which implies that features that are useful in one region are also likely to be useful for other regions. Thus, we use a rather small patch than the image size to convolve this image. For example, when having an image with m * m * r, we could use a n * n * q patch(where n < m && q <= r). The output will be produced in size m - n + 1.\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Convolution_schematic.gif\" width=\"440\"/>)\n\n#### Pooling\nTo further reduce computation, pooling is introduced in CNN. As mentioned previously, a mean pooling is applied into each region of the image because of the 'stationary' property. Pooling usually ranges from 2 to 5.\n\n<img src=\"http://ufldl.stanford.edu/tutorial/images/Pooling_schematic.gif\" width=\"500\"/>)\n\n#### Others\n* Densely Connected Layers: after several convolutional layers, a few densely conncetedly layers are usually constructed before the output layer;\n* Top Layer Classifier: a top classifier is used to do supervised learning on CNN;\n* Back Propogation: unsample on pooling layer and use the flipped filter on convolution layer;\nHere is an exercise of building a *Convolutional Neural Network* using *Tensorflow*. \n\n### Exercise: Convolutional Neural Network\n\n#### Necessary Header\n\n\n```python\n## header\n###### write your code here ######\n```\n\n#### MNIST data\n\n\n```python\n## MNIST data\nmnist = ... ###### write your code here ######\n```\n\n#### Parameters\n\n\n```python\n## parameters\nlearning_rate = ... ###### write your code here ######\ntraining_iters = ... ###### write your code here ######\nbatch_size = ... ###### write your code here ######\ndisplay_step = ... ###### write your code here ######\n```\n\n#### Inputs\n\n\n```python\n## placeholder inputs\nx = ... ###### write your code here ######\ny = ... ###### write your code here ######\n# dropout is a probability for randomly dropping a unit away, it should be a float 32 value\ndropout = ... ###### write your code here ######\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n    'wd': tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n    'output': tf.Variable(tf.random_normal([1024, n_classes]))\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32])),\n    'bc2': tf.Variable(tf.random_normal([64])),\n    'bd': tf.Variable(tf.random_normal([1024])),\n    'output': tf.Variable(tf.random_normal([n_classes]))\n}\n```\n\n#### Graph\n\nIn a traditional *Convolutional Neural Network*, we have several *convolution layers* and *pool layers* following by a *fully-connected layer*.\n\n###### Covolutional Layer\n\n\n```python\n# convolutional layer\ndef conv2d(x, W, b, strides=1):\n    # Conv2D wrapper, with bias and relu activation\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)\n```\n\n###### Pool Layer\n\n\n```python\n# max pool layer\ndef maxpool2d(x, k=2):\n    # MaxPool2D wrapper\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1],\n                          strides=[1, k, k, 1],\n                          padding='SAME')\n```\n\n###### Model\n\n\n```python\n# graph\ndef conv_net(x, weights, biases, dropout):\n    # reshape\n    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n\n    # convolution layer 1\n    conv1 = ... ###### write your code here ######\n    # max pooling layer 1\n    conv1 = ... ###### write your code here ######\n\n    # convolution layer 2\n    conv2 = ... ###### write your code here ######\n    # max pooling layer 2\n    conv2 = ... ###### write your code here ######\n\n    # fully connected layer\n    # reshape conv2 output to fit fully connected layer input\n    fc = tf.reshape(conv2, [-1, weights['wd'].get_shape().as_list()[0]])\n    # apply `tf.nn.relu()` on linear combination of `fc * w[wd] + b[wd]`\n    fc = ... ###### write your code here ######\n    \n    # apply dropout on fully connected layer\n    fc = tf.nn.dropout(fc1, dropout)\n\n    # output is also a linear combination\n    output = ... ###### write your code here ######\n\n    return output\n```\n\n#### Training Steps\n\n\n```python\n# predicted value\npred = conv_net(x, weights, biases, dropout)\n\n# cost and optimizer\ncost = ... ###### write your code here ######\noptimizer = ... ###### write your code here ######\ntraining_steps = ... ###### write your code here ######\n\n# accuracy\ncorrect_prediction = ... ###### write your code here ######\naccuracy = ... ###### write your code here ######\n\n# initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Run a Session\n\n\n```python\n## training\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n\n    # keep training until reach max iterations\n    while step * batch_size < training_iters:\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        # run training steps, use `x = batch_x`, `y = batch_y` and `dropout = 0.5` here\n        sess.run(... ###### write your code here ######)\n\n        if step % display_step == 0:\n            # run batch loss and accuracy, use `x = batch_x`, `y = batch_y` and `dropout = 1` here\n            loss, acc = ... ###### write your code here ######\n\n            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n        step += 1\n\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy for 256 mnist test images\n    print(\"Testing Accuracy:\", \\\n        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n                                      y: mnist.test.labels[:256],\n                                      dropout: 1.}))\n```\n\n[Previous Chapter: AutoEncoder](6-autoencoder.ipynb)\n<br>\n[Next Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n","slug":"TF-7-cnn","published":1,"updated":"2016-12-01T11:47:37.127Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedao000alf8hkal24iuf"},{"title":"TF-8-rnn","date":"2016-12-01T11:47:44.000Z","_content":"\n[Previous Chapter: Convolutional Neural Network](7-cnn.ipynb)\n<br>\n[Next Chapter: Distributed Mode](9-distributed.ipynb)\n\n## Recurrent Neural Network and (LSTM)\n\nFollowing part is an introduction to recurrent neural networks and LSTMs quoted from [this great article](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n\n### Introduction to Recurrent Neural Network\n\n#### Recurrent Neural Network\n\nHumans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. *Recurrent neural networks* are deep learning networks addressing this issue. <span style=\"color: #F08080\">They have loops in them, allowing information to persist.</span>\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"500\"/>\n\nThis chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data. RNNs have been successfly applied to a variety of problems: <span style=\"color: #F08080\">*speech recognition*</span>, <span style=\"color: #F08080\">*language modeling*</span>, <span style=\"color: #F08080\">*translation*</span>, <span style=\"color: #F08080\">*image captioning*</span>.\n\n#### A Major Problem in RNN\n\nConsider trying to predict the last word in the text “I grew up in France… I speak fluent French.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png\" width=\"500\" />\n\n<span style=\"color: #F08080\">Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</span>\n\n#### LSTM Network\n\nLong Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, <span style=\"color: #F08080\">capable of learning long-term dependencies</span>. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n\nLSTMs are explicitly designed to <span style=\"color: #F08080\">avoid the long-term dependency problem</span>. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n\nAll recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"500\" />\n\nLSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are <span style=\"color: #F08080\">four, interacting in a very special way</span>.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=\"500\" />\n\n<span style=\"color: #F08080\">In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others.</span> The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png\" width=\"500\" />\n\n\nThe key to LSTMs is the cell state, the horizontal line running through the top of the diagram.\n\nThe cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. <span style=\"color: #F08080\">It’s very easy for information to just flow along it unchanged.</span>\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png\" width=\"500\" />\n\nThe LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n\nGates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png\" width=\"100\" />\n\nThe sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”\n\n<span style=\"color: #F08080\">An LSTM has three of these gates, to protect and control the cell state.</span>\n\n#### Attention System\n\nLSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, et al. (2015) do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…\n\nAttention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, et al. (2015) seem extremely promising. Work using RNNs in generative models – such as Gregor, et al. (2015), Chung, et al. (2015), or Bayer & Osendorfer (2015) – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!\n\n### Exercise: Recurrent Neural Network\n\nThis is an exercise of *Recurrent Neural Network*.\n\n#### Same as previous chapter\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\nimport numpy as np\n\n## import tensorflow rnn and rnn_cell\nfrom tensorflow.python.ops import rnn, rnn_cell\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.001\ntraining_iters = 100000\nbatch_size = 128\ndisplay_step = 10\n```\n\n#### A little bit difference\nTo classify images using a recurrent neural network, we consider every image row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample.\n\n\n```python\n## graph parameters\nn_input = 28 # MNIST data input (img shape: 28*28)\nn_steps = 28 # timesteps\nn_hidden = 128 # hidden layer num of features\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n## inputs\nx = tf.placeholder(\"float\", [None, n_steps, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])\n```\n\n#### Training Steps\n\n\n```python\n## predicted Value\npred = RNN(x, weights, biases)\n\n## cost and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n## accuracy\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n## initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))}\nbiases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n```\n\n#### Graph\n\n\n```python\n## graph\ndef RNN(x, weights, biases):\n\n    # transpose batch_size and n_steps\n    x = tf.transpose(x, [1, 0, 2])\n    # reshaping to (n_steps*batch_size, n_input)\n    x = tf.reshape(x, [-1, n_input])\n    # split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n    x = tf.split(0, n_steps, x)\n\n    # define a lstm cell with tensorflow\n    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n\n    # get lstm cell output\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n\n    # linear activation\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n```\n\n#### Summary\n\n\n```python\n# summary writer\nwriter = tf.train.SummaryWriter('/root/tensorflow/summaries/rnn', graph = tf.get_default_graph())\n```\n\n#### Run a Session\n\n\n```python\n# training\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n\n    # keep training until reach max iterations\n    while step * batch_size < training_iters:\n        # reshape data to get 28 sequence of 28 elements\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n\n        if step % display_step == 0:\n            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y})\n\n            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n        step += 1\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n    test_label = mnist.test.labels[:test_len]\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n```\n\n[Previous Chapter: Convolutional Neural Network](7-cnn.ipynb)\n<br>\n[Next Chapter: Distributed Mode](9-distributed.ipynb)\n\n","source":"_posts/TF-8-rnn.md","raw":"---\ntitle: TF-8-rnn\ndate: 2016-12-01 19:47:44\ntags:\n---\n\n[Previous Chapter: Convolutional Neural Network](7-cnn.ipynb)\n<br>\n[Next Chapter: Distributed Mode](9-distributed.ipynb)\n\n## Recurrent Neural Network and (LSTM)\n\nFollowing part is an introduction to recurrent neural networks and LSTMs quoted from [this great article](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n\n### Introduction to Recurrent Neural Network\n\n#### Recurrent Neural Network\n\nHumans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. *Recurrent neural networks* are deep learning networks addressing this issue. <span style=\"color: #F08080\">They have loops in them, allowing information to persist.</span>\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"500\"/>\n\nThis chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data. RNNs have been successfly applied to a variety of problems: <span style=\"color: #F08080\">*speech recognition*</span>, <span style=\"color: #F08080\">*language modeling*</span>, <span style=\"color: #F08080\">*translation*</span>, <span style=\"color: #F08080\">*image captioning*</span>.\n\n#### A Major Problem in RNN\n\nConsider trying to predict the last word in the text “I grew up in France… I speak fluent French.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png\" width=\"500\" />\n\n<span style=\"color: #F08080\">Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</span>\n\n#### LSTM Network\n\nLong Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, <span style=\"color: #F08080\">capable of learning long-term dependencies</span>. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n\nLSTMs are explicitly designed to <span style=\"color: #F08080\">avoid the long-term dependency problem</span>. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n\nAll recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" width=\"500\" />\n\nLSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are <span style=\"color: #F08080\">four, interacting in a very special way</span>.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=\"500\" />\n\n<span style=\"color: #F08080\">In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others.</span> The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png\" width=\"500\" />\n\n\nThe key to LSTMs is the cell state, the horizontal line running through the top of the diagram.\n\nThe cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. <span style=\"color: #F08080\">It’s very easy for information to just flow along it unchanged.</span>\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png\" width=\"500\" />\n\nThe LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n\nGates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n\n<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png\" width=\"100\" />\n\nThe sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”\n\n<span style=\"color: #F08080\">An LSTM has three of these gates, to protect and control the cell state.</span>\n\n#### Attention System\n\nLSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, Xu, et al. (2015) do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…\n\nAttention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by Kalchbrenner, et al. (2015) seem extremely promising. Work using RNNs in generative models – such as Gregor, et al. (2015), Chung, et al. (2015), or Bayer & Osendorfer (2015) – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!\n\n### Exercise: Recurrent Neural Network\n\nThis is an exercise of *Recurrent Neural Network*.\n\n#### Same as previous chapter\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\nimport numpy as np\n\n## import tensorflow rnn and rnn_cell\nfrom tensorflow.python.ops import rnn, rnn_cell\n\n## MNIST data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/root/tensorflow/MNIST_data\", one_hot=True)\n\n## parameters\nlearning_rate = 0.001\ntraining_iters = 100000\nbatch_size = 128\ndisplay_step = 10\n```\n\n#### A little bit difference\nTo classify images using a recurrent neural network, we consider every image row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample.\n\n\n```python\n## graph parameters\nn_input = 28 # MNIST data input (img shape: 28*28)\nn_steps = 28 # timesteps\nn_hidden = 128 # hidden layer num of features\nn_classes = 10 # MNIST total classes (0-9 digits)\n\n## inputs\nx = tf.placeholder(\"float\", [None, n_steps, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])\n```\n\n#### Training Steps\n\n\n```python\n## predicted Value\npred = RNN(x, weights, biases)\n\n## cost and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n## accuracy\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n## initialization\ninit = tf.initialize_all_variables()\n```\n\n#### Weights and Biases\n\n\n```python\n## weights and biases\nweights = {'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))}\nbiases = {'out': tf.Variable(tf.random_normal([n_classes]))}\n```\n\n#### Graph\n\n\n```python\n## graph\ndef RNN(x, weights, biases):\n\n    # transpose batch_size and n_steps\n    x = tf.transpose(x, [1, 0, 2])\n    # reshaping to (n_steps*batch_size, n_input)\n    x = tf.reshape(x, [-1, n_input])\n    # split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n    x = tf.split(0, n_steps, x)\n\n    # define a lstm cell with tensorflow\n    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n\n    # get lstm cell output\n    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n\n    # linear activation\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n```\n\n#### Summary\n\n\n```python\n# summary writer\nwriter = tf.train.SummaryWriter('/root/tensorflow/summaries/rnn', graph = tf.get_default_graph())\n```\n\n#### Run a Session\n\n\n```python\n# training\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n\n    # keep training until reach max iterations\n    while step * batch_size < training_iters:\n        # reshape data to get 28 sequence of 28 elements\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\n        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n\n        if step % display_step == 0:\n            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y})\n\n            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.5f}\".format(acc))\n        step += 1\n    print(\"Optimization Finished!\")\n\n    # calculate accuracy for 128 mnist test images\n    test_len = 128\n    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n    test_label = mnist.test.labels[:test_len]\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n```\n\n[Previous Chapter: Convolutional Neural Network](7-cnn.ipynb)\n<br>\n[Next Chapter: Distributed Mode](9-distributed.ipynb)\n\n","slug":"TF-8-rnn","published":1,"updated":"2016-12-01T11:48:07.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedau000blf8hgk4b4oub"},{"title":"TF-9-distributed","date":"2016-12-01T11:48:16.000Z","_content":"\n[Previous Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n## Distributed Mode\n\nHere is a sample of running a *Neural Network* on distributed clustering. Because of the busted Tensorflow distributed management, it could not run now here. Hope it could still help you though.\n\n```python\n\"\"\"\nHere is a mnist training example using a single-layer \nneural network and a softmax classifier.\nTo run this file,\n1. please check '172.16.3.227:~/tensorflow/scripts'\n   and execute 'exec_mnist_distributed.sh'.\n2. execute 'python mnist_distributed.py \\\n            --job_name=worker \\\n            --task_index=${0|1|2}' on each worker\n   and 'python mnist_distributed.py \\\n        --job_name=ps \\\n        --task_index=0' on parameter server\n\nCheck (https://www.tensorflow.org/versions/r0.10/how_tos/style_guide.html) for tensorflow styling guide.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport sys\nimport tempfile\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# input or default parameters\nflags = tf.app.flags\n\nflags.DEFINE_string(\n    \"data_dir\",\n    \"/root/tensorflow/MNIST_data\",\n    \"Directory for storing mnist data\")\nflags.DEFINE_string(\n    \"log_dir\",\n    \"/root/tensorflow/logs/mnist_log\",\n    \"Directory for storing log\")\nflags.DEFINE_boolean(\n    \"download_only\",\n    False,\n    \"Only perform downloading of data\")\nflags.DEFINE_string(\n    \"job_name\",\n    None,\n    \"job name: worker or ps\")\nflags.DEFINE_integer(\n    \"task_index\",\n    None,\n    \"Worker task index, should be >= 0.\")\nflags.DEFINE_integer(\n    \"hidden_units\",\n    100,\n    \"Number of units in the hidden layer of the NN\")\nflags.DEFINE_integer(\n    \"training_steps\",\n    20000,\n    \"Number of (global) training steps to perform\")\nflags.DEFINE_integer(\n    \"batch_size\",\n    100,\n    \"Training batch size to be fetched each time\")\nflags.DEFINE_float(\n    \"learning_rate\",\n    0.01,\n    \"Learning rate in machine learning\")\nflags.DEFINE_string(\n    \"ps_hosts\",\n    \"172.16.3.230:2222\",\n    \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\n    \"worker_hosts\",\n    \"172.16.3.227:2222,172.16.3.228:2222,172.16.3.229:2222\",\n    \"Comma-separated list of hostname:port pairs\")\n\nFLAGS = flags.FLAGS\nIMAGE_PIXELS = 28\n\n\ndef main(_):\n\n  # validate and print necessary arguments\n  if FLAGS.job_name is None or FLAGS.job_name == \"\":\n    raise ValueError(\"Must specify an explicit `job_name`\")\n  if FLAGS.task_index is None or FLAGS.task_index ==\"\":\n    raise ValueError(\"Must specify an explicit `task_index`\")\n  print(\"job name = %s\" % FLAGS.job_name)\n  print(\"task index = %d\" % FLAGS.task_index)\n\n  # parse the ps(es) and worker(s)\n  ps_spec = FLAGS.ps_hosts.split(\",\")\n  worker_spec = FLAGS.worker_hosts.split(\",\")\n  num_workers = len(worker_spec)\n\n  # construct the cluster and server\n  cluster = tf.train.ClusterSpec({\"ps\": ps_spec, \"worker\": worker_spec})\n  server = tf.train.Server(\n      cluster,\n      job_name=FLAGS.job_name,\n      task_index=FLAGS.task_index)\n\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n\n    # replica the devices\n    with tf.device(tf.train.replica_device_setter(\n        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n        cluster=cluster)):\n\n      # weight(s) and bias(es) of the hidden layer\n      hid_w = tf.Variable(tf.truncated_normal(\n        [IMAGE_PIXELS * IMAGE_PIXELS, FLAGS.hidden_units],\n        stddev=1.0 / IMAGE_PIXELS), name=\"hid_w\")\n      hid_b = tf.Variable(tf.zeros([FLAGS.hidden_units]), name=\"hid_b\")\n\n      # weight(s) and bias(es) of the softmax layer\n      sm_w = tf.Variable(tf.truncated_normal([FLAGS.hidden_units, 10],\n        stddev=1.0 / math.sqrt(FLAGS.hidden_units)), name=\"sm_w\")\n      sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\n\n      # inputs for future calculation \n      x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n      y_ = tf.placeholder(tf.float32, [None, 10])\n\n      # hidden layer computation logic\n      hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n      hid = tf.nn.relu(hid_lin)\n\n      # softmax layer computation logic\n      y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n      cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n\n      # global step\n      global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n\n      # train step\n      train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(\n          cross_entropy, global_step=global_step)\n\n      # accuary calculation\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n      # initialization\n      init_op = tf.initialize_all_variables()\n      summary_op = tf.merge_all_summaries()\n      # TODO: (xiao) restore problem(temporary annotated)\n      # saver = tf.train.Saver(tf.all_variables(), sharded=True)\n\n    # create a training supervisor\n    sv = tf.train.Supervisor(\n        is_chief=(FLAGS.task_index == 0),\n        logdir=FLAGS.log_dir,\n        init_op=init_op,\n        summary_op=summary_op,\n\t# TODO: (xiao) checkpoint cannot be restored here\n\t# 1. figure out how to use sharded saver\n\t# 2. use hdfs instead when 0.11 released\n        saver=None,\n        global_step=global_step,\n        save_model_secs=600)\n\n    # mnist data(exit the system is download_only is set True)\n    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n\n    with sv.managed_session(server.target) as sess:\n\n      time_begin = time.time()\n      local_step = 0\n      step = 0\n\n      while not sv.should_stop():\n        # Training feed\n        batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)\n        train_feed = {x: batch_xs, y_: batch_ys}\n\n        # perform training\n        _, step = sess.run([train_step, global_step], feed_dict=train_feed)\n        local_step += 1\n\n        now = time.time()\n        print(\"%f: Worker %d: training step %d done (global step: %d)\"\n            % (now, FLAGS.task_index, local_step, step))\n\n        if step >= FLAGS.training_steps:\n          break\n\n      time_end = time.time()\n      training_time = time_end - time_begin\n      print(\"Training elapsed time: %f s\" % training_time)\n\n      # Validation feed\n      val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n      val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n      print(\"After %d training step(s), validation cross entropy = %g\"\n          % (FLAGS.training_steps, val_xent))\n\n      # let's calculate the accuracy\n      pred_feed = {x: mnist.test.images, y_: mnist.test.labels}\n      print(\"Accuracy is: %f\" % sess.run(accuracy, feed_dict=pred_feed))\n\n    # sv.stop()\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n\n```\n\n[Previous Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n","source":"_posts/TF-9-distributed.md","raw":"---\ntitle: TF-9-distributed\ndate: 2016-12-01 19:48:16\ntags:\n---\n\n[Previous Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n## Distributed Mode\n\nHere is a sample of running a *Neural Network* on distributed clustering. Because of the busted Tensorflow distributed management, it could not run now here. Hope it could still help you though.\n\n```python\n\"\"\"\nHere is a mnist training example using a single-layer \nneural network and a softmax classifier.\nTo run this file,\n1. please check '172.16.3.227:~/tensorflow/scripts'\n   and execute 'exec_mnist_distributed.sh'.\n2. execute 'python mnist_distributed.py \\\n            --job_name=worker \\\n            --task_index=${0|1|2}' on each worker\n   and 'python mnist_distributed.py \\\n        --job_name=ps \\\n        --task_index=0' on parameter server\n\nCheck (https://www.tensorflow.org/versions/r0.10/how_tos/style_guide.html) for tensorflow styling guide.\n\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport math\nimport sys\nimport tempfile\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\n# input or default parameters\nflags = tf.app.flags\n\nflags.DEFINE_string(\n    \"data_dir\",\n    \"/root/tensorflow/MNIST_data\",\n    \"Directory for storing mnist data\")\nflags.DEFINE_string(\n    \"log_dir\",\n    \"/root/tensorflow/logs/mnist_log\",\n    \"Directory for storing log\")\nflags.DEFINE_boolean(\n    \"download_only\",\n    False,\n    \"Only perform downloading of data\")\nflags.DEFINE_string(\n    \"job_name\",\n    None,\n    \"job name: worker or ps\")\nflags.DEFINE_integer(\n    \"task_index\",\n    None,\n    \"Worker task index, should be >= 0.\")\nflags.DEFINE_integer(\n    \"hidden_units\",\n    100,\n    \"Number of units in the hidden layer of the NN\")\nflags.DEFINE_integer(\n    \"training_steps\",\n    20000,\n    \"Number of (global) training steps to perform\")\nflags.DEFINE_integer(\n    \"batch_size\",\n    100,\n    \"Training batch size to be fetched each time\")\nflags.DEFINE_float(\n    \"learning_rate\",\n    0.01,\n    \"Learning rate in machine learning\")\nflags.DEFINE_string(\n    \"ps_hosts\",\n    \"172.16.3.230:2222\",\n    \"Comma-separated list of hostname:port pairs\")\nflags.DEFINE_string(\n    \"worker_hosts\",\n    \"172.16.3.227:2222,172.16.3.228:2222,172.16.3.229:2222\",\n    \"Comma-separated list of hostname:port pairs\")\n\nFLAGS = flags.FLAGS\nIMAGE_PIXELS = 28\n\n\ndef main(_):\n\n  # validate and print necessary arguments\n  if FLAGS.job_name is None or FLAGS.job_name == \"\":\n    raise ValueError(\"Must specify an explicit `job_name`\")\n  if FLAGS.task_index is None or FLAGS.task_index ==\"\":\n    raise ValueError(\"Must specify an explicit `task_index`\")\n  print(\"job name = %s\" % FLAGS.job_name)\n  print(\"task index = %d\" % FLAGS.task_index)\n\n  # parse the ps(es) and worker(s)\n  ps_spec = FLAGS.ps_hosts.split(\",\")\n  worker_spec = FLAGS.worker_hosts.split(\",\")\n  num_workers = len(worker_spec)\n\n  # construct the cluster and server\n  cluster = tf.train.ClusterSpec({\"ps\": ps_spec, \"worker\": worker_spec})\n  server = tf.train.Server(\n      cluster,\n      job_name=FLAGS.job_name,\n      task_index=FLAGS.task_index)\n\n  if FLAGS.job_name == \"ps\":\n    server.join()\n  elif FLAGS.job_name == \"worker\":\n\n    # replica the devices\n    with tf.device(tf.train.replica_device_setter(\n        worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n        cluster=cluster)):\n\n      # weight(s) and bias(es) of the hidden layer\n      hid_w = tf.Variable(tf.truncated_normal(\n        [IMAGE_PIXELS * IMAGE_PIXELS, FLAGS.hidden_units],\n        stddev=1.0 / IMAGE_PIXELS), name=\"hid_w\")\n      hid_b = tf.Variable(tf.zeros([FLAGS.hidden_units]), name=\"hid_b\")\n\n      # weight(s) and bias(es) of the softmax layer\n      sm_w = tf.Variable(tf.truncated_normal([FLAGS.hidden_units, 10],\n        stddev=1.0 / math.sqrt(FLAGS.hidden_units)), name=\"sm_w\")\n      sm_b = tf.Variable(tf.zeros([10]), name=\"sm_b\")\n\n      # inputs for future calculation \n      x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])\n      y_ = tf.placeholder(tf.float32, [None, 10])\n\n      # hidden layer computation logic\n      hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)\n      hid = tf.nn.relu(hid_lin)\n\n      # softmax layer computation logic\n      y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))\n      cross_entropy = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n\n      # global step\n      global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n\n      # train step\n      train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(\n          cross_entropy, global_step=global_step)\n\n      # accuary calculation\n      correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n      accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n      # initialization\n      init_op = tf.initialize_all_variables()\n      summary_op = tf.merge_all_summaries()\n      # TODO: (xiao) restore problem(temporary annotated)\n      # saver = tf.train.Saver(tf.all_variables(), sharded=True)\n\n    # create a training supervisor\n    sv = tf.train.Supervisor(\n        is_chief=(FLAGS.task_index == 0),\n        logdir=FLAGS.log_dir,\n        init_op=init_op,\n        summary_op=summary_op,\n\t# TODO: (xiao) checkpoint cannot be restored here\n\t# 1. figure out how to use sharded saver\n\t# 2. use hdfs instead when 0.11 released\n        saver=None,\n        global_step=global_step,\n        save_model_secs=600)\n\n    # mnist data(exit the system is download_only is set True)\n    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n\n    with sv.managed_session(server.target) as sess:\n\n      time_begin = time.time()\n      local_step = 0\n      step = 0\n\n      while not sv.should_stop():\n        # Training feed\n        batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)\n        train_feed = {x: batch_xs, y_: batch_ys}\n\n        # perform training\n        _, step = sess.run([train_step, global_step], feed_dict=train_feed)\n        local_step += 1\n\n        now = time.time()\n        print(\"%f: Worker %d: training step %d done (global step: %d)\"\n            % (now, FLAGS.task_index, local_step, step))\n\n        if step >= FLAGS.training_steps:\n          break\n\n      time_end = time.time()\n      training_time = time_end - time_begin\n      print(\"Training elapsed time: %f s\" % training_time)\n\n      # Validation feed\n      val_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n      val_xent = sess.run(cross_entropy, feed_dict=val_feed)\n      print(\"After %d training step(s), validation cross entropy = %g\"\n          % (FLAGS.training_steps, val_xent))\n\n      # let's calculate the accuracy\n      pred_feed = {x: mnist.test.images, y_: mnist.test.labels}\n      print(\"Accuracy is: %f\" % sess.run(accuracy, feed_dict=pred_feed))\n\n    # sv.stop()\n\n\nif __name__ == \"__main__\":\n  tf.app.run()\n\n```\n\n[Previous Chapter: Recurrent Neural Network](8-rnn.ipynb)\n\n","slug":"TF-9-distributed","published":1,"updated":"2016-12-01T12:02:42.115Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedb1000clf8hshuwocvu"},{"title":"TF-Introduction","date":"2016-12-01T11:13:38.000Z","_content":"\n## TF Playground\n\nThis is a tutorial for better understanding the concept and syntax of **Tensorflow**. In this tutorial, we assume you already have the basic knowledge of **Python** and **Machine Learning**. You can fill the blank lines, run the script and see what would happen according to the code. This tutorial will begin with some style advice and some basic concepts, following by some exercises of different **Machine Learnig** models.\n\n###### Please feel free to add some chapters if you think it might be good for our group.\n\n### Agenda\n* Tensorflow Basics\n    * [Style Guide](chapters/1-style.ipynb)\n    * [Tensorflow Basics](chapters/2-basics.ipynb)\n    * [Graph](chapters/3-graph.ipynb)\n    * [Summary and Tensorboard](chapters/4-summary.ipynb)\n* Deep Learning in TF\n    * [Neural Network](chapters/5-ann.ipynb)\n    * [Autoencoder](chapters/6-autoencoder.ipynb)\n    * [Convolutional Neural Network](chapters/7-cnn.ipynb)\n    * [Recurrent Neural Network](chapters/8-rnn.ipynb)\n* Clustering\n    * [Distributed Mode](chapters/9-distributed.ipynb)\n\n### Sample Code\n\nHere is a sample **Tensorflow** code, play around and grab as much information as you can here. We'll explain it in detail in later chapters. When you think the code is ready, toggle the **\"run cell\"** button in the menu bar and see what will happen.\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\nimport numpy as np\n\n## input\n\n# randomly generate 100 instances with float type\nx_data = np.random.rand(100).astype(np.float32)\n# create a linear model: y = x * 0.1 + 0.3\ny_data = x_data * 0.1 + 0.3\n\n\n## build the graph(we already know w = 0.3 and b = 0.1 though, tensorflow will figure it out by its own)\n\n# initialize uniform distributed weight vector\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n# initialize bias to 0\nb = tf.Variable(tf.zeros([1]))\n# define the graph\ny = W * x_data + b\n\n# define the loss function\nloss = tf.reduce_mean(tf.square(y - y_data))\n# using gradient descent minimize the loss \noptimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\n\n\n## initialization and launch the graph\n\n# define the initialization\ninit = tf.initialize_all_variables()\n# get a session and initialize the variables\nsess = tf.Session()\nsess.run(init)\n\n\n## training\n\nfor step in range(201):\n    sess.run(train)\n    if step % 20 == 0:\n        print(\"steps: %i, weight: %f, bias: %f\" % (step, sess.run(W), sess.run(b)))\n```\n\n    steps: 0, weight: 0.098388, bias: 0.440273\n    steps: 20, weight: 0.081874, bias: 0.310411\n    steps: 40, weight: 0.094683, bias: 0.303054\n    steps: 60, weight: 0.098440, bias: 0.300896\n    steps: 80, weight: 0.099542, bias: 0.300263\n    steps: 100, weight: 0.099866, bias: 0.300077\n    steps: 120, weight: 0.099961, bias: 0.300023\n    steps: 140, weight: 0.099988, bias: 0.300007\n    steps: 160, weight: 0.099997, bias: 0.300002\n    steps: 180, weight: 0.099999, bias: 0.300001\n    steps: 200, weight: 0.100000, bias: 0.300000\n\n\nIn the above sample, we defined a set of random inputs with `y = 0.1 * x + 0.3` and let our linear model `y = W * x + b` to learn the inputs in 200 training epochs. Results are printed per 20 time steps. `W` and `b` should be quite close to 0.1 and 0.3 respectively.\n\n[Next Chapter: Style Guide](chapters/1-style.ipynb)\n\n","source":"_posts/TF-Introduction.md","raw":"---\ntitle: TF-Introduction\ndate: 2016-12-01 19:13:38\ntags:\n---\n\n## TF Playground\n\nThis is a tutorial for better understanding the concept and syntax of **Tensorflow**. In this tutorial, we assume you already have the basic knowledge of **Python** and **Machine Learning**. You can fill the blank lines, run the script and see what would happen according to the code. This tutorial will begin with some style advice and some basic concepts, following by some exercises of different **Machine Learnig** models.\n\n###### Please feel free to add some chapters if you think it might be good for our group.\n\n### Agenda\n* Tensorflow Basics\n    * [Style Guide](chapters/1-style.ipynb)\n    * [Tensorflow Basics](chapters/2-basics.ipynb)\n    * [Graph](chapters/3-graph.ipynb)\n    * [Summary and Tensorboard](chapters/4-summary.ipynb)\n* Deep Learning in TF\n    * [Neural Network](chapters/5-ann.ipynb)\n    * [Autoencoder](chapters/6-autoencoder.ipynb)\n    * [Convolutional Neural Network](chapters/7-cnn.ipynb)\n    * [Recurrent Neural Network](chapters/8-rnn.ipynb)\n* Clustering\n    * [Distributed Mode](chapters/9-distributed.ipynb)\n\n### Sample Code\n\nHere is a sample **Tensorflow** code, play around and grab as much information as you can here. We'll explain it in detail in later chapters. When you think the code is ready, toggle the **\"run cell\"** button in the menu bar and see what will happen.\n\n\n```python\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport tensorflow as tf\nimport numpy as np\n\n## input\n\n# randomly generate 100 instances with float type\nx_data = np.random.rand(100).astype(np.float32)\n# create a linear model: y = x * 0.1 + 0.3\ny_data = x_data * 0.1 + 0.3\n\n\n## build the graph(we already know w = 0.3 and b = 0.1 though, tensorflow will figure it out by its own)\n\n# initialize uniform distributed weight vector\nW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n# initialize bias to 0\nb = tf.Variable(tf.zeros([1]))\n# define the graph\ny = W * x_data + b\n\n# define the loss function\nloss = tf.reduce_mean(tf.square(y - y_data))\n# using gradient descent minimize the loss \noptimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\n\n\n## initialization and launch the graph\n\n# define the initialization\ninit = tf.initialize_all_variables()\n# get a session and initialize the variables\nsess = tf.Session()\nsess.run(init)\n\n\n## training\n\nfor step in range(201):\n    sess.run(train)\n    if step % 20 == 0:\n        print(\"steps: %i, weight: %f, bias: %f\" % (step, sess.run(W), sess.run(b)))\n```\n\n    steps: 0, weight: 0.098388, bias: 0.440273\n    steps: 20, weight: 0.081874, bias: 0.310411\n    steps: 40, weight: 0.094683, bias: 0.303054\n    steps: 60, weight: 0.098440, bias: 0.300896\n    steps: 80, weight: 0.099542, bias: 0.300263\n    steps: 100, weight: 0.099866, bias: 0.300077\n    steps: 120, weight: 0.099961, bias: 0.300023\n    steps: 140, weight: 0.099988, bias: 0.300007\n    steps: 160, weight: 0.099997, bias: 0.300002\n    steps: 180, weight: 0.099999, bias: 0.300001\n    steps: 200, weight: 0.100000, bias: 0.300000\n\n\nIn the above sample, we defined a set of random inputs with `y = 0.1 * x + 0.3` and let our linear model `y = W * x + b` to learn the inputs in 200 training epochs. Results are printed per 20 time steps. `W` and `b` should be quite close to 0.1 and 0.3 respectively.\n\n[Next Chapter: Style Guide](chapters/1-style.ipynb)\n\n","slug":"TF-Introduction","published":1,"updated":"2016-12-01T12:01:31.463Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedba000dlf8herbmq5yz"},{"title":"How to","date":"2016-07-04T12:15:27.000Z","_content":"\n可参考[hexo官网](https://hexo.io/zh-cn/docs/)\n# 安装\n首先请安装 *node.js*， *git*， *npm*\n`sudo apt-get install git npm nodejs nodejs-legacy`\n\n然后clone项目代码\n`git clone git@github.com:transwarpio/teaching_ml.git`\n\n进入*teaching_ml*目录，然后安装相应npm包\n    ``` bash\n    cd teaching_ml\n    npm install\n    ```\n`npm install`会安装teaching\\_ml/package.json中的包。\n\n# 写作\n`hexo new post [title]`会在`source/_posts/`下建立`[title].md`文件，然后你就可以开始写作了\nmarkdown的具体语法可以参考：[master markdown](https://guides.github.com/features/mastering-markdown/)\n  \n## 图片\n对于资源文件比如图片，在`source/_posts/`文件夹下创建与文章同名的子文件夹。比如`source/_posts/doc.md` ，则有 `source/_posts/doc`文件夹。\n然后在文章中引用时使用相对路径。比如`source/_posts/doc/pic.jpg`。\n引用时为`doc/pic.jpg`\n\n## 公式\n可以使用latex编辑公式，或使用公式编辑器编辑后转成图片展示。\n对于latex公式，使用美元符号`$`来包含inline公式，比如`$ y = x + b $`会显式为$ y = x + b $。\n而双美元符号来显式整行公式，比如`$$ y = x + b $$`,显式为 \n$$\ny = x + b\n$$ \n\n# 部署\n当你写完后，可以使用`hexo server`命令在本地查看效果。\n满意后使用`hexo generate --deploy`部署到github。\n\n","source":"_posts/howto.md","raw":"---\ntitle: How to\ndate: 2016-07-04 20:15:27\ntags:\n---\n\n可参考[hexo官网](https://hexo.io/zh-cn/docs/)\n# 安装\n首先请安装 *node.js*， *git*， *npm*\n`sudo apt-get install git npm nodejs nodejs-legacy`\n\n然后clone项目代码\n`git clone git@github.com:transwarpio/teaching_ml.git`\n\n进入*teaching_ml*目录，然后安装相应npm包\n    ``` bash\n    cd teaching_ml\n    npm install\n    ```\n`npm install`会安装teaching\\_ml/package.json中的包。\n\n# 写作\n`hexo new post [title]`会在`source/_posts/`下建立`[title].md`文件，然后你就可以开始写作了\nmarkdown的具体语法可以参考：[master markdown](https://guides.github.com/features/mastering-markdown/)\n  \n## 图片\n对于资源文件比如图片，在`source/_posts/`文件夹下创建与文章同名的子文件夹。比如`source/_posts/doc.md` ，则有 `source/_posts/doc`文件夹。\n然后在文章中引用时使用相对路径。比如`source/_posts/doc/pic.jpg`。\n引用时为`doc/pic.jpg`\n\n## 公式\n可以使用latex编辑公式，或使用公式编辑器编辑后转成图片展示。\n对于latex公式，使用美元符号`$`来包含inline公式，比如`$ y = x + b $`会显式为$ y = x + b $。\n而双美元符号来显式整行公式，比如`$$ y = x + b $$`,显式为 \n$$\ny = x + b\n$$ \n\n# 部署\n当你写完后，可以使用`hexo server`命令在本地查看效果。\n满意后使用`hexo generate --deploy`部署到github。\n\n","slug":"howto","published":1,"updated":"2016-12-01T06:57:59.094Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedbg000elf8hpm9vs75f"},{"_content":"#+TITLE: mxnet 概述\n#+DATE: <2016-07-05 Tue> \n\n\n* 安装\n+ 编译器: ~g++>4.8~ 或者 ~clang~\n+ 依赖：BLAS 库比如 ~libblas~, ~openblas~\n  对于不同的场景，我们会需要依赖不同的库。在这里，我们暂时不使用 GPU,所以不安装 CUDA。\n\n~git clone --recursive https://github.com/dmlc/mxnet~\n** 目录结构\n#+BEGIN_SRC bash\n|- mxnet\n  |- make\n  |- Makefile\n  |- cmake\n  |- CMakeLists.txt\n  |- docker\n  |- dmlc-core\n  |- ps-lite\n  |- mshadow\n  |- include\n  |- src\n  |- scala-package\n  |- R-package\n  |- python\n  |- ...\n#+END_SRC\n\nmxnet 依赖于 dmlc-core，ps-lite 和 mshadow 三个项目。在我看来，mxnet 实际上可以分为两部分。一部分我称之为 mxnet core，另一部分我称之为 mxnet api。在 core 中，\ninclude 文件夹中定义了一套 c api 供其他语言比如 python，scala 调用。mxnet core 并没有实现完整的神经网络训练逻辑，它定义了神经网络如何做前向后向传播，但实际训练时的迭代次数,\nKV Store 的起停等逻辑则是包含在 mxnet api 中的，所以 python，scala 等接口都有一套自己的实现逻辑。\n\n** 编译\nmxnet 现在有两套编译系统，一套直接基于 make，另一套基于 cmake。推荐使用 make，因为功能更全。现在的 mxnet 的 cmake 脚本不支持编译 scala。\n\n可以通过编辑 *make/config.mk* 文件来配置编译选项。对于我们而言，我们暂时不使用 GPU。同时我们需要与 Spark 结合，所以需要分布式的 KV Store。\n在 *make/config.ml* 下，修改配置如下：\n\n#+BEGIN_SRC make\nUSE_DISK_KVSTORE = 1\n#+END_SRC\n\n因为分布式 KV Store 依赖于 protobuf 和 zmq，我们需要安装对应的依赖库。\n\n开始编译\n\n#+BEGIN_SRC bash\ncd mxnet\nmake\nmake scalapkg   # 如果你需要 scala 包\nmake scalatest  # 运行 scala 的测试用例\n#+END_SRC\n\n若编译成功，你可以在 lib 目录下找到 libmxnet.so 文件。\n\n* 参数服务器的优势 \n现在 Spark 基本是大数据处理的事实标准，Spark MLlib 也实现了许多机器学习算法，但 Spark 其实仍是基于 Map/Reduce 计算模型的，而这一模型与机器学习算法的需求\n并不十分契合。在机器学习中，一个十分重要的步骤是计算参数的最优解，一般使用梯度下降方法：\n\\[\nw = w - \\lambda\\Delta w\n\\]\n\n在 Spark 中，每次迭代时，我们每个 partition 可以计算梯度，然后在 driver 端更新 weights。那么 driver 端必须等待所有 executor 完成梯度计算。一旦某个 executor 出现网络延时等问题，\n整个计算过程将受到影响。而参数服务器的目的既是消除这一影响，单个节点计算的延迟并不会影响整体的计算。使同步执行过程变成异步执行过程。比较 mxnet 和 sparkMLlib 中多层神经网络的训练时间，我们可以看到性能的差距。\n\n[[file:mxnet/perf.png]]\n\n** 实现方式\n在参数服务器中有三种角色：\n1. worker： 计算梯度\n2. server： 从 worker 获取梯度信息，更新参数\n3. scheduler: 负责调度，worker 和 server 需 scheduler 注册信息\n\n[[file:mxnet/arch.png]]\n\n工作流程：\n1. worker，server 向 scheduler 注册，获得相关信息\n2. worker 从 server 端 pull 参数 w\n3. worker 基于参数 w 和数据计算梯度，然后 push 梯度到 server\n4. server 更新参数 w\n5. 反复执行 2-4 这一过程\n\n* 计算模型\n主要参考 mxnet 的两篇文章：\n\n[[http://mxnet.readthedocs.io/en/latest/system/program_model.html]]\n\n[[http://mxnet.readthedocs.io/en/latest/system/note_memory.html]]\n\n对于用户而言，mxnet 提够了一套接口来定义神经网络。\n\n#+BEGIN_SRC scala\nval data = Symbol.Variable(\"data\")\nval fc1 = Symbol.FullyConnected(name = \"fc1\")(Map(\"data\" -> data, \"num_hidden\" -> 128))\nval act1 = Symbol.Activation(name = \"relu1\")(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\nval fc2 = Symbol.FullyConnected(name = \"fc2\")(Map(\"data\" -> act1, \"num_hidden\" -> 64))\nval act2 = Symbol.Activation(name = \"relu2\")(Map(\"data\" -> fc2, \"act_type\" -> \"relu\"))\nval fc3 = Symbol.FullyConnected(name = \"fc3\")(Map(\"data\" -> act2, \"num_hidden\" -> 10))\nval mlp = Symbol.SoftmaxOutput(name = \"softmax\")(Map(\"data\" -> fc3))\n#+END_SRC\n\n如上一段 Scala 代码便定义了一个多层神经网络。而在实际执行时， =Symbol= 会调用 =toStaticGraph= 方法转成 =StaticGraph= 。\n=StaticGraph= 会计算图中节点的依赖并生成拓扑结构。我们知道训练神经网络有两个步骤，前向传播和后向传播。现在有两种不同的后向传播计算方法，\n一种是与前向传播共用一个图，而另一种则是显式生成后向传播图节点。\n  \n[[file:mxnet/back_graph.png]]\n\n有些深度学习库选择共用一个图，比如 caffe，torch。而另一些则选择显式后向传播节点，比如 Theano。mxnet 同样选择显式后向传播。这样可以为优化提供方便。\n\n* 实例\n我们先以一个实例来看看 mxnet 是如何运行的。鉴于 Spark 基本是当前大数据处理的事实标准，我们直接尝试将 mxnet 与 Spark 结合，\n从而更接近生产环境的工作流。mxnet 源码中已经有一个与 Spark 结合的实例，我们直接拿来分析。\n\n#+BEGIN_SRC scala\nclass ClassificationExample\nobject ClassificationExample {\n  def main(args: Array[String]): Unit = {\n    try {\n      // 初始化 SparkContext\n      val conf = new SparkConf().setAppName(\"MXNet\")\n      val sc = new SparkContext(conf)\n\n      // 构建网络\n      val network = if (cmdLine.model == \"mlp\") getMlp else getLenet\n      val dimension = if (cmdLine.model == \"mlp\") Shape(784) else Shape(1, 28, 28)\n      val devs =\n        if (cmdLine.gpus != null) cmdLine.gpus.split(',').map(id => Context.gpu(id.trim.toInt))\n        else if (cmdLine.cpus != null) cmdLine.cpus.split(',').map(id => Context.cpu(id.trim.toInt))\n        else Array(Context.cpu(0))\n\n      // 配置训练属性\n      val mxnet = new MXNet()\n        .setBatchSize(128)\n        .setLabelName(\"softmax_label\")\n        .setContext(devs)\n        .setDimension(dimension)\n        .setNetwork(network)\n        .setNumEpoch(cmdLine.numEpoch)\n        .setNumServer(cmdLine.numServer)\n        .setNumWorker(cmdLine.numWorker)\n        .setExecutorJars(cmdLine.jars)\n        .setJava(cmdLine.java)\n\n      val trainData = parseRawData(sc, cmdLine.input)\n      val start = System.currentTimeMillis\n\n      // 开始训练\n      val model = mxnet.fit(trainData)\n      val timeCost = System.currentTimeMillis - start\n      logger.info(\"Training cost {} milli seconds\", timeCost)\n      model.save(sc, cmdLine.output + \"/model\")\n\n      logger.info(\"Now do validation\")\n      val valData = parseRawData(sc, cmdLine.inputVal)\n\n      // 广播模型用于预测\n      val brModel = sc.broadcast(model)\n      val res = valData.mapPartitions { data =>\n        // get real labels\n        import org.apache.spark.mllib.linalg.Vector\n        val points = ArrayBuffer.empty[Vector]\n        val y = ArrayBuffer.empty[Float]\n        while (data.hasNext) {\n          val evalData = data.next()\n          y += evalData.label.toFloat\n          points += evalData.features\n        }\n\n        // get predicted labels\n        val probArrays = brModel.value.predict(points.toIterator)\n        require(probArrays.length == 1)\n        val prob = probArrays(0)\n        val py = NDArray.argmaxChannel(prob.get)\n        require(y.length == py.size, s\"${y.length} mismatch ${py.size}\")\n\n        // I'm too lazy to calculate the accuracy\n        val res = Iterator((y.toArray zip py.toArray).map {\n          case (y1, py1) => y1 + \",\" + py1 }.mkString(\"\\n\"))\n\n        py.dispose()\n        prob.get.dispose()\n        res\n      }\n      res.saveAsTextFile(cmdLine.output + \"/data\")\n\n      sc.stop()\n    } catch {\n      case e: Throwable =>\n        logger.error(e.getMessage, e)\n        sys.exit(-1)\n    }\n  }\n\n  def getMlp: Symbol = {\n    val data = Symbol.Variable(\"data\")\n    val fc1 = Symbol.FullyConnected(name = \"fc1\")(Map(\"data\" -> data, \"num_hidden\" -> 128))\n    val act1 = Symbol.Activation(name = \"relu1\")(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\n    val fc2 = Symbol.FullyConnected(name = \"fc2\")(Map(\"data\" -> act1, \"num_hidden\" -> 64))\n    val act2 = Symbol.Activation(name = \"relu2\")(Map(\"data\" -> fc2, \"act_type\" -> \"relu\"))\n    val fc3 = Symbol.FullyConnected(name = \"fc3\")(Map(\"data\" -> act2, \"num_hidden\" -> 10))\n    val mlp = Symbol.SoftmaxOutput(name = \"softmax\")(Map(\"data\" -> fc3))\n    mlp\n  }\n}\n\n#+END_SRC\n\n为了与 Spark 沟通，毫无疑问首先是初始化 =SparkContext= 。然后我们需要定义神经网络， =getMlp= 方法通过 =Symbol= 定义了一个多层神经网络。然后新建 =MXNet= 类，定义训练属性。\n可以看到，接下来最关键的一步是 ~mxnet.fit(trainData)~ 。此方法接受一个 RDD,并获得最终模型。\n\n在 ~mxnet.fit~ 方法中，主要有以下几步操作：\n1. 新建一个 ParameterServer scheduler。这里存在一个问题，一旦 scheduler 挂了，整个参数服务器将不能运作，需要 HA 改进\n2. 通过 Spark 每个 partition 新建一个 ParameterServer Server\n3. 对于数据集，每个 partition 新建一个 ParameterServer worker\n4. 每个 partition 新建一个  =FeedForword= 网络，对应每个 worker，调用 ~FeedForword.fit~ 进行训练。\n\n\n#+BEGIN_SRC scala\n  def fit(data: RDD[LabeledPoint]): MXNetModel = {\n    val sc = data.context\n    // distribute native jars\n    params.jars.foreach(jar => sc.addFile(jar))\n\n    val trainData = {\n      if (params.numWorker > data.partitions.length) {\n        logger.info(\"repartitioning training set to {} partitions\", params.numWorker)\n        data.repartition(params.numWorker)\n      } else if (params.numWorker < data.partitions.length) {\n        logger.info(\"repartitioning training set to {} partitions\", params.numWorker)\n        data.coalesce(params.numWorker)\n      } else {\n        data\n      }\n    }\n\n    val schedulerIP = utils.Network.ipAddress\n    val schedulerPort = utils.Network.availablePort\n    // TODO: check ip & port available\n    logger.info(\"Starting scheduler on {}:{}\", schedulerIP, schedulerPort)\n    val scheduler = new ParameterServer(params.runtimeClasspath, role = \"scheduler\",\n      rootUri = schedulerIP, rootPort = schedulerPort,\n      numServer = params.numServer, numWorker = params.numWorker, java = params.javabin)\n    require(scheduler.startProcess(), \"Failed to start ps scheduler process\")\n\n    sc.parallelize(1 to params.numServer, params.numServer).foreachPartition { p =>\n      logger.info(\"Starting server ...\")\n      val server = new ParameterServer(params.runtimeClasspath,\n        role = \"server\",\n        rootUri = schedulerIP, rootPort = schedulerPort,\n        numServer = params.numServer,\n        numWorker = params.numWorker,\n        java = params.javabin)\n      require(server.startProcess(), \"Failed to start ps server process\")\n    }\n\n    val job = trainData.mapPartitions { partition =>\n      val dataIter = new LabeledPointIter(\n        partition, params.dimension,\n        params.batchSize,\n        dataName = params.dataName,\n        labelName = params.labelName)\n\n      // TODO: more nature way to get the # of examples?\n      var numExamples = 0\n      while (dataIter.hasNext) {\n        val dataBatch = dataIter.next()\n        numExamples += dataBatch.label.head.shape(0)\n      }\n      logger.debug(\"Number of samples: {}\", numExamples)\n      dataIter.reset()\n\n      logger.info(\"Launching worker ...\")\n      logger.info(\"Batch {}\", params.batchSize)\n      KVStoreServer.init(ParameterServer.buildEnv(role = \"worker\",\n        rootUri = schedulerIP, rootPort = schedulerPort,\n        numServer = params.numServer,\n        numWorker = params.numWorker))\n      val kv = KVStore.create(\"dist_async\")\n\n      val optimizer: Optimizer = new SGD(learningRate = 0.01f,\n        momentum = 0.9f, wd = 0.00001f)\n\n      logger.debug(\"Define model\")\n      val model = new FeedForward(ctx = params.context,\n        symbol = params.getNetwork,\n        numEpoch = params.numEpoch,\n        optimizer = optimizer,\n        initializer = new Xavier(factorType = \"in\", magnitude = 2.34f),\n        argParams = null,\n        auxParams = null,\n        beginEpoch = 0,\n        epochSize = numExamples / params.batchSize / kv.numWorkers)\n      logger.info(\"Start training ...\")\n      model.fit(trainData = dataIter,\n        evalData = null,\n        evalMetric = new Accuracy(),\n        kvStore = kv)\n\n      logger.info(\"Training finished, waiting for other workers ...\")\n      dataIter.dispose()\n      kv.barrier()\n      kv.dispose()\n      Iterator(new MXNetModel(\n        model, params.dimension, params.batchSize,\n        dataName = params.dataName, labelName = params.labelName))\n    }.cache()\n\n    // force job to run\n    job.foreachPartition(() => _)\n    // simply the first model\n    val mxModel = job.first()\n\n    logger.info(\"Waiting for scheduler ...\")\n    scheduler.waitFor()\n    mxModel\n  }\n\n#+END_SRC \n\n#+BEGIN_SRC scala\n// FeedForword.fit\n  private def fit(trainData: DataIter, evalData: DataIter, evalMetric: EvalMetric = new Accuracy(),\n                  kvStore: Option[KVStore], updateOnKVStore: Boolean,\n                  epochEndCallback: EpochEndCallback = null,\n                  batchEndCallback: BatchEndCallback = null, logger: Logger = FeedForward.logger,\n                  workLoadList: Seq[Float] = null): Unit = {\n    require(evalMetric != null, \"evalMetric cannot be null\")\n    val (argNames, paramNames, auxNames) =\n      initParams(trainData.provideData ++ trainData.provideLabel)\n\n    // init optimizer\n    val batchSizeMultiplier = kvStore.map { kv =>\n      if (kv.`type` == \"dist_sync\") {\n        kv.numWorkers\n      } else {\n        1\n      }\n    }\n    val batchSize = trainData.batchSize * batchSizeMultiplier.getOrElse(1)\n    this.optimizer.setArgNames(argNames)\n    this.optimizer.setRescaleGrad(1f / batchSize)\n\n    logger.debug(\"Start training on multi-device\")\n    Model.trainMultiDevice(\n      symbol, ctx, argNames, paramNames, auxNames,\n      _argParams, _auxParams,\n      this.beginEpoch, this.numEpoch,\n      this.epochSize, this.optimizer,\n      kvStore, updateOnKVStore,\n      trainData = trainData, evalData = Option(evalData),\n      evalMetric = evalMetric,\n      epochEndCallback = Option(epochEndCallback),\n      batchEndCallback = Option(batchEndCallback),\n      logger = logger, workLoadList = workLoadList,\n      monitor = monitor)\n#+END_SRC\n\n可以看到，在 ~FeedForword.fit~ 中，基本上是直接调用了 ~Model.trainMultiDevice~ 方法。而此方法则实现了神经网络的前向后向传播和 KV store 的更新。\n主要步骤：\n1. 取 batch\n2. 在此 batch 上做 forward 和 backward 传播\n3. 从 kv store 更新参数\n\n#+BEGIN_SRC scala\n  private[mxnet] def trainMultiDevice(symbol: Symbol, ctx: Array[Context],\n                                      argNames: Seq[String], paramNames: Seq[String],\n                                      auxNames: Seq[String], argParams: Map[String, NDArray],\n                                      auxParams: Map[String, NDArray],\n                                      beginEpoch: Int, endEpoch: Int, epochSize: Int,\n                                      optimizer: Optimizer,\n                                      kvStore: Option[KVStore], updateOnKVStore: Boolean,\n                                      trainData: DataIter = null,\n                                      evalData: Option[DataIter] = None,\n                                      evalMetric: EvalMetric,\n                                      epochEndCallback: Option[EpochEndCallback] = None,\n                                      batchEndCallback: Option[BatchEndCallback] = None,\n                                      logger: Logger = logger,\n                                      workLoadList: Seq[Float] = Nil,\n                                      monitor: Option[Monitor] = None): Unit = {\n    val executorManager = new DataParallelExecutorManager(\n        symbol = symbol,\n        ctx = ctx,\n        trainData = trainData,\n        paramNames = paramNames,\n        argNames = argNames,\n        auxNames = auxNames,\n        workLoadList = workLoadList,\n        logger = logger)\n\n    monitor.foreach(executorManager.installMonitor)\n    executorManager.setParams(argParams, auxParams)\n\n    // updater for updateOnKVStore = false\n    val updaterLocal = Optimizer.getUpdater(optimizer)\n\n    kvStore.foreach(initializeKVStore(_, executorManager.paramArrays,\n      argParams, executorManager._paramNames, updateOnKVStore))\n    if (updateOnKVStore) {\n      kvStore.foreach(_.setOptimizer(optimizer))\n    }\n\n    // Now start training\n    for (epoch <- beginEpoch until endEpoch) {\n      // Training phase\n      val tic = System.currentTimeMillis\n      evalMetric.reset()\n      var nBatch = 0\n      var epochDone = false\n      // Iterate over training data.\n      trainData.reset()\n      while (!epochDone) {\n        var doReset = true\n        while (doReset && trainData.hasNext) {\n          val dataBatch = trainData.next()\n          executorManager.loadDataBatch(dataBatch)\n          monitor.foreach(_.tic())\n          executorManager.forward(isTrain = true)\n          executorManager.backward()\n          if (updateOnKVStore) {\n            updateParamsOnKVStore(executorManager.paramArrays,\n              executorManager.gradArrays,\n              kvStore)\n          } else {\n            updateParams(executorManager.paramArrays,\n              executorManager.gradArrays,\n              updaterLocal, ctx.length,\n              kvStore)\n          }\n          monitor.foreach(_.tocPrint())\n          // evaluate at end, so out_cpu_array can lazy copy\n          evalMetric.update(dataBatch.label, executorManager.cpuOutputArrays)\n\n          nBatch += 1\n          batchEndCallback.foreach(_.invoke(epoch, nBatch, evalMetric))\n\n          // this epoch is done possibly earlier\n          if (epochSize != -1 && nBatch >= epochSize) {\n            doReset = false\n          }\n          dataBatch.dispose()\n        }\n        if (doReset) {\n          trainData.reset()\n        }\n\n        // this epoch is done\n        epochDone = (epochSize == -1 || nBatch >= epochSize)\n      }\n\n      val (name, value) = evalMetric.get\n      logger.info(s\"Epoch[$epoch] Train-$name=$value\")\n      val toc = System.currentTimeMillis\n      logger.info(s\"Epoch[$epoch] Time cost=${toc - tic}\")\n\n      evalData.foreach { evalDataIter =>\n        evalMetric.reset()\n        evalDataIter.reset()\n        // TODO: make DataIter implement Iterator\n        while (evalDataIter.hasNext) {\n          val evalBatch = evalDataIter.next()\n          executorManager.loadDataBatch(evalBatch)\n          executorManager.forward(isTrain = false)\n          evalMetric.update(evalBatch.label, executorManager.cpuOutputArrays)\n          evalBatch.dispose()\n        }\n\n        val (name, value) = evalMetric.get\n        logger.info(s\"Epoch[$epoch] Validation-$name=$value\")\n      }\n\n      if (epochEndCallback.isDefined || epoch + 1 == endEpoch) {\n        executorManager.copyTo(argParams, auxParams)\n      }\n      epochEndCallback.foreach(_.invoke(epoch, symbol, argParams, auxParams))\n    }\n\n    updaterLocal.dispose()\n    executorManager.dispose()\n  }\n#+END_SRC\n\n* 组件\n** dmlc-core  \n*** parameter.h\n 与 spark 类似，dmlc core 也有一套定义参数的系统。cpp 没有类似 java 的反射机制，\n 所以在 dmlc 中用到的方法比较 hack：计算类中属性的 offset。\n*** data.h\n\n** ps-lite\n postoffice\n server, worker, scheduler\n Control: empty, terminate, add_node, barrier, ack\n van\n message\n 新建 KVWorker 和 KVServer 包含 Customer，初始化时新建一个线程用于接收消息\n\n #+BEGIN_SRC cpp\n Customer::Customer(int id, const Customer::RecvHandle& recv_handle)\n     : id_(id), recv_handle_(recv_handle) {\n   Postoffice::Get()->AddCustomer(this);\n   recv_thread_ = std::unique_ptr<std::thread>(new std::thread(&Customer::Receiving, this));\n }\n #+END_SRC\n\n van 封装通信，现在使用 zmq\n\n** mxnet\n","source":"_posts/mxnet.org","raw":"#+TITLE: mxnet 概述\n#+DATE: <2016-07-05 Tue> \n\n\n* 安装\n+ 编译器: ~g++>4.8~ 或者 ~clang~\n+ 依赖：BLAS 库比如 ~libblas~, ~openblas~\n  对于不同的场景，我们会需要依赖不同的库。在这里，我们暂时不使用 GPU,所以不安装 CUDA。\n\n~git clone --recursive https://github.com/dmlc/mxnet~\n** 目录结构\n#+BEGIN_SRC bash\n|- mxnet\n  |- make\n  |- Makefile\n  |- cmake\n  |- CMakeLists.txt\n  |- docker\n  |- dmlc-core\n  |- ps-lite\n  |- mshadow\n  |- include\n  |- src\n  |- scala-package\n  |- R-package\n  |- python\n  |- ...\n#+END_SRC\n\nmxnet 依赖于 dmlc-core，ps-lite 和 mshadow 三个项目。在我看来，mxnet 实际上可以分为两部分。一部分我称之为 mxnet core，另一部分我称之为 mxnet api。在 core 中，\ninclude 文件夹中定义了一套 c api 供其他语言比如 python，scala 调用。mxnet core 并没有实现完整的神经网络训练逻辑，它定义了神经网络如何做前向后向传播，但实际训练时的迭代次数,\nKV Store 的起停等逻辑则是包含在 mxnet api 中的，所以 python，scala 等接口都有一套自己的实现逻辑。\n\n** 编译\nmxnet 现在有两套编译系统，一套直接基于 make，另一套基于 cmake。推荐使用 make，因为功能更全。现在的 mxnet 的 cmake 脚本不支持编译 scala。\n\n可以通过编辑 *make/config.mk* 文件来配置编译选项。对于我们而言，我们暂时不使用 GPU。同时我们需要与 Spark 结合，所以需要分布式的 KV Store。\n在 *make/config.ml* 下，修改配置如下：\n\n#+BEGIN_SRC make\nUSE_DISK_KVSTORE = 1\n#+END_SRC\n\n因为分布式 KV Store 依赖于 protobuf 和 zmq，我们需要安装对应的依赖库。\n\n开始编译\n\n#+BEGIN_SRC bash\ncd mxnet\nmake\nmake scalapkg   # 如果你需要 scala 包\nmake scalatest  # 运行 scala 的测试用例\n#+END_SRC\n\n若编译成功，你可以在 lib 目录下找到 libmxnet.so 文件。\n\n* 参数服务器的优势 \n现在 Spark 基本是大数据处理的事实标准，Spark MLlib 也实现了许多机器学习算法，但 Spark 其实仍是基于 Map/Reduce 计算模型的，而这一模型与机器学习算法的需求\n并不十分契合。在机器学习中，一个十分重要的步骤是计算参数的最优解，一般使用梯度下降方法：\n\\[\nw = w - \\lambda\\Delta w\n\\]\n\n在 Spark 中，每次迭代时，我们每个 partition 可以计算梯度，然后在 driver 端更新 weights。那么 driver 端必须等待所有 executor 完成梯度计算。一旦某个 executor 出现网络延时等问题，\n整个计算过程将受到影响。而参数服务器的目的既是消除这一影响，单个节点计算的延迟并不会影响整体的计算。使同步执行过程变成异步执行过程。比较 mxnet 和 sparkMLlib 中多层神经网络的训练时间，我们可以看到性能的差距。\n\n[[file:mxnet/perf.png]]\n\n** 实现方式\n在参数服务器中有三种角色：\n1. worker： 计算梯度\n2. server： 从 worker 获取梯度信息，更新参数\n3. scheduler: 负责调度，worker 和 server 需 scheduler 注册信息\n\n[[file:mxnet/arch.png]]\n\n工作流程：\n1. worker，server 向 scheduler 注册，获得相关信息\n2. worker 从 server 端 pull 参数 w\n3. worker 基于参数 w 和数据计算梯度，然后 push 梯度到 server\n4. server 更新参数 w\n5. 反复执行 2-4 这一过程\n\n* 计算模型\n主要参考 mxnet 的两篇文章：\n\n[[http://mxnet.readthedocs.io/en/latest/system/program_model.html]]\n\n[[http://mxnet.readthedocs.io/en/latest/system/note_memory.html]]\n\n对于用户而言，mxnet 提够了一套接口来定义神经网络。\n\n#+BEGIN_SRC scala\nval data = Symbol.Variable(\"data\")\nval fc1 = Symbol.FullyConnected(name = \"fc1\")(Map(\"data\" -> data, \"num_hidden\" -> 128))\nval act1 = Symbol.Activation(name = \"relu1\")(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\nval fc2 = Symbol.FullyConnected(name = \"fc2\")(Map(\"data\" -> act1, \"num_hidden\" -> 64))\nval act2 = Symbol.Activation(name = \"relu2\")(Map(\"data\" -> fc2, \"act_type\" -> \"relu\"))\nval fc3 = Symbol.FullyConnected(name = \"fc3\")(Map(\"data\" -> act2, \"num_hidden\" -> 10))\nval mlp = Symbol.SoftmaxOutput(name = \"softmax\")(Map(\"data\" -> fc3))\n#+END_SRC\n\n如上一段 Scala 代码便定义了一个多层神经网络。而在实际执行时， =Symbol= 会调用 =toStaticGraph= 方法转成 =StaticGraph= 。\n=StaticGraph= 会计算图中节点的依赖并生成拓扑结构。我们知道训练神经网络有两个步骤，前向传播和后向传播。现在有两种不同的后向传播计算方法，\n一种是与前向传播共用一个图，而另一种则是显式生成后向传播图节点。\n  \n[[file:mxnet/back_graph.png]]\n\n有些深度学习库选择共用一个图，比如 caffe，torch。而另一些则选择显式后向传播节点，比如 Theano。mxnet 同样选择显式后向传播。这样可以为优化提供方便。\n\n* 实例\n我们先以一个实例来看看 mxnet 是如何运行的。鉴于 Spark 基本是当前大数据处理的事实标准，我们直接尝试将 mxnet 与 Spark 结合，\n从而更接近生产环境的工作流。mxnet 源码中已经有一个与 Spark 结合的实例，我们直接拿来分析。\n\n#+BEGIN_SRC scala\nclass ClassificationExample\nobject ClassificationExample {\n  def main(args: Array[String]): Unit = {\n    try {\n      // 初始化 SparkContext\n      val conf = new SparkConf().setAppName(\"MXNet\")\n      val sc = new SparkContext(conf)\n\n      // 构建网络\n      val network = if (cmdLine.model == \"mlp\") getMlp else getLenet\n      val dimension = if (cmdLine.model == \"mlp\") Shape(784) else Shape(1, 28, 28)\n      val devs =\n        if (cmdLine.gpus != null) cmdLine.gpus.split(',').map(id => Context.gpu(id.trim.toInt))\n        else if (cmdLine.cpus != null) cmdLine.cpus.split(',').map(id => Context.cpu(id.trim.toInt))\n        else Array(Context.cpu(0))\n\n      // 配置训练属性\n      val mxnet = new MXNet()\n        .setBatchSize(128)\n        .setLabelName(\"softmax_label\")\n        .setContext(devs)\n        .setDimension(dimension)\n        .setNetwork(network)\n        .setNumEpoch(cmdLine.numEpoch)\n        .setNumServer(cmdLine.numServer)\n        .setNumWorker(cmdLine.numWorker)\n        .setExecutorJars(cmdLine.jars)\n        .setJava(cmdLine.java)\n\n      val trainData = parseRawData(sc, cmdLine.input)\n      val start = System.currentTimeMillis\n\n      // 开始训练\n      val model = mxnet.fit(trainData)\n      val timeCost = System.currentTimeMillis - start\n      logger.info(\"Training cost {} milli seconds\", timeCost)\n      model.save(sc, cmdLine.output + \"/model\")\n\n      logger.info(\"Now do validation\")\n      val valData = parseRawData(sc, cmdLine.inputVal)\n\n      // 广播模型用于预测\n      val brModel = sc.broadcast(model)\n      val res = valData.mapPartitions { data =>\n        // get real labels\n        import org.apache.spark.mllib.linalg.Vector\n        val points = ArrayBuffer.empty[Vector]\n        val y = ArrayBuffer.empty[Float]\n        while (data.hasNext) {\n          val evalData = data.next()\n          y += evalData.label.toFloat\n          points += evalData.features\n        }\n\n        // get predicted labels\n        val probArrays = brModel.value.predict(points.toIterator)\n        require(probArrays.length == 1)\n        val prob = probArrays(0)\n        val py = NDArray.argmaxChannel(prob.get)\n        require(y.length == py.size, s\"${y.length} mismatch ${py.size}\")\n\n        // I'm too lazy to calculate the accuracy\n        val res = Iterator((y.toArray zip py.toArray).map {\n          case (y1, py1) => y1 + \",\" + py1 }.mkString(\"\\n\"))\n\n        py.dispose()\n        prob.get.dispose()\n        res\n      }\n      res.saveAsTextFile(cmdLine.output + \"/data\")\n\n      sc.stop()\n    } catch {\n      case e: Throwable =>\n        logger.error(e.getMessage, e)\n        sys.exit(-1)\n    }\n  }\n\n  def getMlp: Symbol = {\n    val data = Symbol.Variable(\"data\")\n    val fc1 = Symbol.FullyConnected(name = \"fc1\")(Map(\"data\" -> data, \"num_hidden\" -> 128))\n    val act1 = Symbol.Activation(name = \"relu1\")(Map(\"data\" -> fc1, \"act_type\" -> \"relu\"))\n    val fc2 = Symbol.FullyConnected(name = \"fc2\")(Map(\"data\" -> act1, \"num_hidden\" -> 64))\n    val act2 = Symbol.Activation(name = \"relu2\")(Map(\"data\" -> fc2, \"act_type\" -> \"relu\"))\n    val fc3 = Symbol.FullyConnected(name = \"fc3\")(Map(\"data\" -> act2, \"num_hidden\" -> 10))\n    val mlp = Symbol.SoftmaxOutput(name = \"softmax\")(Map(\"data\" -> fc3))\n    mlp\n  }\n}\n\n#+END_SRC\n\n为了与 Spark 沟通，毫无疑问首先是初始化 =SparkContext= 。然后我们需要定义神经网络， =getMlp= 方法通过 =Symbol= 定义了一个多层神经网络。然后新建 =MXNet= 类，定义训练属性。\n可以看到，接下来最关键的一步是 ~mxnet.fit(trainData)~ 。此方法接受一个 RDD,并获得最终模型。\n\n在 ~mxnet.fit~ 方法中，主要有以下几步操作：\n1. 新建一个 ParameterServer scheduler。这里存在一个问题，一旦 scheduler 挂了，整个参数服务器将不能运作，需要 HA 改进\n2. 通过 Spark 每个 partition 新建一个 ParameterServer Server\n3. 对于数据集，每个 partition 新建一个 ParameterServer worker\n4. 每个 partition 新建一个  =FeedForword= 网络，对应每个 worker，调用 ~FeedForword.fit~ 进行训练。\n\n\n#+BEGIN_SRC scala\n  def fit(data: RDD[LabeledPoint]): MXNetModel = {\n    val sc = data.context\n    // distribute native jars\n    params.jars.foreach(jar => sc.addFile(jar))\n\n    val trainData = {\n      if (params.numWorker > data.partitions.length) {\n        logger.info(\"repartitioning training set to {} partitions\", params.numWorker)\n        data.repartition(params.numWorker)\n      } else if (params.numWorker < data.partitions.length) {\n        logger.info(\"repartitioning training set to {} partitions\", params.numWorker)\n        data.coalesce(params.numWorker)\n      } else {\n        data\n      }\n    }\n\n    val schedulerIP = utils.Network.ipAddress\n    val schedulerPort = utils.Network.availablePort\n    // TODO: check ip & port available\n    logger.info(\"Starting scheduler on {}:{}\", schedulerIP, schedulerPort)\n    val scheduler = new ParameterServer(params.runtimeClasspath, role = \"scheduler\",\n      rootUri = schedulerIP, rootPort = schedulerPort,\n      numServer = params.numServer, numWorker = params.numWorker, java = params.javabin)\n    require(scheduler.startProcess(), \"Failed to start ps scheduler process\")\n\n    sc.parallelize(1 to params.numServer, params.numServer).foreachPartition { p =>\n      logger.info(\"Starting server ...\")\n      val server = new ParameterServer(params.runtimeClasspath,\n        role = \"server\",\n        rootUri = schedulerIP, rootPort = schedulerPort,\n        numServer = params.numServer,\n        numWorker = params.numWorker,\n        java = params.javabin)\n      require(server.startProcess(), \"Failed to start ps server process\")\n    }\n\n    val job = trainData.mapPartitions { partition =>\n      val dataIter = new LabeledPointIter(\n        partition, params.dimension,\n        params.batchSize,\n        dataName = params.dataName,\n        labelName = params.labelName)\n\n      // TODO: more nature way to get the # of examples?\n      var numExamples = 0\n      while (dataIter.hasNext) {\n        val dataBatch = dataIter.next()\n        numExamples += dataBatch.label.head.shape(0)\n      }\n      logger.debug(\"Number of samples: {}\", numExamples)\n      dataIter.reset()\n\n      logger.info(\"Launching worker ...\")\n      logger.info(\"Batch {}\", params.batchSize)\n      KVStoreServer.init(ParameterServer.buildEnv(role = \"worker\",\n        rootUri = schedulerIP, rootPort = schedulerPort,\n        numServer = params.numServer,\n        numWorker = params.numWorker))\n      val kv = KVStore.create(\"dist_async\")\n\n      val optimizer: Optimizer = new SGD(learningRate = 0.01f,\n        momentum = 0.9f, wd = 0.00001f)\n\n      logger.debug(\"Define model\")\n      val model = new FeedForward(ctx = params.context,\n        symbol = params.getNetwork,\n        numEpoch = params.numEpoch,\n        optimizer = optimizer,\n        initializer = new Xavier(factorType = \"in\", magnitude = 2.34f),\n        argParams = null,\n        auxParams = null,\n        beginEpoch = 0,\n        epochSize = numExamples / params.batchSize / kv.numWorkers)\n      logger.info(\"Start training ...\")\n      model.fit(trainData = dataIter,\n        evalData = null,\n        evalMetric = new Accuracy(),\n        kvStore = kv)\n\n      logger.info(\"Training finished, waiting for other workers ...\")\n      dataIter.dispose()\n      kv.barrier()\n      kv.dispose()\n      Iterator(new MXNetModel(\n        model, params.dimension, params.batchSize,\n        dataName = params.dataName, labelName = params.labelName))\n    }.cache()\n\n    // force job to run\n    job.foreachPartition(() => _)\n    // simply the first model\n    val mxModel = job.first()\n\n    logger.info(\"Waiting for scheduler ...\")\n    scheduler.waitFor()\n    mxModel\n  }\n\n#+END_SRC \n\n#+BEGIN_SRC scala\n// FeedForword.fit\n  private def fit(trainData: DataIter, evalData: DataIter, evalMetric: EvalMetric = new Accuracy(),\n                  kvStore: Option[KVStore], updateOnKVStore: Boolean,\n                  epochEndCallback: EpochEndCallback = null,\n                  batchEndCallback: BatchEndCallback = null, logger: Logger = FeedForward.logger,\n                  workLoadList: Seq[Float] = null): Unit = {\n    require(evalMetric != null, \"evalMetric cannot be null\")\n    val (argNames, paramNames, auxNames) =\n      initParams(trainData.provideData ++ trainData.provideLabel)\n\n    // init optimizer\n    val batchSizeMultiplier = kvStore.map { kv =>\n      if (kv.`type` == \"dist_sync\") {\n        kv.numWorkers\n      } else {\n        1\n      }\n    }\n    val batchSize = trainData.batchSize * batchSizeMultiplier.getOrElse(1)\n    this.optimizer.setArgNames(argNames)\n    this.optimizer.setRescaleGrad(1f / batchSize)\n\n    logger.debug(\"Start training on multi-device\")\n    Model.trainMultiDevice(\n      symbol, ctx, argNames, paramNames, auxNames,\n      _argParams, _auxParams,\n      this.beginEpoch, this.numEpoch,\n      this.epochSize, this.optimizer,\n      kvStore, updateOnKVStore,\n      trainData = trainData, evalData = Option(evalData),\n      evalMetric = evalMetric,\n      epochEndCallback = Option(epochEndCallback),\n      batchEndCallback = Option(batchEndCallback),\n      logger = logger, workLoadList = workLoadList,\n      monitor = monitor)\n#+END_SRC\n\n可以看到，在 ~FeedForword.fit~ 中，基本上是直接调用了 ~Model.trainMultiDevice~ 方法。而此方法则实现了神经网络的前向后向传播和 KV store 的更新。\n主要步骤：\n1. 取 batch\n2. 在此 batch 上做 forward 和 backward 传播\n3. 从 kv store 更新参数\n\n#+BEGIN_SRC scala\n  private[mxnet] def trainMultiDevice(symbol: Symbol, ctx: Array[Context],\n                                      argNames: Seq[String], paramNames: Seq[String],\n                                      auxNames: Seq[String], argParams: Map[String, NDArray],\n                                      auxParams: Map[String, NDArray],\n                                      beginEpoch: Int, endEpoch: Int, epochSize: Int,\n                                      optimizer: Optimizer,\n                                      kvStore: Option[KVStore], updateOnKVStore: Boolean,\n                                      trainData: DataIter = null,\n                                      evalData: Option[DataIter] = None,\n                                      evalMetric: EvalMetric,\n                                      epochEndCallback: Option[EpochEndCallback] = None,\n                                      batchEndCallback: Option[BatchEndCallback] = None,\n                                      logger: Logger = logger,\n                                      workLoadList: Seq[Float] = Nil,\n                                      monitor: Option[Monitor] = None): Unit = {\n    val executorManager = new DataParallelExecutorManager(\n        symbol = symbol,\n        ctx = ctx,\n        trainData = trainData,\n        paramNames = paramNames,\n        argNames = argNames,\n        auxNames = auxNames,\n        workLoadList = workLoadList,\n        logger = logger)\n\n    monitor.foreach(executorManager.installMonitor)\n    executorManager.setParams(argParams, auxParams)\n\n    // updater for updateOnKVStore = false\n    val updaterLocal = Optimizer.getUpdater(optimizer)\n\n    kvStore.foreach(initializeKVStore(_, executorManager.paramArrays,\n      argParams, executorManager._paramNames, updateOnKVStore))\n    if (updateOnKVStore) {\n      kvStore.foreach(_.setOptimizer(optimizer))\n    }\n\n    // Now start training\n    for (epoch <- beginEpoch until endEpoch) {\n      // Training phase\n      val tic = System.currentTimeMillis\n      evalMetric.reset()\n      var nBatch = 0\n      var epochDone = false\n      // Iterate over training data.\n      trainData.reset()\n      while (!epochDone) {\n        var doReset = true\n        while (doReset && trainData.hasNext) {\n          val dataBatch = trainData.next()\n          executorManager.loadDataBatch(dataBatch)\n          monitor.foreach(_.tic())\n          executorManager.forward(isTrain = true)\n          executorManager.backward()\n          if (updateOnKVStore) {\n            updateParamsOnKVStore(executorManager.paramArrays,\n              executorManager.gradArrays,\n              kvStore)\n          } else {\n            updateParams(executorManager.paramArrays,\n              executorManager.gradArrays,\n              updaterLocal, ctx.length,\n              kvStore)\n          }\n          monitor.foreach(_.tocPrint())\n          // evaluate at end, so out_cpu_array can lazy copy\n          evalMetric.update(dataBatch.label, executorManager.cpuOutputArrays)\n\n          nBatch += 1\n          batchEndCallback.foreach(_.invoke(epoch, nBatch, evalMetric))\n\n          // this epoch is done possibly earlier\n          if (epochSize != -1 && nBatch >= epochSize) {\n            doReset = false\n          }\n          dataBatch.dispose()\n        }\n        if (doReset) {\n          trainData.reset()\n        }\n\n        // this epoch is done\n        epochDone = (epochSize == -1 || nBatch >= epochSize)\n      }\n\n      val (name, value) = evalMetric.get\n      logger.info(s\"Epoch[$epoch] Train-$name=$value\")\n      val toc = System.currentTimeMillis\n      logger.info(s\"Epoch[$epoch] Time cost=${toc - tic}\")\n\n      evalData.foreach { evalDataIter =>\n        evalMetric.reset()\n        evalDataIter.reset()\n        // TODO: make DataIter implement Iterator\n        while (evalDataIter.hasNext) {\n          val evalBatch = evalDataIter.next()\n          executorManager.loadDataBatch(evalBatch)\n          executorManager.forward(isTrain = false)\n          evalMetric.update(evalBatch.label, executorManager.cpuOutputArrays)\n          evalBatch.dispose()\n        }\n\n        val (name, value) = evalMetric.get\n        logger.info(s\"Epoch[$epoch] Validation-$name=$value\")\n      }\n\n      if (epochEndCallback.isDefined || epoch + 1 == endEpoch) {\n        executorManager.copyTo(argParams, auxParams)\n      }\n      epochEndCallback.foreach(_.invoke(epoch, symbol, argParams, auxParams))\n    }\n\n    updaterLocal.dispose()\n    executorManager.dispose()\n  }\n#+END_SRC\n\n* 组件\n** dmlc-core  \n*** parameter.h\n 与 spark 类似，dmlc core 也有一套定义参数的系统。cpp 没有类似 java 的反射机制，\n 所以在 dmlc 中用到的方法比较 hack：计算类中属性的 offset。\n*** data.h\n\n** ps-lite\n postoffice\n server, worker, scheduler\n Control: empty, terminate, add_node, barrier, ack\n van\n message\n 新建 KVWorker 和 KVServer 包含 Customer，初始化时新建一个线程用于接收消息\n\n #+BEGIN_SRC cpp\n Customer::Customer(int id, const Customer::RecvHandle& recv_handle)\n     : id_(id), recv_handle_(recv_handle) {\n   Postoffice::Get()->AddCustomer(this);\n   recv_thread_ = std::unique_ptr<std::thread>(new std::thread(&Customer::Receiving, this));\n }\n #+END_SRC\n\n van 封装通信，现在使用 zmq\n\n** mxnet\n","slug":"mxnet","published":1,"date":"2016-11-30T09:54:27.155Z","updated":"2016-11-30T09:54:27.155Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedbw000flf8hzygpr8cl"},{"_content":"#+TITLE: Support Vector Machine\n#+DATE: 2016-08-30\n\n* SVM\n** 介绍\nSupport Vector Machine 支持向量机是一种机器学习算法。 \n\n给定一个训练集 \\( S = \\{ (x_i, y_i) \\}_{i=1}^{m} \\), 其中 \\( x_i \\in \\mathbb{R}^n \\) 并且 \\( y_i \\in \\{ +1, -1 \\} \\),\n图[[svm]]展示了一个 SVM 需要解决的问题。 我们标记  \\( w \\cdot x - b = 0 \\) 为超平面， \\( w \\) 代表该超平面的向量。 \n我们需要做的是找到能将 \\( y_i=1 \\) 的点和 \\( y_i=-1 \\) 的点 分开的边际最大的超平面.\n这就意味着 \\( y_i(w \\cdot x_i -b ) \\geq 1 \\)，对于所有 \\( 1 \\leq i \\leq n \\).\n\n所以优化问题可以写成：\n\n最大化\n\n\\[ \\frac{2}{\\|w\\|} \\]\n\n这等价于最小化\n\n\\[ \\frac{1}{2} \\| w \\|^2 \\]\n\nsubject to \\( y_i(w \\cdot x_i - b) \\geq 1 \\) for all \\( 1 \\leq i \\leq n \\)\n\n#+ATTR_HTML: :alt captionm :width 400px\n#+caption: SVM\n#+name: svm\n[[file:images/svm/svm.png]]\n\n事实上，它可以被看作一个带有惩罚项的最小化损失问题。最终，我们希望找到以下问题的最小解\n\n\\[\n \\min_{w} \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{m}\\sum_{(x, y) \\in S} \\ell(w; (x, y))\n\\]\n\n其中 \\lambda 是正规化参数, \\( \\ell(w, (x, y)) \\) 是 hinge 损失函数:\n\n\\[\n\\ell(w, (x, y)) = max\\{0, 1-y \\langle w, x \\rangle \\}\n\\]\n\n对于这一最优化问题，我们可以使用梯度下降算法来达到最小值。\n\n目标函数为：\n\n\\[\nf(w) = \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{m}\\sum_{(x_i, y_i) \\in S}\\ell(w; (x_i, y_i))\n\\]\n\n所以，迭代 /t/ 时的梯度为：\n\n\\[\n\\nabla_t = \\lambda w_t - \\frac{1}{m}\\sum_{(x_i, y_i) \\in S}\\mathbbm{1}[y_i \\langle w, x_i \\rangle < 1]y_i x_i\n\\]\n\n于是，我们可以更新  \\( w \\), 其中 \\( \\eta_t \\) 是下降速度\n\\[\nw_{t+1} \\leftarrow w_t - \\eta_t\\nabla_t\n\\]\n\n** SGD\n从上一节我们可以看到每次迭代我们都需要所有的数据点来计算梯度。而当数据集变大后，无疑会耗费大量的计算时间。\n这就是为什么在大规模梯度下降算法中，我们总会使用 SGD（随机梯度下降）。SDG 在每次迭代时只使用一部分数据而不是全部，\n从而降低了计算量。\n\n所以，现在目标函数变成了：\n\\[\nf(w, A_t) = \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{k}\\sum_{(x_i, y_i) \\in A_t}\\ell(w; (x_i, y_i))\n\\]\nwhere \\( A_t \\subset S \\), \\( |A_t| = k \\). At each iteration, we takes a subset of data point.\n\n然后梯度为：\n \\[ \\nabla_t = \\lambda w_t - \\frac{1}{k}\\sum_{(x_i, y_i) \\in A_t}\\mathbbm{1}[y_i \\langle w, x_i \\rangle < 1]y_i x_i \\]\n\n** Pegasos and MLlib implementation\nPegasos 是 SVM 使用梯度下降算法的一种实现。Spark MLlib 也提供了 SVM 的梯度下降实现，于 Pegasos 稍有不同。\n主要是梯度的更新速度不同。\n\n\\[\nw_{t+1} \\leftarrow w_t - \\eta_t\\nabla_t\n\\]\n\n在 Pegasos 算法中, 更新速度为\n\\[\n\\eta_t = \\frac{\\alpha}{t\\lambda}\n\\]\n\n而在 MLlib 中，为：\n\\[\n\\eta_t = \\frac{\\alpha}{\\sqrt{t}}\n\\]\n\n其中 \\alpha 是更新速度参数。\n\n* SGD in Spark\n** treeAggregate\nSpark 来计算 SGD 的主要优势使可以分布式地计算梯度，然后将它们累加起来。\n在 Spark 中，这一任务是通过 RDD 的 *treeAggregate* 方法来完成的。\n*Aggregate* 可被视为泛化的 *Map* 和 *Reduce* 的组合。 *treeAggregate* 的定义为\n\n#+BEGIN_SRC scala\nRDD.treeAggregate(zeroValue: U)(\n      seqOp: (U, T) => U,\n      combOp: (U, U) => U,\n      depth: Int = 2): U\n#+END_SRC\n\n在此方法中有三个参数，其中前两个对我们更重要：\n\n+ seqOp: 计算每隔 partition 中的子梯度\n+ combOp: 将 seqOp 或上层 combOp 的值合并\n+ depth: 控制 tree 的深度\n\n#+caption: tree aggregate\n#+name: tree\n[[file:images/svm/tree.png]]\n\n** 实现\nSGD 是一个求最优化的算法，许多机器学习算法都可以用 SGD 来求解。所以 Spark 对其做了抽象。\n\n#+BEGIN_SRC scala\nclass SVMWithSGD private (\n    private var stepSize: Double,\n    private var numIterations: Int,\n    private var regParam: Double,\n    private var miniBatchFraction: Double)\n  extends GeneralizedLinearAlgorithm[SVMModel] with Serializable {\n\n  private val gradient = new HingeGradient()\n  private val updater = new SquaredL2Updater()\n  @Since(\"0.8.0\")\n  override val optimizer = new GradientDescent(gradient, updater)\n    .setStepSize(stepSize)\n    .setNumIterations(numIterations)\n    .setRegParam(regParam)\n    .setMiniBatchFraction(miniBatchFraction)\n#+END_SRC\n\n可以看到 ~SVMWithSGD~ 继承了 ~GeneralizedLinearAlgorithm~ ，并定义 ~optimizer~ 来确定如何获得优化解。\n而 ~optimizer~ 即是 SGD 算法的实现。正如上节所述，线性 SVM 实际上是使用 hinge 损失函数和一个 L2 惩罚项的线性模型，因此这里使用了 ~HingeGradient~ 和 ~SquaredL2Updater~ \n作为 ~GradientDescent~ 的参数。\n\n#+BEGIN_SRC scala\nclass HingeGradient extends Gradient {\n  override def compute(data: Vector, label: Double, weights: Vector): (Vector, Double) = {\n    val dotProduct = dot(data, weights)\n    // Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))\n    // Therefore the gradient is -(2y - 1)*x\n    val labelScaled = 2 * label - 1.0\n    if (1.0 > labelScaled * dotProduct) {\n      val gradient = data.copy\n      scal(-labelScaled, gradient)\n      (gradient, 1.0 - labelScaled * dotProduct)\n    } else {\n      (Vectors.sparse(weights.size, Array.empty, Array.empty), 0.0)\n    }\n  }\n\n  override def compute(\n      data: Vector,\n      label: Double,\n      weights: Vector,\n      cumGradient: Vector): Double = {\n    val dotProduct = dot(data, weights)\n    // Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))\n    // Therefore the gradient is -(2y - 1)*x\n    val labelScaled = 2 * label - 1.0\n    if (1.0 > labelScaled * dotProduct) {\n      axpy(-labelScaled, data, cumGradient)\n      1.0 - labelScaled * dotProduct\n    } else {\n      0.0\n    }\n  }\n}\n#+END_SRC\n\n#+BEGIN_SRC scala\n/**\n * :: DeveloperApi ::\n * Updater for L2 regularized problems.\n *          R(w) = 1/2 ||w||^2\n * Uses a step-size decreasing with the square root of the number of iterations.\n */\n@DeveloperApi\nclass SquaredL2Updater extends Updater {\n  override def compute(\n      weightsOld: Vector,\n      gradient: Vector,\n      stepSize: Double,\n      iter: Int,\n      regParam: Double): (Vector, Double) = {\n    // add up both updates from the gradient of the loss (= step) as well as\n    // the gradient of the regularizer (= regParam * weightsOld)\n    // w' = w - thisIterStepSize * (gradient + regParam * w)\n    // w' = (1 - thisIterStepSize * regParam) * w - thisIterStepSize * gradient\n    val thisIterStepSize = stepSize / math.sqrt(iter)\n    val brzWeights: BV[Double] = weightsOld.asBreeze.toDenseVector\n    brzWeights :*= (1.0 - thisIterStepSize * regParam)\n    brzAxpy(-thisIterStepSize, gradient.asBreeze, brzWeights)\n    val norm = brzNorm(brzWeights, 2.0)\n\n    (Vectors.fromBreeze(brzWeights), 0.5 * regParam * norm * norm)\n  }\n}\n#+END_SRC\n\n此节中, [[code]] 展示了 ~GradientDescent~ 的主要执行逻辑。 重复执行 ~numIterations~ 次以获得最终的 \\( w \\)。\n\n首先, ~data.sample~ 通过 ~miniBatchFraction~ 取一部分样本. 然后使用 ~treeAggregate~ 。\n在 ~seqOp~ 中, ~gradientSum~ 会通过 ~axpy(y, b_x, c._1)~ 更新，如果 \\( y\\langle w, x \\rangle < 1 \\)，即分类错误。\n在 ~combOp~ 中, ~gradientSum~ 通过 ~c1._1 += c2._1~ 被集合起来。 当获得 ~gradientSum~ 后, 我们就可以计算 ~step~ 和 ~gradient~ 了。\n最后, 我们使用 ~axpy(-step, gradient, weights)~ 更新 ~weights~ 。\n\n#+caption: GradientDescent 代码片断\n#+name: code\n#+BEGIN_SRC scala\n    while (!converged && i <= numIterations) {\n      val bcWeights = data.context.broadcast(weights)\n      // Sample a subset (fraction miniBatchFraction) of the total data\n      // compute and sum up the subgradients on this subset (this is one map-reduce)\n      val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 42 + i)\n        .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n          seqOp = (c, v) => {\n            // c: (grad, loss, count), v: (label, features)\n            val l = gradient.compute(v._2, v._1, bcWeights.value, Vectors.fromBreeze(c._1))\n            (c._1, c._2 + l, c._3 + 1)\n          },\n          combOp = (c1, c2) => {\n            // c: (grad, loss, count)\n            (c1._1 += c2._1, c1._2 + c2._2, c1._3 + c2._3)\n          })\n\n      if (miniBatchSize > 0) {\n        /**\n         * lossSum is computed using the weights from the previous iteration\n         * and regVal is the regularization value computed in the previous iteration as well.\n         */\n        stochasticLossHistory.append(lossSum / miniBatchSize + regVal)\n        val update = updater.compute(\n          weights, Vectors.fromBreeze(gradientSum / miniBatchSize.toDouble),\n          stepSize, i, regParam)\n        weights = update._1\n        regVal = update._2\n\n        previousWeights = currentWeights\n        currentWeights = Some(weights)\n        if (previousWeights != None && currentWeights != None) {\n          converged = isConverged(previousWeights.get,\n            currentWeights.get, convergenceTol)\n        }\n      } else {\n        logWarning(s\"Iteration ($i/$numIterations). The size of sampled batch is zero\")\n      }\n      i += 1\n#+END_SRC\n\n* 实验和性能\n** 正确性验证\n我们模拟了一些简单的 2D 和 3D 数据来验证正确性。\n#+caption: 2D linear\n#+name: 2d-linear\n[[file:images/svm/2d_linear.png]]\n\n#+caption: 3D linear\n#+name: 3d-linear\n[[file:images/svm/3d_linear.png]]\n\n** 收敛速度\n我们比较两种实现的收敛速度差异。这里，我们使用 5GB 带有 1000 个特征的模拟数据。使用 4 个 executors 并迭代 100 次。\n\n#+ATTR_LATEX: :width 16cm\n#+caption: before aligning Y axis\n#+name: convergence1\n[[file:images/svm/step1.png]]\n\n#+ATTR_LATEX: :width 16cm\n#+caption: after aligning Y axis\n#+name: convergence2\n[[file:images/svm/step2.png]]\n\n\n* 参考文献\n1. Zaharia, Matei, et al. \"Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing.\" Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association, 2012\n2. Zaharia, Matei, et al. \"Spark: cluster computing with working sets.\" Proceedings of the 2nd USENIX conference on Hot topics in cloud computing. Vol. 10. 2010\n3. Shalev-Shwartz, Shai, et al. \"Pegasos: Primal estimated sub-gradient solver for svm.\" Mathematical programming 127.1 (2011): 3-30\n","source":"_posts/svm.org","raw":"#+TITLE: Support Vector Machine\n#+DATE: 2016-08-30\n\n* SVM\n** 介绍\nSupport Vector Machine 支持向量机是一种机器学习算法。 \n\n给定一个训练集 \\( S = \\{ (x_i, y_i) \\}_{i=1}^{m} \\), 其中 \\( x_i \\in \\mathbb{R}^n \\) 并且 \\( y_i \\in \\{ +1, -1 \\} \\),\n图[[svm]]展示了一个 SVM 需要解决的问题。 我们标记  \\( w \\cdot x - b = 0 \\) 为超平面， \\( w \\) 代表该超平面的向量。 \n我们需要做的是找到能将 \\( y_i=1 \\) 的点和 \\( y_i=-1 \\) 的点 分开的边际最大的超平面.\n这就意味着 \\( y_i(w \\cdot x_i -b ) \\geq 1 \\)，对于所有 \\( 1 \\leq i \\leq n \\).\n\n所以优化问题可以写成：\n\n最大化\n\n\\[ \\frac{2}{\\|w\\|} \\]\n\n这等价于最小化\n\n\\[ \\frac{1}{2} \\| w \\|^2 \\]\n\nsubject to \\( y_i(w \\cdot x_i - b) \\geq 1 \\) for all \\( 1 \\leq i \\leq n \\)\n\n#+ATTR_HTML: :alt captionm :width 400px\n#+caption: SVM\n#+name: svm\n[[file:images/svm/svm.png]]\n\n事实上，它可以被看作一个带有惩罚项的最小化损失问题。最终，我们希望找到以下问题的最小解\n\n\\[\n \\min_{w} \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{m}\\sum_{(x, y) \\in S} \\ell(w; (x, y))\n\\]\n\n其中 \\lambda 是正规化参数, \\( \\ell(w, (x, y)) \\) 是 hinge 损失函数:\n\n\\[\n\\ell(w, (x, y)) = max\\{0, 1-y \\langle w, x \\rangle \\}\n\\]\n\n对于这一最优化问题，我们可以使用梯度下降算法来达到最小值。\n\n目标函数为：\n\n\\[\nf(w) = \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{m}\\sum_{(x_i, y_i) \\in S}\\ell(w; (x_i, y_i))\n\\]\n\n所以，迭代 /t/ 时的梯度为：\n\n\\[\n\\nabla_t = \\lambda w_t - \\frac{1}{m}\\sum_{(x_i, y_i) \\in S}\\mathbbm{1}[y_i \\langle w, x_i \\rangle < 1]y_i x_i\n\\]\n\n于是，我们可以更新  \\( w \\), 其中 \\( \\eta_t \\) 是下降速度\n\\[\nw_{t+1} \\leftarrow w_t - \\eta_t\\nabla_t\n\\]\n\n** SGD\n从上一节我们可以看到每次迭代我们都需要所有的数据点来计算梯度。而当数据集变大后，无疑会耗费大量的计算时间。\n这就是为什么在大规模梯度下降算法中，我们总会使用 SGD（随机梯度下降）。SDG 在每次迭代时只使用一部分数据而不是全部，\n从而降低了计算量。\n\n所以，现在目标函数变成了：\n\\[\nf(w, A_t) = \\frac{\\lambda}{2}\\|w\\|^2 + \\frac{1}{k}\\sum_{(x_i, y_i) \\in A_t}\\ell(w; (x_i, y_i))\n\\]\nwhere \\( A_t \\subset S \\), \\( |A_t| = k \\). At each iteration, we takes a subset of data point.\n\n然后梯度为：\n \\[ \\nabla_t = \\lambda w_t - \\frac{1}{k}\\sum_{(x_i, y_i) \\in A_t}\\mathbbm{1}[y_i \\langle w, x_i \\rangle < 1]y_i x_i \\]\n\n** Pegasos and MLlib implementation\nPegasos 是 SVM 使用梯度下降算法的一种实现。Spark MLlib 也提供了 SVM 的梯度下降实现，于 Pegasos 稍有不同。\n主要是梯度的更新速度不同。\n\n\\[\nw_{t+1} \\leftarrow w_t - \\eta_t\\nabla_t\n\\]\n\n在 Pegasos 算法中, 更新速度为\n\\[\n\\eta_t = \\frac{\\alpha}{t\\lambda}\n\\]\n\n而在 MLlib 中，为：\n\\[\n\\eta_t = \\frac{\\alpha}{\\sqrt{t}}\n\\]\n\n其中 \\alpha 是更新速度参数。\n\n* SGD in Spark\n** treeAggregate\nSpark 来计算 SGD 的主要优势使可以分布式地计算梯度，然后将它们累加起来。\n在 Spark 中，这一任务是通过 RDD 的 *treeAggregate* 方法来完成的。\n*Aggregate* 可被视为泛化的 *Map* 和 *Reduce* 的组合。 *treeAggregate* 的定义为\n\n#+BEGIN_SRC scala\nRDD.treeAggregate(zeroValue: U)(\n      seqOp: (U, T) => U,\n      combOp: (U, U) => U,\n      depth: Int = 2): U\n#+END_SRC\n\n在此方法中有三个参数，其中前两个对我们更重要：\n\n+ seqOp: 计算每隔 partition 中的子梯度\n+ combOp: 将 seqOp 或上层 combOp 的值合并\n+ depth: 控制 tree 的深度\n\n#+caption: tree aggregate\n#+name: tree\n[[file:images/svm/tree.png]]\n\n** 实现\nSGD 是一个求最优化的算法，许多机器学习算法都可以用 SGD 来求解。所以 Spark 对其做了抽象。\n\n#+BEGIN_SRC scala\nclass SVMWithSGD private (\n    private var stepSize: Double,\n    private var numIterations: Int,\n    private var regParam: Double,\n    private var miniBatchFraction: Double)\n  extends GeneralizedLinearAlgorithm[SVMModel] with Serializable {\n\n  private val gradient = new HingeGradient()\n  private val updater = new SquaredL2Updater()\n  @Since(\"0.8.0\")\n  override val optimizer = new GradientDescent(gradient, updater)\n    .setStepSize(stepSize)\n    .setNumIterations(numIterations)\n    .setRegParam(regParam)\n    .setMiniBatchFraction(miniBatchFraction)\n#+END_SRC\n\n可以看到 ~SVMWithSGD~ 继承了 ~GeneralizedLinearAlgorithm~ ，并定义 ~optimizer~ 来确定如何获得优化解。\n而 ~optimizer~ 即是 SGD 算法的实现。正如上节所述，线性 SVM 实际上是使用 hinge 损失函数和一个 L2 惩罚项的线性模型，因此这里使用了 ~HingeGradient~ 和 ~SquaredL2Updater~ \n作为 ~GradientDescent~ 的参数。\n\n#+BEGIN_SRC scala\nclass HingeGradient extends Gradient {\n  override def compute(data: Vector, label: Double, weights: Vector): (Vector, Double) = {\n    val dotProduct = dot(data, weights)\n    // Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))\n    // Therefore the gradient is -(2y - 1)*x\n    val labelScaled = 2 * label - 1.0\n    if (1.0 > labelScaled * dotProduct) {\n      val gradient = data.copy\n      scal(-labelScaled, gradient)\n      (gradient, 1.0 - labelScaled * dotProduct)\n    } else {\n      (Vectors.sparse(weights.size, Array.empty, Array.empty), 0.0)\n    }\n  }\n\n  override def compute(\n      data: Vector,\n      label: Double,\n      weights: Vector,\n      cumGradient: Vector): Double = {\n    val dotProduct = dot(data, weights)\n    // Our loss function with {0, 1} labels is max(0, 1 - (2y - 1) (f_w(x)))\n    // Therefore the gradient is -(2y - 1)*x\n    val labelScaled = 2 * label - 1.0\n    if (1.0 > labelScaled * dotProduct) {\n      axpy(-labelScaled, data, cumGradient)\n      1.0 - labelScaled * dotProduct\n    } else {\n      0.0\n    }\n  }\n}\n#+END_SRC\n\n#+BEGIN_SRC scala\n/**\n * :: DeveloperApi ::\n * Updater for L2 regularized problems.\n *          R(w) = 1/2 ||w||^2\n * Uses a step-size decreasing with the square root of the number of iterations.\n */\n@DeveloperApi\nclass SquaredL2Updater extends Updater {\n  override def compute(\n      weightsOld: Vector,\n      gradient: Vector,\n      stepSize: Double,\n      iter: Int,\n      regParam: Double): (Vector, Double) = {\n    // add up both updates from the gradient of the loss (= step) as well as\n    // the gradient of the regularizer (= regParam * weightsOld)\n    // w' = w - thisIterStepSize * (gradient + regParam * w)\n    // w' = (1 - thisIterStepSize * regParam) * w - thisIterStepSize * gradient\n    val thisIterStepSize = stepSize / math.sqrt(iter)\n    val brzWeights: BV[Double] = weightsOld.asBreeze.toDenseVector\n    brzWeights :*= (1.0 - thisIterStepSize * regParam)\n    brzAxpy(-thisIterStepSize, gradient.asBreeze, brzWeights)\n    val norm = brzNorm(brzWeights, 2.0)\n\n    (Vectors.fromBreeze(brzWeights), 0.5 * regParam * norm * norm)\n  }\n}\n#+END_SRC\n\n此节中, [[code]] 展示了 ~GradientDescent~ 的主要执行逻辑。 重复执行 ~numIterations~ 次以获得最终的 \\( w \\)。\n\n首先, ~data.sample~ 通过 ~miniBatchFraction~ 取一部分样本. 然后使用 ~treeAggregate~ 。\n在 ~seqOp~ 中, ~gradientSum~ 会通过 ~axpy(y, b_x, c._1)~ 更新，如果 \\( y\\langle w, x \\rangle < 1 \\)，即分类错误。\n在 ~combOp~ 中, ~gradientSum~ 通过 ~c1._1 += c2._1~ 被集合起来。 当获得 ~gradientSum~ 后, 我们就可以计算 ~step~ 和 ~gradient~ 了。\n最后, 我们使用 ~axpy(-step, gradient, weights)~ 更新 ~weights~ 。\n\n#+caption: GradientDescent 代码片断\n#+name: code\n#+BEGIN_SRC scala\n    while (!converged && i <= numIterations) {\n      val bcWeights = data.context.broadcast(weights)\n      // Sample a subset (fraction miniBatchFraction) of the total data\n      // compute and sum up the subgradients on this subset (this is one map-reduce)\n      val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 42 + i)\n        .treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(\n          seqOp = (c, v) => {\n            // c: (grad, loss, count), v: (label, features)\n            val l = gradient.compute(v._2, v._1, bcWeights.value, Vectors.fromBreeze(c._1))\n            (c._1, c._2 + l, c._3 + 1)\n          },\n          combOp = (c1, c2) => {\n            // c: (grad, loss, count)\n            (c1._1 += c2._1, c1._2 + c2._2, c1._3 + c2._3)\n          })\n\n      if (miniBatchSize > 0) {\n        /**\n         * lossSum is computed using the weights from the previous iteration\n         * and regVal is the regularization value computed in the previous iteration as well.\n         */\n        stochasticLossHistory.append(lossSum / miniBatchSize + regVal)\n        val update = updater.compute(\n          weights, Vectors.fromBreeze(gradientSum / miniBatchSize.toDouble),\n          stepSize, i, regParam)\n        weights = update._1\n        regVal = update._2\n\n        previousWeights = currentWeights\n        currentWeights = Some(weights)\n        if (previousWeights != None && currentWeights != None) {\n          converged = isConverged(previousWeights.get,\n            currentWeights.get, convergenceTol)\n        }\n      } else {\n        logWarning(s\"Iteration ($i/$numIterations). The size of sampled batch is zero\")\n      }\n      i += 1\n#+END_SRC\n\n* 实验和性能\n** 正确性验证\n我们模拟了一些简单的 2D 和 3D 数据来验证正确性。\n#+caption: 2D linear\n#+name: 2d-linear\n[[file:images/svm/2d_linear.png]]\n\n#+caption: 3D linear\n#+name: 3d-linear\n[[file:images/svm/3d_linear.png]]\n\n** 收敛速度\n我们比较两种实现的收敛速度差异。这里，我们使用 5GB 带有 1000 个特征的模拟数据。使用 4 个 executors 并迭代 100 次。\n\n#+ATTR_LATEX: :width 16cm\n#+caption: before aligning Y axis\n#+name: convergence1\n[[file:images/svm/step1.png]]\n\n#+ATTR_LATEX: :width 16cm\n#+caption: after aligning Y axis\n#+name: convergence2\n[[file:images/svm/step2.png]]\n\n\n* 参考文献\n1. Zaharia, Matei, et al. \"Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing.\" Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation. USENIX Association, 2012\n2. Zaharia, Matei, et al. \"Spark: cluster computing with working sets.\" Proceedings of the 2nd USENIX conference on Hot topics in cloud computing. Vol. 10. 2010\n3. Shalev-Shwartz, Shai, et al. \"Pegasos: Primal estimated sub-gradient solver for svm.\" Mathematical programming 127.1 (2011): 3-30\n","slug":"svm","published":1,"date":"2016-11-30T09:54:27.155Z","updated":"2016-11-30T09:54:27.155Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6bedc4000glf8hvgcucjhc"},{"title":"关联规则挖掘基础篇","date":"2016-07-04T06:46:01.000Z","_content":"<center>![img](关联规则挖掘基础篇/market.jpg)</center>\n### 什么是关联规则挖掘？\n　　作为数据挖掘的重要研究方向之一，关联规则挖掘的目的是从事务数据集中分析数据项之间潜在的关联关系，揭示其中蕴含的对于用户有价值的模式。一般认为，关联规则挖掘主要由两个步骤组成：(1)从事务数据集中挖掘所有支持度不小于最小支持度阈值的频繁项集；(2)从上一步结果中生成满足最小置信度阈值要求的关联规则。其中，由于具有指数级别的时间复杂度，频繁项集挖掘所消耗的时间往往超过用户可以接受的程度。在过去的十多年中，国内外的研究者们提出了许多算法来不断改进相关算法的性能。这里的性能主要指的是执行时间。\n<!-- more -->\n### 问题定义\n　　<b>定义1</b>（项集）设I={i<sub>1</sub>，i<sub>2</sub>，...，i<sub>n</sub>}是n个不同的数据项组成的集合。包含0个或多个数据项的集合，称之为项集。\n　　<b>定义2</b>（k-项集）如果一个项集包含 k个数据项，则称之为k-项集。\n　　<b>定义3</b>（事务）事务是不同的数据项组成的集合。每一条事务T是I的一个子集，即T⊆ I。\n　　<b>定义4</b>（事务数据集）事务数据集D={T<sub>1</sub>，T<sub>2</sub>，...，T<sub>m</sub>}是m条事务组成的集合。\n　　<b>定义5</b>（项集的支持度计数）项集X在D中的支持度计数表示D中包含X的事务数，其形式化定义如下:\n<center>count(X)=|{T<sub>i</sub>|X⊆T<sub>i</sub>，T<sub>i</sub>∈D}|</center>\n　　其中，|·|表示集合中元素的个数。\n　　<b>定义6</b>（项集的支持度）项集X在D中的支持度表示包含X的事务在D中所占的比例，其形式化定义如下:\n<center>support(X)=|{T<sub>i</sub>|X⊆T<sub>i</sub>，T<sub>i</sub>∈D}|/|D|</center>\n　　<b>定义7</b>（频繁项集）如果项集X的支持度不小于用户给定的最小支持度阈值 minSup，则称X为频繁项集。\n　　<b>定义8</b>（候选项集）可能成为频繁项集的项集称为候选项集。\n### 问题分析\n　　如果一个事务数据集中包含5个{a}，{b}，{c}，{d}，{e}不同的数据项，则该问题的解空间包含2<sup>5</sup>个候选项集，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/lattice.png\" width=\"600\"/>\n</div>\n　　为了计算该解空间中每一个候选项集的支持度，Brute-force方法通过扫描事务数据集，将所有候选项集与事务逐一比较。如果事务中包含该候选项集，则增加候选项集的支持度。该过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/brute_force.png\" width=\"600\"/>\n</div>\n　　从而，可知Brute-force方法的时间复杂度约为O(NMw)，其中N是事务数据集的大小，M是候选项集的数量，w是平均事务的长度。由于M=2<sup>k</sup>，k是数据项的数量，因此，该方法的时间复杂度是指数级别。\n### Apriori算法分析\n#### 基本思想\n　　Apriori算法采用了逐层搜索的策略来对解空间进行遍历。在遍历的过程中 ，该算法采用了先验原理（*如果一个项集是频繁项集，则其任意子集均是频繁项集。*）来对解空间进行剪枝，减少候选项集的数量。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/apriori_prune.png\" width=\"600\"/>\n</div>\n　　给定如上图所示的解空间，如果候选项集{A，B}不是频繁项集，则该候选项集的任意超集均不可能成为频繁项集，因此，无需计算这些项集的支持度，可以将其从解空间中剪枝，减少了不必要的计算量。\n#### 算法过程\n　　Apriori算法首先扫描一次事务数据集，计算各个数据项的支持度，从而得到频繁1-项集。将这些频繁1-项集自连接来生成候选2-项集。通过再一次扫描事务数据集，计算各个候选项集的支持度，从而得到频繁2-项集。Apriori算法按照这个方式不断迭代，直至不再产生新的候选项集或频繁项集为止。其中，将两个k-项集自连接来生成候选(k+1)-项集的要求是这两个k-项集除了最后一个数据项不同，其余数据项均相同。所生成的不满足先验原理的候选(k+1)-项集将被删除。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/self_join.png\" width=\"400\"/>\n</div>\n　　如上图所示，将频繁3-项集{abc}和{abd}做自连接生成候选4-项集{a，b，c，d}，由于{a，b，c，d}的任意子集均是频繁项集，因此，保留该候选项集。而候选4-项集{a，c，d，e}的子集{c，d，e}并不是频繁项集，因此，将其删除。\n　　Apriori算法的伪代码如下。\n```\ninitially, scan DB once to get frequent 1-itemset\nrepeat\n　　  generate (k+1)-candidate itemsets from frequent k-itemset\n　　  test (k+1)-candidate itemsets against DB to find frequent (k+1)-itemsets\n　　  set k := k + 1\nuntil no candidate or frequent itemsets can be generated\nreturn all the frequent itemsets derived\n```\n　　给定事务数据集TDB，Apriori算法的执行过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/apriori.jpg\" width=\"600\"/>\n</div>\n　　可知Apriori算法的执行过程需要多次扫描事务数据集，尽管采用了基于先验定理的剪枝技术，仍然需要在内存中保存大量候选项集，另外，计算候选项集的支持度计数所需要的时间开销较大。\n### Apriori算法优化策略\n#### Hash Tree\n　　支持度计数的一种方法是将每个事务与所有的候选项集进行比较，并且更新包含在事务中的候选项集的支持度计数。这种方法是时间开销比较大，尤其当事务和候选项集的数量都很多时。\n　　另外一种方法是枚举每个事务所包含的项集，并且利用这些项集来更新对应的候选项集的支持度。该方法通过建立Hash Tree来表示候选项集。建立Hash Tree的伪代码如下。\n```\ninitially, k = 1\nm is the maximum number of candidate itemsets of a tree node which is specified by user\nfor each candidate c in all candidate itemsets \n    compute the hash value v of kth item of c\n    insert c to tree node n according to v\n    if the number of candidate itemsets of n exceeds m\n        k := k + 1\n        split n by k\nreturn Hash Tree\n```\n　　下图是一颗Hash Tree的例子。树的每一个内部节点都使用Hash函数h(x)=x%3来确定应当沿着当前节点的哪个分支向下。候选项集经过多次计算Hash函数后存储在Hash Tree的叶子节点中。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/Hash Tree.png\" width=\"600\"/>\n</div>\n　　考虑一条事务t={1，2，3，4，5}，为了更新候选项集的支持度计数，所有包含属于事务t的候选3-项集的叶节点至少访问一次。注意，包含在t中的候选3-项集必然是以数据项{1}，{2}，{3}开始。因此，Hash Tree的根节点将数据项{1}，{2}，{3}分别散列到不同的子节点。在树的下一层，根据事务的第二个数据项进行散列。继续这一过程，直至到达Hash Tree的叶节点。将事务与叶节点中存储的候选项集进行比较，如果候选项集是该事务的子集，则增加它的支持度计数。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/subset_hash_tree.png\" width=\"600\"/>\n</div>\n#### Direct Hashing and Pruning(DHP)\n　　Apriori算法在执行过程中需要生成大量候选项集，同时，为了计算这些候选项集的支持度计数需要大量的时间开销。采用DHP技术可以帮助减少候选项集的数量，尤其是在前两轮迭代计算过程中，实验结果表明采用DHP技术后候选项集的数量减少了一个数量级。另外，DHP技术会对事务数据集进行裁剪，有助于减少后续计算的时间开销。\n　　下图是采用DHP技术生成候选2-项集的过程。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/dhp_example.png\" width=\"600\"/>\n</div>\n　　DHP技术在计算候选1-项集的支持度计数的同时，对每一条事务所包含的2-项集进行枚举，根据Hash函数将其映射到对应的bucket。每一个bucket记录了其所包含的项集的数量。在生成候选2-项集时，通过查询对应的bucket来过滤不满足最小支持度阈值的候选2-项集。例如，通过Hash函数计算频繁1-项集{A}和{B}自连接生成的候选2-项集{A，B}对应的Bucket，可以发现其不满足最小支持度阈值，因此，无需计算该候选2-项集的支持度计数。\n　　对于频繁(k+1)-项集而言，其必然包含(k+1)个频繁k-项集，同时，每一个数据项必然出现了k次。如频繁3-项集{B，C，D}包含3个频繁2-项集{B，C}，{B，D}，{C，D}，其中，{B}，{C}，{D}各分别出现2次。根据这一规律，DHP计数对事务数据集进行裁剪。具体地，在遍历事务数据集来计算候选k-项集的支持度计数时，对于每一条事务，统计每一个数据项在候选项集中出现的次数，并将那些出现次数小于k次的数据项删除。如果删除之后，整条事务的长度小于(k+1)，则将这条事务从事务数据集中删除。\n### Apriori算法并行化\n　　Apriori算法并行化的基本思想是将生成候选项集的过程和计算候选项集计数的过程交给各个工作节点独立执行。本文简单介绍一下如何采用Spark技术来实现Apriori算法。\n　　事务数据集由RDD来表示，计算频繁1-项集的过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/yafim_1.png\" width=\"300\"/>\n</div>\n　　在接下来的每一轮迭代过程中，各个分区生成的候选项集将被collect到driver端，建立Hash Tree，并通过broadcast的方式将Hash Tree发送到各个worker。每一个executor根据Hash Tree计算分区内候选项集的支持度计数。在具体实现生成候选项集时，共有两种实现方式，其一是调用Spark自带的join方法，其二是采用MapReduce中map side join的方式实现，即将候选项集broadcast到各个worker，每一个executor将当前分区内的候选项集与broadcast变量中的候选项集进行自连接。实验结果表明第二种实现方式更加稳定和高效。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/yafim.png\" width=\"300\"/>\n</div>\n### FP-Growth算法分析\n#### 基本思想\n　　FP-Growth算法采用分而治之的思想，递归地将事务数据集划分为多个更小的条件事务数据集来挖掘频繁项集。同时，采用FP-Tree来表示事务数据集，FP-Tree是一种前缀树的变形，具有较高的压缩性能。FP-Growth算法在执行过程中只需要两次遍历事务数据集，并且不产生候选项集，从而在性能上比Apriori算法快了一个数量级。\n#### 算法过程\n　　给定如下图所示的事务数据集。首先，FP-Growth算法扫描一次事务数据集，计算各个数据项的支持度计数，从而得到频繁1-项集。然后，再一次扫描事务数据集，根据频繁1-项集对每一条事务进行过滤，删除其中不满足最小支持度阈值的1-项集，并按照支持度计数递减排序。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/db.jpg\" width=\"300\"/>\n</div>\n　　FP-Tree的每一个节点存储了数据项的名称，支持度计数和指向同名节点的指针。将上一步处理过后的事务插入到FP-Tree的过程如下图所示（图中未画出指向同名节点的指针）。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fptree.png\" width=\"400\"/>\n</div>\n　　为了便于遍历FP-Tree中的数据项，FP-Growth算法通过建立头表（header table）来记录每一个数据项的支持度计数和指针，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/headertable.jpg\" width=\"400\"/>\n</div>\n　　概括地讲，FP-Growth算法挖掘频繁项集的过程由两个子过程组成。其一，是遍历事务数据集并建立FP-Tree。其二，是对于该FP-Tree对应的头表中的每一个数据项，通过遍历同名节点链表来生成数据项的条件事务数据集。该算法通过递归地执行上述两个子过程来挖掘频繁项集，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fpgrowthmine.jpg\" width=\"800\"/>\n</div>\n### FP-Growth算法优化策略\n#### FP-Array\n　　在FP-Growth算法挖掘频繁项集的过程中，每一次递归都需要两次遍历FP-Tree。第一次是通过遍历FP-Tree生成条件事务数据集，第二次是根据条件事务数据集建立条件FP-Tree。尽管采用FP-Tree来表示事务数据集具有较高的压缩性能，但是，当FP-Tree所包含的节点数量较多时，遍历FP-Tree所需的时间明显增加。采用FP-Array技术后，每一次递归可以只需要一次遍历，进一步提高了FP-Growth算法的性能。\n　　下面将介绍如何采用FP-Array技术来改进FP-Growth算法。给定事务数据集如下图所示。与FP-Growth算法相同，将所有事务进行过滤和排序，然后插入到FP-Tree中。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fparray1.png\" width=\"600\"/>\n</div>\n　　与FP-Growth算法不同之处在于，将每一条事务插入到FP-Tree的过程的同时，需要额外构建了一个二维矩阵，称之为FP-Array，来记录与每一个数据项共同出现的数据项的支持度计数，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fparray.png\" width=\"300\"/>\n</div>\n　　例如上图中第三行表示与数据项{g}共同出现的数据项{b}、{a}、{d}的支持度计数分别为3、2、3。需要注意的是，无需考虑比数据项{g}支持度计数更低的数据项，例如{f}、{e}，因为这些项在下一次递归计算时并不起任何作用。所以，改进后的FP-Growth算法只需要扫描FP-Array就可以生成条件事务数据集。因此，与原FP-Growth算法相比，每一次递归的计算量均减少了一半的遍历FP-Tree的时间。\n### FP-Growth算法并行化\n　　对于FP-Growth算法并行化的研究主要依赖于并行计算框架。其中，较为典型的代表是由北京谷歌研究中心Li Haoyuan在MapReduce框架上实现的PFP算法，其执行流程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/pfp1.png\" width=\"400\"/>\n</div>\n　　该算法共执行三次Map和Reduce方法来查找事务数据集中的频繁项集。第一次执行Map和Reduce方法的目的是统计每一个数据项在事务数据集中出现的次数。删除不满足阈值的数据项后，按照支持度计数递减排序。然后,将上述计算结果分组，并为每一个组分配一个唯一的id。分组数量和分组策略的合理性都对该算法的性能有着直接影响。其中,分组数量由用户指定。为了均衡各个工作节点的工作负载，该算法采用了基于哈希的分组策略，并将分组结果通过分布式缓存技术(Distributed Cache)传输到各个工作节点。第二次执行Map和Reduce方法的目的是生成条件事务数据集和查找条件事务数据集中包含的频繁项集。其中，Map方法的输入是事务数据集的一个分区。对于分区中的每一条事务，该算法将根据分组结果来生成其对应的条件事务，将其写入到磁盘上，并作为Reduce方法的输入，如下图所示。Reduce方法从集群的其他工作节点的磁盘上拉取当前组对应的所有条件事务，将其作为新的事务数据集，通过执行单机FP-Growth算法来挖掘其中包含的所有频繁项集。第三次执行Map和Reduce方法最终汇总所有工作节点的计算结果。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/pfp.png\" width=\"auto\"/>\n</div>\n　　在Spark MLlib中也有FP-Growth算法的实现。该算法总体思路上与PFP算法相同，不同之处在于对shuffle进行了优化。PFP算法中shuffle的条件事务数据集可以理解为数组。但是，Spark MLlib在shuffle之前基于条件事务数据集建立了FP-Tree，因此，shuffle的是FP-Tree。由于FP-Tree具有较好的压缩性能，尽管建立FP-Tree时牺牲了一点时间，但是，当需要shuffle的数据量较大时，Spark MLlib中实现的FP-Growth算法确实具有较好的效果。然而，该实现仍然存在比较明显的缺点，有兴趣的读者可以通过阅读源码来思考一下这个问题。\n\n```\n/**\n  * Computes an FP-Growth model that contains frequent itemsets.\n  * @param data input data set, each element contains a transaction\n  * @return an [[FPGrowthModel]]\n  *\n  */\n@Since(\"1.3.0\")\ndef run[Item: ClassTag](data: RDD[Array[Item]]): FPGrowthModel[Item] = {\n    if (data.getStorageLevel == StorageLevel.NONE) {\n        logWarning(\"Input data is not cached.\")\n    }\n    val count = data.count()\n    // 最小支持度阈值minCount\n    val minCount = math.ceil(minSupport * count).toLong \n    val numParts = if (numPartitions > 0) numPartitions else data.partitions.length\n    // 采用HashPartitioner来对数据项进行分组\n    val partitioner = new HashPartitioner(numParts)\n    // 计算频繁1-项集\n    val freqItems = genFreqItems(data, minCount, partitioner)\n    // 挖掘所有频繁项集\n    val freqItemsets = genFreqItemsets(data, minCount, freqItems, partitioner)\n    new FPGrowthModel(freqItemsets)\n}\n\n/**\n  * Generate frequent itemsets by building FP-Trees, the extraction is done on each partition.\n  * @param data transactions\n  * @param minCount minimum count for frequent itemsets\n  * @param freqItems frequent items\n  * @param partitioner partitioner used to distribute transactions\n  * @return an RDD of (frequent itemset, count)\n  */\nprivate def genFreqItemsets[Item: ClassTag](\n        data: RDD[Array[Item]],\n        minCount: Long,\n        freqItems: Array[Item],\n        partitioner: Partitioner): RDD[FreqItemset[Item]] = {\n        val itemToRank = freqItems.zipWithIndex.toMap\n    data.flatMap { transaction =>\n        genCondTransactions(transaction, itemToRank, partitioner) // 生成候选项集\n    }.aggregateByKey(new FPTree[Int], partitioner.numPartitions)(\n        (tree, transaction) => tree.add(transaction, 1L), // 在Map端建立FP-Tree\n        (tree1, tree2) => tree1.merge(tree2)) // 在Reduce端合并FP-Tree\n    .flatMap { case (part, tree) =>\n        tree.extract(minCount, x => partitioner.getPartition(x) == part) // 递归挖掘所有频繁项集\n    }.map { case (ranks, count) =>\n        new FreqItemset(ranks.map(i => freqItems(i)).toArray, count)\n    }\n  }\n```\n### 结束语\n　　本文从时间复杂度角度引入对频繁项集挖掘问题的分析，概要地介绍了两种常见的频繁项集挖掘算法Apriori算法和FP-Growth算法，并对它们的优化策略和并行化方法进行了介绍。\n\n\n\n","source":"_posts/associations/关联规则挖掘基础篇.md","raw":"title: \"关联规则挖掘基础篇\"\ndate: 2016-07-04 14:46:01\ncategories: 数据挖掘\ntags: [数据挖掘, 关联规则]\n---\n<center>![img](关联规则挖掘基础篇/market.jpg)</center>\n### 什么是关联规则挖掘？\n　　作为数据挖掘的重要研究方向之一，关联规则挖掘的目的是从事务数据集中分析数据项之间潜在的关联关系，揭示其中蕴含的对于用户有价值的模式。一般认为，关联规则挖掘主要由两个步骤组成：(1)从事务数据集中挖掘所有支持度不小于最小支持度阈值的频繁项集；(2)从上一步结果中生成满足最小置信度阈值要求的关联规则。其中，由于具有指数级别的时间复杂度，频繁项集挖掘所消耗的时间往往超过用户可以接受的程度。在过去的十多年中，国内外的研究者们提出了许多算法来不断改进相关算法的性能。这里的性能主要指的是执行时间。\n<!-- more -->\n### 问题定义\n　　<b>定义1</b>（项集）设I={i<sub>1</sub>，i<sub>2</sub>，...，i<sub>n</sub>}是n个不同的数据项组成的集合。包含0个或多个数据项的集合，称之为项集。\n　　<b>定义2</b>（k-项集）如果一个项集包含 k个数据项，则称之为k-项集。\n　　<b>定义3</b>（事务）事务是不同的数据项组成的集合。每一条事务T是I的一个子集，即T⊆ I。\n　　<b>定义4</b>（事务数据集）事务数据集D={T<sub>1</sub>，T<sub>2</sub>，...，T<sub>m</sub>}是m条事务组成的集合。\n　　<b>定义5</b>（项集的支持度计数）项集X在D中的支持度计数表示D中包含X的事务数，其形式化定义如下:\n<center>count(X)=|{T<sub>i</sub>|X⊆T<sub>i</sub>，T<sub>i</sub>∈D}|</center>\n　　其中，|·|表示集合中元素的个数。\n　　<b>定义6</b>（项集的支持度）项集X在D中的支持度表示包含X的事务在D中所占的比例，其形式化定义如下:\n<center>support(X)=|{T<sub>i</sub>|X⊆T<sub>i</sub>，T<sub>i</sub>∈D}|/|D|</center>\n　　<b>定义7</b>（频繁项集）如果项集X的支持度不小于用户给定的最小支持度阈值 minSup，则称X为频繁项集。\n　　<b>定义8</b>（候选项集）可能成为频繁项集的项集称为候选项集。\n### 问题分析\n　　如果一个事务数据集中包含5个{a}，{b}，{c}，{d}，{e}不同的数据项，则该问题的解空间包含2<sup>5</sup>个候选项集，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/lattice.png\" width=\"600\"/>\n</div>\n　　为了计算该解空间中每一个候选项集的支持度，Brute-force方法通过扫描事务数据集，将所有候选项集与事务逐一比较。如果事务中包含该候选项集，则增加候选项集的支持度。该过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/brute_force.png\" width=\"600\"/>\n</div>\n　　从而，可知Brute-force方法的时间复杂度约为O(NMw)，其中N是事务数据集的大小，M是候选项集的数量，w是平均事务的长度。由于M=2<sup>k</sup>，k是数据项的数量，因此，该方法的时间复杂度是指数级别。\n### Apriori算法分析\n#### 基本思想\n　　Apriori算法采用了逐层搜索的策略来对解空间进行遍历。在遍历的过程中 ，该算法采用了先验原理（*如果一个项集是频繁项集，则其任意子集均是频繁项集。*）来对解空间进行剪枝，减少候选项集的数量。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/apriori_prune.png\" width=\"600\"/>\n</div>\n　　给定如上图所示的解空间，如果候选项集{A，B}不是频繁项集，则该候选项集的任意超集均不可能成为频繁项集，因此，无需计算这些项集的支持度，可以将其从解空间中剪枝，减少了不必要的计算量。\n#### 算法过程\n　　Apriori算法首先扫描一次事务数据集，计算各个数据项的支持度，从而得到频繁1-项集。将这些频繁1-项集自连接来生成候选2-项集。通过再一次扫描事务数据集，计算各个候选项集的支持度，从而得到频繁2-项集。Apriori算法按照这个方式不断迭代，直至不再产生新的候选项集或频繁项集为止。其中，将两个k-项集自连接来生成候选(k+1)-项集的要求是这两个k-项集除了最后一个数据项不同，其余数据项均相同。所生成的不满足先验原理的候选(k+1)-项集将被删除。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/self_join.png\" width=\"400\"/>\n</div>\n　　如上图所示，将频繁3-项集{abc}和{abd}做自连接生成候选4-项集{a，b，c，d}，由于{a，b，c，d}的任意子集均是频繁项集，因此，保留该候选项集。而候选4-项集{a，c，d，e}的子集{c，d，e}并不是频繁项集，因此，将其删除。\n　　Apriori算法的伪代码如下。\n```\ninitially, scan DB once to get frequent 1-itemset\nrepeat\n　　  generate (k+1)-candidate itemsets from frequent k-itemset\n　　  test (k+1)-candidate itemsets against DB to find frequent (k+1)-itemsets\n　　  set k := k + 1\nuntil no candidate or frequent itemsets can be generated\nreturn all the frequent itemsets derived\n```\n　　给定事务数据集TDB，Apriori算法的执行过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/apriori.jpg\" width=\"600\"/>\n</div>\n　　可知Apriori算法的执行过程需要多次扫描事务数据集，尽管采用了基于先验定理的剪枝技术，仍然需要在内存中保存大量候选项集，另外，计算候选项集的支持度计数所需要的时间开销较大。\n### Apriori算法优化策略\n#### Hash Tree\n　　支持度计数的一种方法是将每个事务与所有的候选项集进行比较，并且更新包含在事务中的候选项集的支持度计数。这种方法是时间开销比较大，尤其当事务和候选项集的数量都很多时。\n　　另外一种方法是枚举每个事务所包含的项集，并且利用这些项集来更新对应的候选项集的支持度。该方法通过建立Hash Tree来表示候选项集。建立Hash Tree的伪代码如下。\n```\ninitially, k = 1\nm is the maximum number of candidate itemsets of a tree node which is specified by user\nfor each candidate c in all candidate itemsets \n    compute the hash value v of kth item of c\n    insert c to tree node n according to v\n    if the number of candidate itemsets of n exceeds m\n        k := k + 1\n        split n by k\nreturn Hash Tree\n```\n　　下图是一颗Hash Tree的例子。树的每一个内部节点都使用Hash函数h(x)=x%3来确定应当沿着当前节点的哪个分支向下。候选项集经过多次计算Hash函数后存储在Hash Tree的叶子节点中。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/Hash Tree.png\" width=\"600\"/>\n</div>\n　　考虑一条事务t={1，2，3，4，5}，为了更新候选项集的支持度计数，所有包含属于事务t的候选3-项集的叶节点至少访问一次。注意，包含在t中的候选3-项集必然是以数据项{1}，{2}，{3}开始。因此，Hash Tree的根节点将数据项{1}，{2}，{3}分别散列到不同的子节点。在树的下一层，根据事务的第二个数据项进行散列。继续这一过程，直至到达Hash Tree的叶节点。将事务与叶节点中存储的候选项集进行比较，如果候选项集是该事务的子集，则增加它的支持度计数。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/subset_hash_tree.png\" width=\"600\"/>\n</div>\n#### Direct Hashing and Pruning(DHP)\n　　Apriori算法在执行过程中需要生成大量候选项集，同时，为了计算这些候选项集的支持度计数需要大量的时间开销。采用DHP技术可以帮助减少候选项集的数量，尤其是在前两轮迭代计算过程中，实验结果表明采用DHP技术后候选项集的数量减少了一个数量级。另外，DHP技术会对事务数据集进行裁剪，有助于减少后续计算的时间开销。\n　　下图是采用DHP技术生成候选2-项集的过程。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/dhp_example.png\" width=\"600\"/>\n</div>\n　　DHP技术在计算候选1-项集的支持度计数的同时，对每一条事务所包含的2-项集进行枚举，根据Hash函数将其映射到对应的bucket。每一个bucket记录了其所包含的项集的数量。在生成候选2-项集时，通过查询对应的bucket来过滤不满足最小支持度阈值的候选2-项集。例如，通过Hash函数计算频繁1-项集{A}和{B}自连接生成的候选2-项集{A，B}对应的Bucket，可以发现其不满足最小支持度阈值，因此，无需计算该候选2-项集的支持度计数。\n　　对于频繁(k+1)-项集而言，其必然包含(k+1)个频繁k-项集，同时，每一个数据项必然出现了k次。如频繁3-项集{B，C，D}包含3个频繁2-项集{B，C}，{B，D}，{C，D}，其中，{B}，{C}，{D}各分别出现2次。根据这一规律，DHP计数对事务数据集进行裁剪。具体地，在遍历事务数据集来计算候选k-项集的支持度计数时，对于每一条事务，统计每一个数据项在候选项集中出现的次数，并将那些出现次数小于k次的数据项删除。如果删除之后，整条事务的长度小于(k+1)，则将这条事务从事务数据集中删除。\n### Apriori算法并行化\n　　Apriori算法并行化的基本思想是将生成候选项集的过程和计算候选项集计数的过程交给各个工作节点独立执行。本文简单介绍一下如何采用Spark技术来实现Apriori算法。\n　　事务数据集由RDD来表示，计算频繁1-项集的过程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/yafim_1.png\" width=\"300\"/>\n</div>\n　　在接下来的每一轮迭代过程中，各个分区生成的候选项集将被collect到driver端，建立Hash Tree，并通过broadcast的方式将Hash Tree发送到各个worker。每一个executor根据Hash Tree计算分区内候选项集的支持度计数。在具体实现生成候选项集时，共有两种实现方式，其一是调用Spark自带的join方法，其二是采用MapReduce中map side join的方式实现，即将候选项集broadcast到各个worker，每一个executor将当前分区内的候选项集与broadcast变量中的候选项集进行自连接。实验结果表明第二种实现方式更加稳定和高效。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/yafim.png\" width=\"300\"/>\n</div>\n### FP-Growth算法分析\n#### 基本思想\n　　FP-Growth算法采用分而治之的思想，递归地将事务数据集划分为多个更小的条件事务数据集来挖掘频繁项集。同时，采用FP-Tree来表示事务数据集，FP-Tree是一种前缀树的变形，具有较高的压缩性能。FP-Growth算法在执行过程中只需要两次遍历事务数据集，并且不产生候选项集，从而在性能上比Apriori算法快了一个数量级。\n#### 算法过程\n　　给定如下图所示的事务数据集。首先，FP-Growth算法扫描一次事务数据集，计算各个数据项的支持度计数，从而得到频繁1-项集。然后，再一次扫描事务数据集，根据频繁1-项集对每一条事务进行过滤，删除其中不满足最小支持度阈值的1-项集，并按照支持度计数递减排序。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/db.jpg\" width=\"300\"/>\n</div>\n　　FP-Tree的每一个节点存储了数据项的名称，支持度计数和指向同名节点的指针。将上一步处理过后的事务插入到FP-Tree的过程如下图所示（图中未画出指向同名节点的指针）。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fptree.png\" width=\"400\"/>\n</div>\n　　为了便于遍历FP-Tree中的数据项，FP-Growth算法通过建立头表（header table）来记录每一个数据项的支持度计数和指针，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/headertable.jpg\" width=\"400\"/>\n</div>\n　　概括地讲，FP-Growth算法挖掘频繁项集的过程由两个子过程组成。其一，是遍历事务数据集并建立FP-Tree。其二，是对于该FP-Tree对应的头表中的每一个数据项，通过遍历同名节点链表来生成数据项的条件事务数据集。该算法通过递归地执行上述两个子过程来挖掘频繁项集，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fpgrowthmine.jpg\" width=\"800\"/>\n</div>\n### FP-Growth算法优化策略\n#### FP-Array\n　　在FP-Growth算法挖掘频繁项集的过程中，每一次递归都需要两次遍历FP-Tree。第一次是通过遍历FP-Tree生成条件事务数据集，第二次是根据条件事务数据集建立条件FP-Tree。尽管采用FP-Tree来表示事务数据集具有较高的压缩性能，但是，当FP-Tree所包含的节点数量较多时，遍历FP-Tree所需的时间明显增加。采用FP-Array技术后，每一次递归可以只需要一次遍历，进一步提高了FP-Growth算法的性能。\n　　下面将介绍如何采用FP-Array技术来改进FP-Growth算法。给定事务数据集如下图所示。与FP-Growth算法相同，将所有事务进行过滤和排序，然后插入到FP-Tree中。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fparray1.png\" width=\"600\"/>\n</div>\n　　与FP-Growth算法不同之处在于，将每一条事务插入到FP-Tree的过程的同时，需要额外构建了一个二维矩阵，称之为FP-Array，来记录与每一个数据项共同出现的数据项的支持度计数，如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/fparray.png\" width=\"300\"/>\n</div>\n　　例如上图中第三行表示与数据项{g}共同出现的数据项{b}、{a}、{d}的支持度计数分别为3、2、3。需要注意的是，无需考虑比数据项{g}支持度计数更低的数据项，例如{f}、{e}，因为这些项在下一次递归计算时并不起任何作用。所以，改进后的FP-Growth算法只需要扫描FP-Array就可以生成条件事务数据集。因此，与原FP-Growth算法相比，每一次递归的计算量均减少了一半的遍历FP-Tree的时间。\n### FP-Growth算法并行化\n　　对于FP-Growth算法并行化的研究主要依赖于并行计算框架。其中，较为典型的代表是由北京谷歌研究中心Li Haoyuan在MapReduce框架上实现的PFP算法，其执行流程如下图所示。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/pfp1.png\" width=\"400\"/>\n</div>\n　　该算法共执行三次Map和Reduce方法来查找事务数据集中的频繁项集。第一次执行Map和Reduce方法的目的是统计每一个数据项在事务数据集中出现的次数。删除不满足阈值的数据项后，按照支持度计数递减排序。然后,将上述计算结果分组，并为每一个组分配一个唯一的id。分组数量和分组策略的合理性都对该算法的性能有着直接影响。其中,分组数量由用户指定。为了均衡各个工作节点的工作负载，该算法采用了基于哈希的分组策略，并将分组结果通过分布式缓存技术(Distributed Cache)传输到各个工作节点。第二次执行Map和Reduce方法的目的是生成条件事务数据集和查找条件事务数据集中包含的频繁项集。其中，Map方法的输入是事务数据集的一个分区。对于分区中的每一条事务，该算法将根据分组结果来生成其对应的条件事务，将其写入到磁盘上，并作为Reduce方法的输入，如下图所示。Reduce方法从集群的其他工作节点的磁盘上拉取当前组对应的所有条件事务，将其作为新的事务数据集，通过执行单机FP-Growth算法来挖掘其中包含的所有频繁项集。第三次执行Map和Reduce方法最终汇总所有工作节点的计算结果。\n<div align=center>\n<img src=\"关联规则挖掘基础篇/pfp.png\" width=\"auto\"/>\n</div>\n　　在Spark MLlib中也有FP-Growth算法的实现。该算法总体思路上与PFP算法相同，不同之处在于对shuffle进行了优化。PFP算法中shuffle的条件事务数据集可以理解为数组。但是，Spark MLlib在shuffle之前基于条件事务数据集建立了FP-Tree，因此，shuffle的是FP-Tree。由于FP-Tree具有较好的压缩性能，尽管建立FP-Tree时牺牲了一点时间，但是，当需要shuffle的数据量较大时，Spark MLlib中实现的FP-Growth算法确实具有较好的效果。然而，该实现仍然存在比较明显的缺点，有兴趣的读者可以通过阅读源码来思考一下这个问题。\n\n```\n/**\n  * Computes an FP-Growth model that contains frequent itemsets.\n  * @param data input data set, each element contains a transaction\n  * @return an [[FPGrowthModel]]\n  *\n  */\n@Since(\"1.3.0\")\ndef run[Item: ClassTag](data: RDD[Array[Item]]): FPGrowthModel[Item] = {\n    if (data.getStorageLevel == StorageLevel.NONE) {\n        logWarning(\"Input data is not cached.\")\n    }\n    val count = data.count()\n    // 最小支持度阈值minCount\n    val minCount = math.ceil(minSupport * count).toLong \n    val numParts = if (numPartitions > 0) numPartitions else data.partitions.length\n    // 采用HashPartitioner来对数据项进行分组\n    val partitioner = new HashPartitioner(numParts)\n    // 计算频繁1-项集\n    val freqItems = genFreqItems(data, minCount, partitioner)\n    // 挖掘所有频繁项集\n    val freqItemsets = genFreqItemsets(data, minCount, freqItems, partitioner)\n    new FPGrowthModel(freqItemsets)\n}\n\n/**\n  * Generate frequent itemsets by building FP-Trees, the extraction is done on each partition.\n  * @param data transactions\n  * @param minCount minimum count for frequent itemsets\n  * @param freqItems frequent items\n  * @param partitioner partitioner used to distribute transactions\n  * @return an RDD of (frequent itemset, count)\n  */\nprivate def genFreqItemsets[Item: ClassTag](\n        data: RDD[Array[Item]],\n        minCount: Long,\n        freqItems: Array[Item],\n        partitioner: Partitioner): RDD[FreqItemset[Item]] = {\n        val itemToRank = freqItems.zipWithIndex.toMap\n    data.flatMap { transaction =>\n        genCondTransactions(transaction, itemToRank, partitioner) // 生成候选项集\n    }.aggregateByKey(new FPTree[Int], partitioner.numPartitions)(\n        (tree, transaction) => tree.add(transaction, 1L), // 在Map端建立FP-Tree\n        (tree1, tree2) => tree1.merge(tree2)) // 在Reduce端合并FP-Tree\n    .flatMap { case (part, tree) =>\n        tree.extract(minCount, x => partitioner.getPartition(x) == part) // 递归挖掘所有频繁项集\n    }.map { case (ranks, count) =>\n        new FreqItemset(ranks.map(i => freqItems(i)).toArray, count)\n    }\n  }\n```\n### 结束语\n　　本文从时间复杂度角度引入对频繁项集挖掘问题的分析，概要地介绍了两种常见的频繁项集挖掘算法Apriori算法和FP-Growth算法，并对它们的优化策略和并行化方法进行了介绍。\n\n\n\n","slug":"associations/关联规则挖掘基础篇","published":1,"updated":"2016-11-30T09:54:27.155Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciw6beddr000hlf8h4ypxbh7j"}],"PostAsset":[{"_id":"source/_posts/svm/3d_ball.png","slug":"3d_ball.png","post":"ciw6bedc4000glf8hvgcucjhc","modified":1,"renderable":0},{"_id":"source/_posts/svm/3d_ball_2.eps","slug":"3d_ball_2.eps","post":"ciw6bedc4000glf8hvgcucjhc","modified":1,"renderable":0},{"_id":"source/_posts/svm/3d_linear.png","slug":"3d_linear.png","post":"ciw6bedc4000glf8hvgcucjhc","modified":1,"renderable":0},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fparray1.png","slug":"fparray1.png","post":"ciw6beddr000hlf8h4ypxbh7j","modified":1,"renderable":0},{"_id":"source/_posts/associations/关联规则挖掘基础篇/market.jpg","slug":"market.jpg","post":"ciw6beddr000hlf8h4ypxbh7j","modified":1,"renderable":0},{"_id":"source/_posts/mxnet/arch.png","post":"ciw6bedbw000flf8hzygpr8cl","slug":"arch.png","modified":1,"renderable":1},{"_id":"source/_posts/mxnet/back_graph.png","post":"ciw6bedbw000flf8hzygpr8cl","slug":"back_graph.png","modified":1,"renderable":1},{"_id":"source/_posts/mxnet/perf.png","post":"ciw6bedbw000flf8hzygpr8cl","slug":"perf.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/2d_circle.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"2d_circle.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/2d_linear.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"2d_linear.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/2dcircle_2.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"2dcircle_2.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/3d_ball_2.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"3d_ball_2.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/3d_linear_2.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"3d_linear_2.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/code.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"code.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/codeblack.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"codeblack.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/codewhite.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"codewhite.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/perf.eps","post":"ciw6bedc4000glf8hvgcucjhc","slug":"perf.eps","modified":1,"renderable":1},{"_id":"source/_posts/svm/perf.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"perf.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/rdd.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"rdd.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/spark.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"spark.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/ste1.eps","post":"ciw6bedc4000glf8hvgcucjhc","slug":"ste1.eps","modified":1,"renderable":1},{"_id":"source/_posts/svm/step.eps","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step.eps","modified":1,"renderable":1},{"_id":"source/_posts/svm/step.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/step1.eps","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step1.eps","modified":1,"renderable":1},{"_id":"source/_posts/svm/step1.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step1.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/step2.eps","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step2.eps","modified":1,"renderable":1},{"_id":"source/_posts/svm/step2.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"step2.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/svm.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"svm.png","modified":1,"renderable":1},{"_id":"source/_posts/svm/tree.png","post":"ciw6bedc4000glf8hvgcucjhc","slug":"tree.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/Hash Tree.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"Hash Tree.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/apriori.jpg","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"apriori.jpg","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/apriori_prune.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"apriori_prune.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/brute_force.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"brute_force.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/db.jpg","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"db.jpg","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/dhp_example.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"dhp_example.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fparray.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"fparray.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fpgrowthmine.jpg","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"fpgrowthmine.jpg","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/fptree.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"fptree.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/headertable.jpg","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"headertable.jpg","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/lattice.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"lattice.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/pfp.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"pfp.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/pfp1.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"pfp1.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/self_join.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"self_join.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/subset_hash_tree.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"subset_hash_tree.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/yafim.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"yafim.png","modified":1,"renderable":1},{"_id":"source/_posts/associations/关联规则挖掘基础篇/yafim_1.png","post":"ciw6beddr000hlf8h4ypxbh7j","slug":"yafim_1.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"ciw6beddr000hlf8h4ypxbh7j","category_id":"ciw6beddu000ilf8hl3jcqpbu","_id":"ciw6bede3000llf8hp4l2ephx"}],"PostTag":[{"post_id":"ciw6bed9l0001lf8hi8uu3pc8","tag_id":"ciw6bed9v0003lf8hskem7a5t","_id":"ciw6bedad0007lf8hfb0doe70"},{"post_id":"ciw6beddr000hlf8h4ypxbh7j","tag_id":"ciw6beddv000jlf8h3jsf04h7","_id":"ciw6bede3000mlf8hf6yj9po9"},{"post_id":"ciw6beddr000hlf8h4ypxbh7j","tag_id":"ciw6beddz000klf8h7biz72fp","_id":"ciw6bede3000nlf8hpsrnw8pi"}],"Tag":[{"name":"Multivariate Statistics","_id":"ciw6bed9v0003lf8hskem7a5t"},{"name":"数据挖掘","_id":"ciw6beddv000jlf8h3jsf04h7"},{"name":"关联规则","_id":"ciw6beddz000klf8h7biz72fp"}]}}